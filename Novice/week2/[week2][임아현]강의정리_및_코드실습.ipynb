{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dfa9abd",
   "metadata": {},
   "source": [
    "### [TensorFlow] Lec-04 Multi variable linear regression\n",
    "이전복습내용)\n",
    "- Hypothesis : 가설함수 , 우리의 예측 H(x)=Wx +b\n",
    "- Cost function : 비용함수, 우리의 예측과 실제 값의 차이, cost(W) = (가설-실제데이터)제곱의 평균\n",
    "- Gradient Descent : 경사하강알고리즘, cost 를 최소화하는 w를 찾아가는 방법,  w=w-(learning rate) X (비용미분)\n",
    "\n",
    "1) 변수가 하나일 때 가설함수 Wx + b\n",
    "2) 변수가 여러개  Multi variable,늘어난 변수만큼 가중치를 필요하게 된다. w1x1 + w2x2 + w3x3 + b\n",
    "3) 몇 백개의 변수 -> Matrix Multiplication 이용\n",
    "4) 앞 matrix의 열의 개수와 뒤의 matrix의 행의 개수가 일치해야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e999361",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [73., 80., 75., 152.],\n",
    "    [93., 88., 93., 185.],\n",
    "    [89., 91., 90., 180.],\n",
    "    [96., 98., 100., 196.],\n",
    "    [73., 66., 70., 142.]\n",
    "], dtype= np.float32)\n",
    "\n",
    "x = data[:, :-1]\n",
    "y= data [:, [-1]]\n",
    "\n",
    "w= tf.Variable(tf.random_normal([3,1]))\n",
    "b= tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "\n",
    "def predict(x):\n",
    "    return tf.matmul(x,w) + b\n",
    "\n",
    "n_epochs = 2000\n",
    "for i in range(n_epochs+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean((tf.square(predict(x)-y)))\n",
    "        w_grad, b_grad = tape.gradient(cost, [w,b])\n",
    "        \n",
    "        w.assign_sub(learning_rate * w_grad)\n",
    "        b.assign_sub(learning_rate * b_grad)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"{:5}|{:10.4f}\".format(i, cost.numpy()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad94f5",
   "metadata": {},
   "source": [
    "### [TensorFlow] Lab-05-1 Logistic Regression\n",
    "1) What is Logistic Regression?\n",
    "- classification (0:positive / 1:negative) \n",
    "- Logistic VS Linear : Discrete(데이터 분리 구별이 가능, 0과 1로 분류 가능) / Continous (시간같은 연속적인 데이터, 수치형 )\n",
    "\n",
    "2) How to Solve?\n",
    "- Hypothesis Representation : 직선 -> Pass/Fail 구부러지는 그래프\n",
    "- Linear(wx+b) - Logistic(0< a <1) - DecisionBoundary( a>0.5 0.5보다 크면1 작으면 0)\n",
    "- Sigmoid/Logisitic Function : Linear를 통해 나온 수치화 값을 Logistic function을 통해 sigmoid 함수 \n",
    "- Decision Boundary \n",
    "- Cost Function : 랜덤하게 만들어진 W 값을 최적의 파라미터로 만들어주는 것,   \n",
    "- Optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae67bfa",
   "metadata": {},
   "source": [
    "### Lab 05 Logistic Classification (diabetes) - Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_train = xy[:, 0:-1]\n",
    "y_train = xy[:, [-1]]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(xy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e87cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal((8, 1)), name='weight')\n",
    "b = tf.Variable(tf.random.normal((1,)), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(features):\n",
    "    hypothesis  = tf.divide(1., 1. + tf.exp(tf.matmul(features, W) + b))\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae7ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(hypothesis, features, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7968be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e124e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(hypothesis, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(logistic_regression(features),features,labels)\n",
    "    return tape.gradient(loss_value, [W,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1001\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    for features, labels  in iter(dataset):\n",
    "        grads = grad(logistic_regression(features), features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
