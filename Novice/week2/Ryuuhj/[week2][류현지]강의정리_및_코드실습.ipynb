{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b253d27",
   "metadata": {},
   "source": [
    "# Lec 4. Multi variable linear regression\n",
    "**ğŸ“Œ ë³€ìˆ˜ê°€ ì—¬ëŸ¬ ê°œì¼ ë•Œ Hypothesis / Cost function**\n",
    "- ë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ ì¦ê°€í•  ìˆ˜ë¡, ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ëŠ”ë° í•œê³„ â†’ ***Matrix***  ì´ìš©\n",
    "![](https://1.bp.blogspot.com/-Jp5xumLwAz8/XFASYqRzIqI/AAAAAAAAA5s/It-uq9d6eJsdIVZWz-8W95yYOy6fhhsrwCLcBGAs/s400/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA%2B2019-01-29%2B%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE%2B5.44.04.png)\n",
    "- Tensor flowì—ì„  â†’ XWë¡œ í‘œí˜„ (í–‰ë ¬ì˜ ê³± ë•Œë¬¸ì—)\n",
    "- ë”°ë¼ì„œ ë‹¤ë³€ìˆ˜ hypothesisë¥¼ ê° í–‰ë ¬(X, W)ì˜ ê³±ìœ¼ë¡œ í‘œí˜„ ì´ ê°€ëŠ¥í•˜ë‹¤. (Xê°€ ì•ì— ì˜´) â‡’ H(X) = XW\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7b581b07-d313-42b2-83d9-5337ffb4fc6e/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T113240Z&X-Amz-Expires=86400&X-Amz-Signature=0ea20a5b9600b02baea487e512b550dd4968c6319c6c796c47485a5c8d9bf26a&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "\t- X Matrix\n",
    "\t\t- Column ìˆ˜ :  feature ìˆ˜\n",
    "\t\t- Row ìˆ˜ : instance ìˆ˜\n",
    "\n",
    "**ğŸ“Œ Matrixë¥¼ ì‚¬ìš©í•´ í‘œí˜„í•˜ëŠ” ê²ƒì˜ ì¥ì **\n",
    "- instance ê°œìˆ˜, feature ê°œìˆ˜ ìƒê´€ì—†ì´  ***H(X) = XW*** ë¡œ ë™ì¼í•œ í‘œí˜„ ì‚¬ìš© ê°€ëŠ¥í•¨.\n",
    "- instance ê°œìˆ˜ ìƒê´€X (â†’ ë‚´ì ê³¼ ë¬´ê´€)\n",
    "\n",
    "**ğŸ“Œ Weight matrixì˜ í¬ê¸° ê²°ì •?**\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b57e09c6-f0f8-4b93-98be-2f9c68df18f5/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T114336Z&X-Amz-Expires=86400&X-Amz-Signature=7bef43a0befdf759d9b96acdd2ebe2afb6a4371f88515ad04727868f224bd8eb&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "\t- Row = ì…ë ¥ ë°ì´í„°(X)ì˜ Column (feature) (ì…ë ¥ ê°œìˆ˜)\n",
    "\t- Column = ì¶œë ¥(H)ì˜ Column\n",
    "\n",
    "> âˆ´ **Weightì˜ í¬ê¸°ëŠ” ì…ë ¥/ì¶œë ¥ ê°œìˆ˜ì™€ ë¬´ê´€í•˜ë‹¤!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d1262c",
   "metadata": {},
   "source": [
    "# **Lec 5. Logistic Regression**\n",
    "\n",
    "**ğŸ“– Logistic Regression ê°œë…ì  ì ‘ê·¼**\n",
    "\n",
    " **Binary Classificaiton**\n",
    " - 2ê°€ì§€ ê°’ìœ¼ë¡œë§Œ í‘œí˜„ë¨ - 0 (positive), 1(negative) \n",
    " - ì´ê²ƒì„ í† ëŒ€ë¡œ Logistic Regression ëª¨ë¸ ìƒì„±\n",
    "\n",
    "**Logistic vs. Linear**\n",
    "- Logisticì„ ì ìš©í•˜ê¸° ìœ„í•œ data\n",
    "\t- 2ê°€ì§€ caseë¡œ ë¶„ë¦¬ ê°€ëŠ¥í•œ data\n",
    "\t- ì…€ ìˆ˜ ìˆê³  í©ì–´ì ¸ ìˆìŒ (Discrete ; Counted)\n",
    "\t- Ex. ì‹ ë°œ ì‚¬ì´ì¦ˆ\n",
    "\tâˆ´ Binary ê°’ ì‚¬ìš©\n",
    "\n",
    "- Linearì„ ì ìš©í•˜ê¸° ìœ„í•œ data\n",
    "\t- ë°ì´í„°ë“¤ì´ ì—°ì†ì ì„ (Continuous ; Measured)\n",
    "\t- ì´ì–´ì§€ëŠ” ê°’ë“¤ì„ ì˜ˆì¸¡ ê°€ëŠ¥\n",
    "\t- Ex. ì‹œê°„, ëª¸ë¬´ê²Œ\n",
    "\tâˆ´ Numeric ê°’ ì‚¬ìš© (ìˆ˜ì¹˜í˜• ë°ì´í„°)\n",
    "\n",
    "**ğŸ“– Logistic Regression ì˜ Hypothesis í‘œí˜„**\n",
    "\n",
    "**[ì˜ˆì‹œ] Study Hour â†’ Test Pass/Fail ì˜ˆì¸¡í•˜ê¸°**\n",
    "\n",
    "- Linear Regressionì„ ì ìš© í–ˆì„ ê²½ìš°\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/43a9da37-e1bd-47fd-99fd-b2c511cb2fe8/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T132555Z&X-Amz-Expires=86400&X-Amz-Signature=184eab361a314c299b8a451b398515f227432393c25008467b2ecd205bba98e1&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "\t- ê²°ê³¼ê°’ìœ¼ë¡œ ì—°ì†ì ì¸ ìˆ˜ì¹˜ ê°’ìœ¼ë¡œ ë°ì´í„°ê°€ ë‚˜ì˜´\n",
    "\t- But ì›í•˜ëŠ” ê°’ â‡’  Binary Classificationì— ëŒ€í•œ ê²°ê³¼ê°’ì´ í•„ìš”í•¨ (Passëƒ Failì´ëƒ)\n",
    "\n",
    "- Logistic Regression \n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2f70d3e4-38c0-474e-8665-e9dc39ac4b2b/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T155345Z&X-Amz-Expires=86400&X-Amz-Signature=126726eaddbdbc5ba05e953042a4663b89eef30ba11bb4088868886ab43707f3&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "\t- linear functionì˜ outputì„ ë„£ì€ ê²°ê³¼ = 0 or 1\n",
    "\t\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5efb277c-bb3a-447a-89f5-c0a901c46f0d/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T155505Z&X-Amz-Expires=86400&X-Amz-Signature=b773f5efec0d508a15b8b8a7495bd8170a51dfee55b31fb155bd376da089d427&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "\n",
    "- ë‰´ëŸ° ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ í•˜ë‚˜ì˜ ì»´í¬ë„ŒíŠ¸ì´ê¸°ë„ í•¨\n",
    "> **X â†’ Linear í•œ ê°’ â†’ 0 ~1 êµ¬ê°„ ê°’ â†’ decision boundary â†’ 0ê³¼ 1ì˜ ê°’ìœ¼ë¡œ ë„ì¶œ**\n",
    "\n",
    "**ğŸ“– Sigmoid (Logistic) function  [g(z)]**\n",
    "\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/4b4ac69b-2a16-4501-81af-ea434cdeae95/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T164109Z&X-Amz-Expires=86400&X-Amz-Signature=3ca6a104249eb80399c11865bc24eb134827f387d096f010d1f9a7a6f1481080&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "- z(input)ì€ real number(ìˆ˜ì¹˜í˜• ê°’)\n",
    "- z  ì¦ê°€ â†‘ âˆ e^(-x) â†“ , g(z) â‰ˆ 1\n",
    "- z  ì¦ê°€ â†“ âˆ e^(-x) â†‘ , g(z) â‰ˆ 0\n",
    "- linear regressionìœ¼ë¡œ ë‚˜ì˜¨ ì‹¤ìˆ˜ ê°’ì„ sigmoid funcì„ í†µí•´ 0, 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë„ì¶œ ê°€ëŠ¥í•¨.\n",
    "\n",
    "**ğŸ“Œ Decision Boundary**\n",
    "- 0.5ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, ë³´ë‹¤ í¬ë©´ 1/ì‘ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬\n",
    "- Sigmoid functionì˜ outputì€ 0 â‰¤ y â‰¤ 1 ë²”ìœ„ì˜ numerical value âˆ´ binaryí•˜ê²Œ ì²˜ë¦¬ í•„ìš” (â†’ Decision Boundary)\n",
    "- decision boundary function í‘œí˜„ì€ Linear/Non-linear ì¢…ë¥˜ ëª¨ë‘ ê°€ëŠ¥\t\n",
    "![Untitled.png (267Ã—246)](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a7902d10-0150-413b-a000-32b1d95a9faf/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T165601Z&X-Amz-Expires=86400&X-Amz-Signature=1e20e1228139a522269c96941fca2cf9204fe18cbae981db79c53ccd47b57200&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/85c011c8-cd1c-4b6a-b4f5-8dbe38a551e9/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T164955Z&X-Amz-Expires=86400&X-Amz-Signature=69d884badcc4dd5a0f38a461b8297c7d7f5b7c4b22e24189d962926f904b4a94&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject) \n",
    "\n",
    "    - Linear : x2 = -x1 + 3ìœ¼ë¡œ ì§ì„  ê·¸ë˜í”„ê°€ ê·¸ë ¤ì§€ê³ , ìœ„<-> ì•„ë˜ë¡œ ë¶„í• ë¨\n",
    "\t\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f1ae3fa8-58fa-4692-a899-3f42d2703524/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T165431Z&X-Amz-Expires=86400&X-Amz-Signature=7dfec5309453449b7c7b25ae70973d1a7a908e492887443867ceacce3c07db60&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0410d0ff-26f2-43fc-9516-98262699a16d/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221008T165452Z&X-Amz-Expires=86400&X-Amz-Signature=e734cebc22517d3892b81f09b8b020fb977bc5168d40eaaf638ed0241f53226c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "\n",
    "    - Non - linear : ì› ê·¸ë˜í”„ê°€ ê·¸ë ¤ì§€ê³  1ì´ decision boundary ê²°ì • ìˆ˜ê°€ ëœë‹¤.\n",
    "    \n",
    "## **ğŸ“Œ Cost Function**\n",
    "- Cost = ì›í•˜ëŠ” ì´ìƒì ì¸ model ê°’ - ìµœì´ˆì— ë§Œë“¤ì–´ì§„ model ê°’\n",
    "- ë”°ë¼ì„œ Costë¥¼ ì¤„ì—¬ì•¼ ì›í•˜ëŠ” ëª¨ë¸ê°’ì„ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆìŒ (cost = 0)\n",
    "\t- ë°ì´í„° í•™ìŠµì„ í†µí•´ ìµœì ì˜ parameterê°’ ì°¾ê¸°\n",
    "\t- Cost ìˆ˜ì‹\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/131f35ab-7bcb-48ea-b971-9a699224b32d/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221009%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221009T152633Z&X-Amz-Expires=86400&X-Amz-Signature=03962373877eae5ebb4f821e1b6d0e4fdbb280dafcec3c06bf04e3b43ae17bc5&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "- êµ¬í˜„ ì‹œ input = hypothesis , labels \n",
    "\t- Cost = hypothesis - labels\n",
    "\t- out put = cost ê°’\n",
    "\t- costê°€ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë¶„ë¥˜ë¥¼ ì˜ í•˜ëŠ” ê²ƒ\n",
    "- Cost ê°’ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•œ ê³¼ì •\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ab00cfc9-19df-4fde-974a-febdd9e408d1/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221009%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221009T153057Z&X-Amz-Expires=86400&X-Amz-Signature=ec16d3155fdfe48279ab127cea32194ab158ea0f2000829ef62b5c1bec2e2183&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3054f987-d46d-451b-8baa-b1e4b0380881/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221009%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221009T154332Z&X-Amz-Expires=86400&X-Amz-Signature=456eee83aeb13045665ac06f0954a2c29f5d4b72afcb13f4ad4bed5822b5a76b&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "- logistic regressionì˜ 1/0ì˜ ê°’ì— ëŒ€í•œ cost í•¨ìˆ˜ì„\n",
    "- y = 1 â†’ ì‹¤ì œ ì›í•˜ëŠ” ê°’ì´ 1ì¸ ê²½ìš°, ê°€ì„¤ ê°’ë„ 1ì´ì—¬ì•¼ cost = 0\n",
    "\t- ë°˜ëŒ€ë¡œ ê°€ì„¤ ê°’ (ì‹¤ì œë¡œ ë‚˜ì˜¤ëŠ” ê°’)ì´ 0ì´ë©´ â†’ costê°€ ë¬´í•œì— ê°€ê¹ê²Œ ì¦ê°€\n",
    "\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8563d26a-e2bc-46c4-8995-07a5734e8485/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221009%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221009T154402Z&X-Amz-Expires=86400&X-Amz-Signature=f581239ee773c897ca734c39f290132d2835b772a19bfc7ab78cf9b658e86150&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "> ìœ„ ë‘ ê°€ì§€ ê²½ìš°ë¥¼ í•©ì¹˜ë©´ ì´ìƒì ì¸ convex êµ¬ì¡°ë¥¼ ê°€ì§„ cost function ë„ì¶œ\n",
    "\n",
    "**ğŸ“Œ Optimization: Cost functionì„ ìµœì†Œí™” í•  ìˆ˜ ìˆëŠ” ë°©ë²•?**\n",
    "\n",
    "- Cost functionì—ì„œ ìˆœê°„ ì†ë„ ê¸°ìš¸ê¸°ê°€ 0ì— ê°€ê¹Œìš´ Î¸ ì°¾ê¸°\n",
    "![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ba338778-f4c6-419e-929d-078f774a7741/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221009%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20221009T154850Z&X-Amz-Expires=86400&X-Amz-Signature=1ff72beaf51ed4c75f99f1a2506f8c91ace406927f92806c74d7e84397acda10&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
    "- Gradient, learning rate, model ê°’(W, b)ë¥¼ í†µí•´ ìµœì ì˜ ê°’(optimizer ìµœì í™” í•˜ëŠ” ê°’)ì„ ì°¾ì•„ë‚¼ ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da624b7",
   "metadata": {},
   "source": [
    "# Lec 4 - LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f552b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e6deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9bc342",
   "metadata": {},
   "source": [
    "Matrix ì‚¬ìš© X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05370983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |   11325.9121\n",
      "   50 |     135.3618\n",
      "  100 |      11.1817\n",
      "  150 |       9.7940\n",
      "  200 |       9.7687\n",
      "  250 |       9.7587\n",
      "  300 |       9.7489\n",
      "  350 |       9.7389\n",
      "  400 |       9.7292\n",
      "  450 |       9.7194\n",
      "  500 |       9.7096\n",
      "  550 |       9.6999\n",
      "  600 |       9.6903\n",
      "  650 |       9.6806\n",
      "  700 |       9.6709\n",
      "  750 |       9.6612\n",
      "  800 |       9.6517\n",
      "  850 |       9.6421\n",
      "  900 |       9.6325\n",
      "  950 |       9.6229\n",
      " 1000 |       9.6134\n"
     ]
    }
   ],
   "source": [
    " #data and label (5,3)â‹…(?,?)=(5,1)\n",
    "x1 = [ 73.,  93.,  89.,  96.,  73.]\n",
    "x2 = [ 80.,  88.,  91.,  98.,  66.]\n",
    "x3 = [ 75.,  93.,  90., 100.,  70.]\n",
    "Y  = [152., 185., 180., 196., 142.]\n",
    "\n",
    "#random weights -> (3,1) \n",
    "w1 = tf.Variable(tf.random.normal((1,)))\n",
    "w2 = tf.Variable(tf.random.normal((1,)))\n",
    "w3 = tf.Variable(tf.random.normal((1,)))\n",
    "b  = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "#ì„ì˜ì˜ ì‘ì€ ê°’ í• ë‹¹\n",
    "learning_rate = 0.000001\n",
    "\n",
    "#Gradient descent êµ¬í˜„ (weight ê³„ì† ì—…ë°ì´íŠ¸) - 1001ë²ˆ ë°˜ë³µ\n",
    "for i in range(1000+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape: #ë³€ìˆ˜ ë³€í™” ì •ë³´ tapeê¸°ë¡\n",
    "        hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y)) #ì˜¤ì°¨ ì œê³±ì˜ í‰ê· ê°’\n",
    "    #W1, W2ì— ëŒ€í•œ gradient ê°’ êµ¬í•´ì„œ ê°ê° í• ë‹¹\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\n",
    "    \n",
    "    #êµ¬í•œ gradientê°’ ë¹¼ì„œ ì—…ë°ì´íŠ¸ (gradient * learning_rate)\n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:12.4f}\".format(i, cost.numpy())) #costë§Œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fcb5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 335.280823 |    -4.0663 |     1.1220 |  -6.065215\n",
      "   50 |  76.037262 |    -0.8001 |     1.6209 |  -4.978779\n",
      "  100 |  18.959263 |     0.7151 |     1.8781 |  -4.429109\n",
      "  150 |   6.310240 |     1.4125 |     2.0104 |  -4.134423\n",
      "  200 |   3.445082 |     1.7284 |     2.0768 |  -3.961648\n",
      "  250 |   2.743659 |     1.8667 |     2.1075 |  -3.847750\n",
      "  300 |   2.525401 |     1.9225 |     2.1184 |  -3.762738\n",
      "  350 |   2.417754 |     1.9402 |     2.1181 |  -3.692262\n",
      "  400 |   2.337300 |     1.9403 |     2.1114 |  -3.629400\n",
      "  450 |   2.264998 |     1.9325 |     2.1008 |  -3.570778\n",
      "  500 |   2.196328 |     1.9213 |     2.0881 |  -3.514729\n",
      "  550 |   2.130126 |     1.9085 |     2.0741 |  -3.460409\n",
      "  600 |   2.066037 |     1.8953 |     2.0595 |  -3.407385\n",
      "  650 |   2.003917 |     1.8819 |     2.0444 |  -3.355424\n",
      "  700 |   1.943679 |     1.8686 |     2.0293 |  -3.304398\n",
      "  750 |   1.885258 |     1.8555 |     2.0141 |  -3.254230\n",
      "  800 |   1.828595 |     1.8425 |     1.9990 |  -3.204873\n",
      "  850 |   1.773636 |     1.8297 |     1.9841 |  -3.156293\n",
      "  900 |   1.720329 |     1.8171 |     1.9693 |  -3.108468\n",
      "  950 |   1.668625 |     1.8048 |     1.9547 |  -3.061379\n",
      " 1000 |   1.618474 |     1.7926 |     1.9403 |  -3.015011\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0) \n",
    "\n",
    "#data and label (5,2)â‹…(?,?)=(5,1)\n",
    "x1_data = [1, 0, 3, 0, 5]\n",
    "x2_data = [0, 2, 0, 4, 0]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "#random weights -> (2,1) \n",
    "W1 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "W2 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "b  = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "\n",
    "#ì„ì˜ì˜ ì‘ì€ ê°’ í• ë‹¹\n",
    "learning_rate = tf.Variable(0.001)\n",
    "\n",
    "#Gradient descent êµ¬í˜„ (weight ê³„ì† ì—…ë°ì´íŠ¸) - 1001ë²ˆ ë°˜ë³µ\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape: #ë³€ìˆ˜ ë³€í™” ì •ë³´ tapeê¸°ë¡\n",
    "        hypothesis = W1 * x1_data + W2 * x2_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data)) #ì˜¤ì°¨ ì œê³±ì˜ í‰ê· ê°’\n",
    "        #W1, W2ì— ëŒ€í•œ gradient ê°’ êµ¬í•´ì„œ ê°ê° í• ë‹¹\n",
    "    W1_grad, W2_grad, b_grad = tape.gradient(cost, [W1, W2, b])\n",
    "    #êµ¬í•œ gradientê°’ ë¹¼ì„œ ì—…ë°ì´íŠ¸ (gradient * learning_rate)\n",
    "    W1.assign_sub(learning_rate * W1_grad)\n",
    "    W2.assign_sub(learning_rate * W2_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(i, cost.numpy(), W1.numpy()[0], W2.numpy()[0], b.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0e156",
   "metadata": {},
   "source": [
    "GradientTape()\n",
    "- with êµ¬ë¬¸ ì•ˆ ë³€ìˆ˜ë“¤ì˜ ë³€í™” ì •ë³´ë¥¼ tapeì— ê¸°ë¡í•¨\n",
    "\n",
    "tape.gradient(A, [b.c])\n",
    "\n",
    "- í•¨ìˆ˜(A)ì— ëŒ€í•´ ë³€ìˆ˜ë“¤([b,c])ì— ëŒ€í•œ ê°œë³„ ë¯¸ë¶„ê°’ì„ êµ¬í•´ tupleë¡œ ë°˜í™˜\n",
    "\n",
    "A.assign_sub(B)\n",
    "\n",
    "- A = A - B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569e994a",
   "metadata": {},
   "source": [
    "Matrix ì‚¬ìš© O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd95258",
   "metadata": {},
   "source": [
    "slice ë©”ì†Œë“œ\n",
    "- data[Row ,Column ]\n",
    "  - \":\" -> ì²˜ìŒ ~ ëê¹Œì§€\n",
    "  - \" :-1\" -> ì²˜ìŒ ~ ë§ˆì§€ë§‰ ì „ ê¹Œì§€\n",
    "  - \" [-1]\" -> ë§ˆì§€ë§‰ \"ë§Œ\"\n",
    "  \n",
    "tf.matmul(X, W)\n",
    "- ë‚´ì í•¨ìˆ˜\n",
    "- X inner pot W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db5a7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62785ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 |  5455.5903\n",
      "  100 |    31.7443\n",
      "  200 |    30.9326\n",
      "  300 |    30.7894\n",
      "  400 |    30.6468\n",
      "  500 |    30.5055\n",
      "  600 |    30.3644\n",
      "  700 |    30.2242\n",
      "  800 |    30.0849\n",
      "  900 |    29.9463\n",
      " 1000 |    29.8081\n",
      " 1100 |    29.6710\n",
      " 1200 |    29.5348\n",
      " 1300 |    29.3989\n",
      " 1400 |    29.2641\n",
      " 1500 |    29.1299\n",
      " 1600 |    28.9961\n",
      " 1700 |    28.8634\n",
      " 1800 |    28.7313\n",
      " 1900 |    28.5997\n",
      " 2000 |    28.4689\n"
     ]
    }
   ],
   "source": [
    "# X=(5*3) , Y=(5,1)\n",
    "data = np.array([\n",
    "    # X1,   X2,    X3,   y\n",
    "    [ 73.,  80.,  75., 152. ],\n",
    "    [ 93.,  88.,  93., 185. ],\n",
    "    [ 89.,  91.,  90., 180. ],\n",
    "    [ 96.,  98., 100., 196. ],\n",
    "    [ 73.,  66.,  70., 142. ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# npì˜ slicing ì‚¬ìš© -> ë°ì´í„° ë¶„í• \n",
    "X = data[:, :-1] # input\n",
    "y = data[:, [-1]] # ì¶œë ¥=label=ì •ë‹µ\n",
    "\n",
    "#X Column = 3, Y Column = 1 --> W(3,1)\n",
    "W = tf.Variable(tf.random.normal((3, 1)))\n",
    "b = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# hypothesis function : ê°€ì„¤ í•¨ìˆ˜\n",
    "def predict(X):\n",
    "    return tf.matmul(X, W) + b #ì´í›„ bëŠ” ìƒëµ ê°€ëŠ¥\n",
    "\n",
    "print(\"epoch | cost\")\n",
    "\n",
    "#gradient descent- 2001ë²ˆ ë°˜ë³µ -> W ì—…ë°ì´íŠ¸\n",
    "n_epochs = 2000\n",
    "for i in range(n_epochs+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
    "\n",
    "    # calculates the gradients of the loss\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "\n",
    "    # W updateë„ í•œ ì¤„ë¡œ ëë‚¨!\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"{:5} | {:10.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb96796",
   "metadata": {},
   "source": [
    "28ì—ì„œ ë”ì´ìƒ ê°ì†Œ X -> ìµœì í™” ì™„ë£Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f46e560",
   "metadata": {},
   "source": [
    "# LEC 5 - LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25cc5537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dec5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì‚¬ìš©í•  data (x,label(y) ì„ ì–¸)\n",
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_train = xy[:, 0:-1]\n",
    "y_train = xy[:, [-1]]\n",
    "\n",
    "#í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "x_test = np.array([[5, 2]], dtype=np.float32)\n",
    "y_test = np.array([[1]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38828420",
   "metadata": {},
   "source": [
    "- **batch size**\n",
    "    - í•œ ë²ˆì˜ batchë§ˆë‹¤ ì£¼ëŠ” ë°ì´í„° ìƒ˜í”Œì˜ size \n",
    "    - **batch** :ë³´í†µ mini-batchë¼ê³  í‘œí˜„. ë‚˜ëˆ ì§„ ë°ì´í„° ì…‹\n",
    "    - **iterationë§ˆë‹¤ ì£¼ëŠ” ë°ì´í„° ì‚¬ì´ì¦ˆ**\n",
    "    - iteration: epochë¥¼ ë‚˜ëˆ„ì–´ì„œ ì‹¤í–‰í•˜ëŠ” íšŸìˆ˜\n",
    "    \n",
    "- **.from_tensor_slices**\n",
    "    - ë¦¬ìŠ¤íŠ¸, ë„˜íŒŒì´, í…ì„œí”Œë¡œìš° ìë£Œí˜•ì—ì„œ -> ë°ì´í„°ì…‹ ë§Œë“¤ê¸° ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f733cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Dataset-> ìš°ë¦¬ê°€ ì›í•˜ëŠ” xê°’, yê°’ì„ ì‹¤ì œ xê¸¸ì´ë§Œí¼ batch sizeë¡œ í•´ì„œ í•™ìŠµí•  data ê°’ ê°€ì ¸ì˜´\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\n",
    "#ì›í•˜ëŠ” ëª¨ë¸ ì„ ì–¸\n",
    "W = tf.Variable(tf.random.normal((8, 1)), name='weight')\n",
    "b = tf.Variable(tf.random.normal((1,)), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08633802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.6217\n",
      "Iter: 100, Loss: 0.6143\n",
      "Iter: 200, Loss: 0.6074\n",
      "Iter: 300, Loss: 0.6009\n",
      "Iter: 400, Loss: 0.5949\n",
      "Iter: 500, Loss: 0.5892\n",
      "Iter: 600, Loss: 0.5839\n",
      "Iter: 700, Loss: 0.5789\n",
      "Iter: 800, Loss: 0.5742\n",
      "Iter: 900, Loss: 0.5698\n",
      "Iter: 1000, Loss: 0.5657\n"
     ]
    }
   ],
   "source": [
    "#logistic_regressionì— ëŒ€í•œ hypothesis\n",
    "def logistic_regression(features):               \n",
    "    hypothesis  = tf.divide(1., 1. + tf.exp(tf.matmul(features, W) + b))\n",
    "    return hypothesis\n",
    "\n",
    "# cost = hypothesis - label(y) \n",
    "# cost(hÎ¸, (x),y) = -ylog( hÎ¸(x) ) - (1-y)log( 1- hÎ¸(x) )\n",
    "def loss_fn(hypothesis, features, labels):\n",
    "    hypothesis = logistic_regression(features) #ì½”ë“œ ì˜¤ë¥˜ ë°©ì§€ìœ„í•´ í•œë²ˆ ë”\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "#learning rateë¡œ oprtimizer ì„ ì–¸\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜\n",
    "def grad(hypothesis, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(logistic_regression(features),features,labels)\n",
    "    return tape.gradient(loss_value, [W,b])\n",
    "\n",
    "# ì‹¤ì œ í•™ìŠµ ì‹œì‘\n",
    "EPOCHS = 1001\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    for features, labels  in iter(dataset): #datasetì„ í† ëŒ€ë¡œ iteratorì„ ëŒë¦¼ -> x, yê°’ ëŒ€ì…\n",
    "        #ê°€ì„¤(ëª¨ë¸ê°’), x, yë¡œ gradient êµ¬í•´ì„œ\n",
    "        grads = grad(logistic_regression(features), features, labels)\n",
    "        #gradient descent ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ gradientê°€ ìµœì†Œê°€ ë˜ëŠ”(=costê°€ ìµœì†Œì¸) ê°€ì„¤ê°’ ë§Œë“œëŠ” W,b êµ¬í•˜ê¸° \n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd65094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
