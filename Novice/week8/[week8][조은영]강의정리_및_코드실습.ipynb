{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RNN\n",
        "## Sequence data\n",
        "- NN/CNN X\n",
        "- 그 다음 것을 계산하는데 그 전 상태가 영향을 미침\n",
        "\n",
        "## Recurrent Neural Network\n",
        "$$ h_t = fw(h_{t-1},x_t) $$\n",
        "$$ h_t = tahh(W_{hh}h_{t-1}+W_{xh}x_t) $$\n",
        "$$ y_t = W_{hy}h_t $$\n",
        "\n",
        "## RNN applications\n",
        "- Language Modeling\n",
        "- Speech Recognition\n",
        "- Machin Translation\n",
        "- Conversation Modeling/Question Answering\n",
        "- Image/Video Captioning\n",
        "- Image/Music/Dance Generation\n",
        "\n",
        "## RNN offer a lot of flexibility\n",
        "- one to one\n",
        "- one to many (e.g. Image Captioning)\n",
        "- many to one (e.g. Sentiment Classification)\n",
        "- many to many (e.g. Machin Translation)\n",
        "- many to many (e.g. Video classification on frame level)\n",
        "\n",
        "## Multi-Layer RNN\n",
        "- 여러개의 Layer를 둘 수 있음 > 복잡한 학습\n",
        "\n",
        "## Training RNNs is challenging\n",
        "- Several advanced models\n",
        "  - Long Short Term Memory (LSTM)\n",
        "  - GRU by Cho et al.2014\n"
      ],
      "metadata": {
        "id": "hS33qgaOD3ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN basics\n",
        "## RNN in TensorFLow\n",
        "- 선언 후 loop하는 방식\n",
        "- API 활용\n"
      ],
      "metadata": {
        "id": "pkEU2N-5Icla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One cell: 4 (input-dim), 2 (hidden_size)\n"
      ],
      "metadata": {
        "id": "IzPoevtdI_py"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "htMUaUiLDqFv"
      },
      "outputs": [],
      "source": [
        "# setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential, Model\n",
        "\n",
        "# One hot encoding for each char in 'hello'\n",
        "h = [1, 0, 0, 0]\n",
        "e = [0, 1, 0, 0]\n",
        "l = [0, 0, 1, 0]\n",
        "o = [0, 0, 0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One cell RNN input_dim (4) -> output_dim (2)\n",
        "x_data = np.array([[h]], dtype=np.float32)\n",
        "\n",
        "hidden_size = 2\n",
        "cell = layers.SimpleRNNCell(units=hidden_size) # creating SimpleRNNCell\n",
        "rnn = layers.RNN(cell, return_sequences=True, return_state=True) # analogous to tf.nn.dynamic_rnn\n",
        "outputs, states = rnn(x_data)\n",
        "\n",
        "print('x_data: {}, shape: {}'.format(x_data, x_data.shape))\n",
        "print('outputs: {}, shape: {}'.format(outputs, outputs.shape))\n",
        "print('states: {}, shape: {}'.format(states, states.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49n4cSToJcrl",
        "outputId": "0c5e8ae0-1da3-4b42-c441-62e6299c8e1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data: [[[1. 0. 0. 0.]]], shape: (1, 1, 4)\n",
            "outputs: [[[-0.7521577   0.02801924]]], shape: (1, 1, 2)\n",
            "states: [[-0.7521577   0.02801924]], shape: (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unfolding to n sequences\n"
      ],
      "metadata": {
        "id": "uuQPJMNcJA2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
        "x_data = np.array([[h, e, l, l, o]], dtype=np.float32)\n",
        "\n",
        "hidden_size = 2\n",
        "rnn = layers.SimpleRNN(units=2, return_sequences=True, return_state=True)    \n",
        "outputs, states = rnn(x_data)\n",
        "\n",
        "print('x_data: {}, shape: {} \\n'.format(x_data, x_data.shape))\n",
        "print('outputs: {}, shape: {} \\n'.format(outputs, outputs.shape))\n",
        "print('states: {}, shape: {}'.format(states, states.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpg3falMJsu4",
        "outputId": "5c01cd0a-e332-489e-834b-eb0d1042dc9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data: [[[1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1.]]], shape: (1, 5, 4) \n",
            "\n",
            "outputs: [[[-0.11868375  0.04374024]\n",
            "  [-0.76728576 -0.4132299 ]\n",
            "  [-0.6160405  -0.34114617]\n",
            "  [-0.5742557  -0.1982033 ]\n",
            "  [-0.12445982 -0.5815702 ]]], shape: (1, 5, 2) \n",
            "\n",
            "states: [[-0.12445982 -0.5815702 ]], shape: (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching input"
      ],
      "metadata": {
        "id": "z-6ernzfJB5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
        "# 3 batches 'hello', 'eolll', 'lleel'\n",
        "x_data = np.array([[h, e, l, l, o],\n",
        "                   [e, o, l, l, l],\n",
        "                   [l, l, e, e, l]], dtype=np.float32)\n",
        "\n",
        "hidden_size = 2\n",
        "rnn = layers.SimpleRNN(units=2, return_sequences=True, return_state=True)    \n",
        "outputs, states = rnn(x_data)\n",
        "\n",
        "print('x_data: {}, shape: {} \\n'.format(x_data, x_data.shape))\n",
        "print('outputs: {}, shape: {} \\n'.format(outputs, outputs.shape))\n",
        "print('states: {}, shape: {}'.format(states, states.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEjDcUFQJ6Y3",
        "outputId": "c328f2bd-909d-4aec-b7f9-f5f091c2ec1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data: [[[1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1.]]\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]]\n",
            "\n",
            " [[0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0.]]], shape: (3, 5, 4) \n",
            "\n",
            "outputs: [[[ 0.61806625  0.03502199]\n",
            "  [-0.2445237   0.23894477]\n",
            "  [-0.05489645  0.77628404]\n",
            "  [-0.19458076  0.91980433]\n",
            "  [-0.36250082  0.92203534]]\n",
            "\n",
            " [[ 0.3479356   0.15374534]\n",
            "  [-0.7560337   0.7096639 ]\n",
            "  [ 0.45863786  0.8977236 ]\n",
            "  [-0.60316706  0.94176435]\n",
            "  [ 0.34829178  0.9360175 ]]\n",
            "\n",
            " [[-0.30891302  0.6746309 ]\n",
            "  [ 0.04707701  0.89849985]\n",
            "  [ 0.37514094  0.7834192 ]\n",
            "  [ 0.05749449  0.747855  ]\n",
            "  [-0.30183068  0.9169008 ]]], shape: (3, 5, 2) \n",
            "\n",
            "states: [[-0.36250082  0.92203534]\n",
            " [ 0.34829178  0.9360175 ]\n",
            " [-0.30183068  0.9169008 ]], shape: (3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Many to one\n",
        "## Various usage of RNN\n",
        "- one to one\n",
        "- one to many (e.g. Image Captioning)\n",
        "- many to one (e.g. Sentiment Classification)\n",
        "- many to many (e.g. Machin Translation)\n",
        "- many to many (e.g. Video classification on frame level)\n",
        "\n",
        "## What is \"many to one\"?\n",
        "- Sequence classification\n",
        "  - e.g. classify polarity of sentence <br/>\n",
        "  sequence: sentence, token: word\n",
        "\n",
        "## Example : word sentiment classification\n",
        "### Preparing dataset\n"
      ],
      "metadata": {
        "id": "HGF-7dmvKReV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "%matplotlib inline\n",
        "\n",
        "# example data\n",
        "words = ['good', 'bad', 'worse', 'so good']\n",
        "y_data = [1,0,0,1]\n",
        "\n",
        "# creating a token dictionary\n",
        "char_set = [''] + sorted(list(set(''.join(words))))\n",
        "idx2char = {idx : char for idx, char in enumerate(char_set)}\n",
        "char2idx = {char : idx for idx, char in enumerate(char_set)}\n",
        "\n",
        "print(char_set)\n",
        "print(idx2char)\n",
        "print(char2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdH_--roLKs0",
        "outputId": "5115db4f-4c5e-470e-a1a9-7cb3a5f6360b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', ' ', 'a', 'b', 'd', 'e', 'g', 'o', 'r', 's', 'w']\n",
            "{0: '', 1: ' ', 2: 'a', 3: 'b', 4: 'd', 5: 'e', 6: 'g', 7: 'o', 8: 'r', 9: 's', 10: 'w'}\n",
            "{'': 0, ' ': 1, 'a': 2, 'b': 3, 'd': 4, 'e': 5, 'g': 6, 'o': 7, 'r': 8, 's': 9, 'w': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting sequence of tokens to sequence of indices\n",
        "x_data = list(map(lambda word : [char2idx.get(char) for char in word], words))\n",
        "x_data_len = list(map(lambda word : len(word), x_data))\n",
        "\n",
        "print(x_data)\n",
        "print(x_data_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk8jWa0qLXax",
        "outputId": "46206aae-0a83-42aa-eb4d-3d5a35bffff3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]\n",
            "[4, 3, 5, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding the sequence of indices\n",
        "max_sequence = 10\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence,\n",
        "                       padding = 'post', truncating = 'post')\n",
        "\n",
        "# checking data\n",
        "print(x_data)\n",
        "print(x_data_len)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGRiXESvLX5_",
        "outputId": "4e05b94f-8c03-49e1-9585-d5aa9e37fb16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6  7  7  4  0  0  0  0  0  0]\n",
            " [ 3  2  4  0  0  0  0  0  0  0]\n",
            " [10  7  8  9  5  0  0  0  0  0]\n",
            " [ 9  7  1  6  7  7  4  0  0  0]]\n",
            "[4, 3, 5, 7]\n",
            "[1, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and training model\n",
        "\n"
      ],
      "metadata": {
        "id": "sXns43bELQTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating simple rnn for \"many to one\" classification\n",
        "input_dim = len(char2idx)\n",
        "output_dim = len(char2idx)\n",
        "one_hot = np.eye(len(char2idx))\n",
        "hidden_size = 10\n",
        "num_classes = 2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
        "                           trainable=False, mask_zero=True, input_length=max_sequence,\n",
        "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
        "model.add(layers.SimpleRNN(units=hidden_size))\n",
        "model.add(layers.Dense(units=num_classes))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NLUF3gtLahw",
        "outputId": "b729e5cd-a723-4620-b8a8-7fe36ddf5f10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 11)            121       \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 10)                220       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 363\n",
            "Trainable params: 242\n",
            "Non-trainable params: 121\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating loss function\n",
        "def loss_fn(model, x, y):\n",
        "    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True))\n",
        "\n",
        "# creating an optimizer\n",
        "lr = .01\n",
        "epochs = 30\n",
        "batch_size = 2\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
      ],
      "metadata": {
        "id": "1BG049kKLfSW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating data pipeline\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size = 4)\n",
        "tr_dataset = tr_dataset.batch(batch_size = batch_size)\n",
        "\n",
        "print(tr_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_EXUxr2Lgre",
        "outputId": "ec861118-5d94-4920-b8ac-2d43a4e8bacb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "tr_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "    \n",
        "    for x_mb, y_mb in tr_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x=x_mb, y=y_mb)\n",
        "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
        "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    else:\n",
        "        avg_tr_loss /= tr_step\n",
        "        tr_loss_hist.append(avg_tr_loss)\n",
        "    \n",
        "    if (epoch + 1) % 5 ==0:        \n",
        "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg30w2POLiDM",
        "outputId": "52a8cc48-4808-4389-a22a-cb8212b90ea6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   5, tr_loss : 0.216\n",
            "epoch :  10, tr_loss : 0.040\n",
            "epoch :  15, tr_loss : 0.013\n",
            "epoch :  20, tr_loss : 0.007\n",
            "epoch :  25, tr_loss : 0.005\n",
            "epoch :  30, tr_loss : 0.004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking performance"
      ],
      "metadata": {
        "id": "ouv_IVFVLSb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(x_data)\n",
        "yhat = np.argmax(yhat, axis=-1)\n",
        "print('acc : {:.2%}'.format(np.mean(yhat == y_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52IsfzzcLjqi",
        "outputId": "1a692fba-b96c-4d25-b830-6335575b369f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 517ms/step\n",
            "acc : 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tr_loss_hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "VaBi7fzELk7b",
        "outputId": "8baff417-4b59-451d-d93c-18e4f7a85b5c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7ce5446310>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Many to one stacking\n",
        "## What is \"stacking\"?\n",
        "- RNN을 여러개 쌓을 수 있음\n",
        "- 더 좋은 성능을 보임\n",
        "- input에 가까운 RNN은 syntactic information을 더 잘 인코딩\n",
        "- output에 가까운 RNN은 sementic information을 더 잘 인코딩\n",
        "\n",
        "## Many to one stacking\n",
        "- RNN을 여러개 활용\n",
        "\n",
        "## Example: sentence classification\n",
        "### Preparing dataset"
      ],
      "metadata": {
        "id": "fNUn4dCwMjhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pprint import pprint\n",
        "%matplotlib inline\n",
        "\n",
        "# example data\n",
        "sentences = ['What I cannot create, I do not understand.',\n",
        "             'Intellecuals solve problems, geniuses prevent them',\n",
        "             'A person who never made a mistake never tied anything new.',\n",
        "             'The same equations have the same solutions.']\n",
        "y_data = [1,0,0,1] # 1: richard feynman, 0: albert einstein\n",
        "\n",
        "# creating a token dictionary\n",
        "char_set = [''] + sorted(list(set(''.join(sentences))))\n",
        "idx2char = {idx : char for idx, char in enumerate(char_set)}\n",
        "char2idx = {char : idx for idx, char in enumerate(char_set)}\n",
        "\n",
        "print(char_set)\n",
        "print(idx2char)\n",
        "print(char2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nmzxEjLNaVZ",
        "outputId": "d54702f9-4973-4b2c-b8fa-877660be3290"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', ' ', ',', '.', 'A', 'I', 'T', 'W', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
            "{0: '', 1: ' ', 2: ',', 3: '.', 4: 'A', 5: 'I', 6: 'T', 7: 'W', 8: 'a', 9: 'b', 10: 'c', 11: 'd', 12: 'e', 13: 'g', 14: 'h', 15: 'i', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'y'}\n",
            "{'': 0, ' ': 1, ',': 2, '.': 3, 'A': 4, 'I': 5, 'T': 6, 'W': 7, 'a': 8, 'b': 9, 'c': 10, 'd': 11, 'e': 12, 'g': 13, 'h': 14, 'i': 15, 'k': 16, 'l': 17, 'm': 18, 'n': 19, 'o': 20, 'p': 21, 'q': 22, 'r': 23, 's': 24, 't': 25, 'u': 26, 'v': 27, 'w': 28, 'y': 29}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting sequence of tokens to sequence of indices\n",
        "x_data = list(map(lambda sentence : [char2idx.get(char) for char in sentence], sentences))\n",
        "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
        "\n",
        "print(x_data)\n",
        "print(x_data_len)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkNuaygkNhLB",
        "outputId": "a79c2740-69a6-4405-a0f3-b2d63af7a669"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7, 14, 8, 25, 1, 5, 1, 10, 8, 19, 19, 20, 25, 1, 10, 23, 12, 8, 25, 12, 2, 1, 5, 1, 11, 20, 1, 19, 20, 25, 1, 26, 19, 11, 12, 23, 24, 25, 8, 19, 11, 3], [5, 19, 25, 12, 17, 17, 12, 10, 26, 8, 17, 24, 1, 24, 20, 17, 27, 12, 1, 21, 23, 20, 9, 17, 12, 18, 24, 2, 1, 13, 12, 19, 15, 26, 24, 12, 24, 1, 21, 23, 12, 27, 12, 19, 25, 1, 25, 14, 12, 18], [4, 1, 21, 12, 23, 24, 20, 19, 1, 28, 14, 20, 1, 19, 12, 27, 12, 23, 1, 18, 8, 11, 12, 1, 8, 1, 18, 15, 24, 25, 8, 16, 12, 1, 19, 12, 27, 12, 23, 1, 25, 15, 12, 11, 1, 8, 19, 29, 25, 14, 15, 19, 13, 1, 19, 12, 28, 3], [6, 14, 12, 1, 24, 8, 18, 12, 1, 12, 22, 26, 8, 25, 15, 20, 19, 24, 1, 14, 8, 27, 12, 1, 25, 14, 12, 1, 24, 8, 18, 12, 1, 24, 20, 17, 26, 25, 15, 20, 19, 24, 3]]\n",
            "[42, 50, 58, 43]\n",
            "[1, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding the sequence of indices\n",
        "max_sequence = 55\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence,\n",
        "                       padding = 'post', truncating = 'post')\n",
        "\n",
        "# checking data\n",
        "print(x_data)\n",
        "print(x_data_len)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66JNR3FXNigv",
        "outputId": "5ae7426a-1a89-43b7-c069-17ce06dc63dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 14  8 25  1  5  1 10  8 19 19 20 25  1 10 23 12  8 25 12  2  1  5  1\n",
            "  11 20  1 19 20 25  1 26 19 11 12 23 24 25  8 19 11  3  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 5 19 25 12 17 17 12 10 26  8 17 24  1 24 20 17 27 12  1 21 23 20  9 17\n",
            "  12 18 24  2  1 13 12 19 15 26 24 12 24  1 21 23 12 27 12 19 25  1 25 14\n",
            "  12 18  0  0  0  0  0]\n",
            " [ 4  1 21 12 23 24 20 19  1 28 14 20  1 19 12 27 12 23  1 18  8 11 12  1\n",
            "   8  1 18 15 24 25  8 16 12  1 19 12 27 12 23  1 25 15 12 11  1  8 19 29\n",
            "  25 14 15 19 13  1 19]\n",
            " [ 6 14 12  1 24  8 18 12  1 12 22 26  8 25 15 20 19 24  1 14  8 27 12  1\n",
            "  25 14 12  1 24  8 18 12  1 24 20 17 26 25 15 20 19 24  3  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]]\n",
            "[42, 50, 58, 43]\n",
            "[1, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model"
      ],
      "metadata": {
        "id": "EG9-K6myNkjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating stacked rnn for \"many to one\" classification with dropout\n",
        "num_classes = 2\n",
        "hidden_dims = [10,10]\n",
        "\n",
        "input_dim = len(char2idx)\n",
        "output_dim = len(char2idx)\n",
        "one_hot = np.eye(len(char2idx))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
        "                           trainable=False, mask_zero=True, input_length=max_sequence,\n",
        "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
        "model.add(layers.SimpleRNN(units=hidden_dims[0], return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dropout(rate = .2)))\n",
        "model.add(layers.SimpleRNN(units=hidden_dims[1]))\n",
        "model.add(layers.Dropout(rate = .2))\n",
        "model.add(layers.Dense(units=num_classes))"
      ],
      "metadata": {
        "id": "95UbWo7DNl6i"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_8gvfthNntL",
        "outputId": "c10b24d8-4087-4c5f-8f1a-61668a6d6b0a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 55, 30)            900       \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 55, 10)            410       \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 55, 10)           0         \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 10)                210       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,542\n",
            "Trainable params: 642\n",
            "Non-trainable params: 900\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating loss function\n",
        "def loss_fn(model, x, y, training):    \n",
        "    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x, training), from_logits=True))\n",
        "\n",
        "# creating and optimizer\n",
        "lr = .01\n",
        "epochs = 30\n",
        "batch_size = 2\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
      ],
      "metadata": {
        "id": "Hq-BORGONpmG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating data pipeline\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
        "tr_dataset = tr_dataset.batch(batch_size=batch_size)\n",
        "\n",
        "print(tr_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fNZy26RNrF9",
        "outputId": "ded8301d-3bc8-40f6-cc94-1fa2ef84e067"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 55), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "tr_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "    \n",
        "    for x_mb, y_mb in tr_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, training=True)\n",
        "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
        "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    else:\n",
        "        avg_tr_loss /= tr_step\n",
        "        tr_loss_hist.append(avg_tr_loss)\n",
        "    \n",
        "    if (epoch + 1) % 5 ==0:\n",
        "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4j7V0YINtes",
        "outputId": "10ce5447-6871-4243-824f-0c1913bb46da"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   5, tr_loss : 0.145\n",
            "epoch :  10, tr_loss : 0.024\n",
            "epoch :  15, tr_loss : 0.015\n",
            "epoch :  20, tr_loss : 0.017\n",
            "epoch :  25, tr_loss : 0.004\n",
            "epoch :  30, tr_loss : 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking performance"
      ],
      "metadata": {
        "id": "sQT32I33NuqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(x_data)\n",
        "yhat = np.argmax(yhat, axis=-1)\n",
        "print('accuracy : {:.2%}'.format(np.mean(yhat == y_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB0h0UhhNwZJ",
        "outputId": "6933bdbe-0b91-4af1-dbce-2c8a3c72f332"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 366ms/step\n",
            "accuracy : 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tr_loss_hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FLl2bBu9NyAi",
        "outputId": "dc734f12-2702-4e9e-fec8-8b1b991ea6d1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cdb58b950>]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeBUlEQVR4nO3deXRcZ53m8e+vqrRVabEllRzLtmRLVvbFiU02SMiEpQ3DJDAEEtOkm3OaBMKEQ0MPB3pmCHSAGZo0NDQJS1gaSA+EsExwg5k0TcyQzSFO4pA4jmNZllfZ2myt1lJV7/xRJUdWtJTkkq/uredzjk7duvWq9Lu+yaNX733rveacQ0REgiHkdQEiIpI7CnURkQBRqIuIBIhCXUQkQBTqIiIBEvHqB1dXV7uVK1d69eNFRHzp6aef7nTOxad63bNQX7lyJVu3bvXqx4uI+JKZ7Z3udQ2/iIgEiEJdRCRAFOoiIgGiUBcRCRCFuohIgCjURUQCRKEuIhIgns1Tn6unWrt5dFcnZcURSosilGYey4ojxIoy20UFxIrCRML6nSUi+cV3of7M3qN89Xe7smobLQzz2evP551rl89zVSIiC4PvQv0Dr2/k/Vc1MDCSoH8oQf9wgr6hBAPD6e3+oQR9mccfPtHK5p3tCnURyRtZhbqZrQe+CoSB7zjnvjDh9TrgB8CiTJtPOuc25bjWE8Iho7y4gPLigmnbPXfgGM3t/fNVhojIgjPjoLOZhYF7gLcA5wIbzOzcCc3+B/CAc+5i4Cbg67kudC6aakpp6RwgmdIt+0QkP2RzJfFSoNk51+KcGwHuB66f0MYB5ZntCuBQ7kqcu8aaUkYSKfZ3D3pdiojIaZFNqC8D9o97fiCzb7zPAO81swPAJuDDk72Rmd1qZlvNbGtHR8ccyp2d1TWlAOzSEIyI5IlczfnbAHzfObcceCtwn5m96r2dc/c659Y559bF41MuB5wzY6GucXURyRfZhPpBYMW458sz+8b7K+ABAOfcE0AxUJ2LAk9FeXEBS8qLFOoikjeyCfWngCYzW2VmhaQvhG6c0GYf8AYAMzuHdKjP//hKFlbXlNLc3ud1GSIip8WMoe6cSwC3Aw8BO0jPctluZnea2XWZZn8D3GJmzwE/Bt7nnFsQU06aasrY3THAAilHRGReZTVPPTPnfNOEfXeM234ReG1uS8uNxppS+ocTHO4dYmlFidfliIjMq8AvjrI6npkBc0Tj6iISfIEP9aYlmgEjIvkj8KFeFStkUbSA5g6FuogEX+BD3cxYHS9VT11E8kLgQx3GpjUq1EUk+PIm1LsHRugeGPG6FBGReZU3oQ66WCoiwZdXob5LnywVkYDLi1CvrSghWhhWT11EAi8vQj0UMho1A0ZE8kBehDpoBoyI5Ie8CvW2niH6hxNelyIiMm/yKtQBdqu3LiIBlnehrlvbiUiQ5U2o11dGKQibxtVFJNDyJtQj4RCrqmMKdREJtLwJddCt7UQk+PIs1MvY1z3I0GjS61JEROZFnoV6KSkHrV0DXpciIjIv8ivUdWs7EQm4vAr1hniMkGm1RhEJrrwK9eKCMCsqo7q1nYgEVl6FOqSHYJo1/CIiAZV/oV5Typ7OARLJlNeliIjkXF6G+kgyxf6jx70uRUQk5/Iy1AF2HdGHkEQkePIu1BvH7leqi6UiEkB5F+rlxQWcUV6saY0iEkh5F+qguyCJSHDlbajvbu/HOed1KSIiOZW3oT4wkqStZ8jrUkREcipvQx10FyQRCZ68DnWNq4tI0ORlqFfFClkcLVCoi0jg5GWom5nugiQigZSXoQ6a1igiwZTHoV7G0cFRuvqHvS5FRCRn8jjUNQNGRIIn70NdQzAiEiR5G+q1FcXECsMKdREJlKxC3czWm9lOM2s2s09O0ebdZvaimW03sx/ltszcMzMadbFURAImMlMDMwsD9wBvAg4AT5nZRufci+PaNAF/C7zWOXfUzGrmq+BcWh0v5fHdXV6XISKSM9n01C8Fmp1zLc65EeB+4PoJbW4B7nHOHQVwzrXntsz50VhTyuHeIfqGRr0uRUQkJ7IJ9WXA/nHPD2T2jXcmcKaZPWZmW8xs/WRvZGa3mtlWM9va0dExt4pzqEkXS0UkYHJ1oTQCNAHXABuAb5vZoomNnHP3OufWOefWxePxHP3oudMMGBEJmmxC/SCwYtzz5Zl94x0ANjrnRp1ze4CXSYf8glZXGaUwHNKt7UQkMLIJ9aeAJjNbZWaFwE3AxgltHiTdS8fMqkkPx7TksM55EQmHWFUdo/mIQl1EgmHGUHfOJYDbgYeAHcADzrntZnanmV2XafYQ0GVmLwKbgY8753wxrWR1Tal66iISGDNOaQRwzm0CNk3Yd8e4bQd8LPPlK401pfzmhTaGRpMUF4S9LkdE5JTk7SdKxzTVlJJy0NIx4HUpIiKnLO9D/cQMGA3BiEgA5H2or6qOETJNaxSRYMj7UC8uCFNXGWW3Ql1EAiDvQx3SQzC7dGs7EQkAhTrpGTB7OgdIJFNelyIickoU6kBDdYzRpOPQsSGvSxEROSUKdaCuMgbA3m5NaxQRf1OoA/VVUQD2dg16XImIyKlRqANnlBdTGAmxr1uhLiL+plAHQiFjxeIS9nZp+EVE/E2hnlFfFdPwi4j4nkI9o74qyr7uQdJrk4mI+JNCPaO+MsrgSJLO/hGvSxERmTOFekZ9VXpa4z5NaxQRH1OoZ9RlpjW2dmpcXUT8S6GesXxxCWawV9MaRcTHFOoZRZEwtRUl7NO0RhHxMYX6OHWVUfXURcTXFOrj1FdF2ae56iLiYwr1ceqqonQNjNA/nPC6FBGROVGoj1M/tlqjxtVFxKcU6uOMrdaoIRgR8SuF+jhjc9V1sVRE/EqhPk55cQGVsUIt7CUivqVQn6CuMqqlAkTEtxTqE9RXRdVTFxHfUqhPUF8Z5dCx44wkUl6XIiIyawr1CeqqYqQcHDiq3rqI+I9CfYJ6zYARER9TqE9QX6m56iLiXwr1CeJlRZQUhHWxVER8SaE+gZlpWqOI+JZCfRJ1mtYoIj6lUJ9EfWWUfd2DpFLO61JERGZFoT6J+qoow4kU7X3DXpciIjIrCvVJ1FdpCV4R8SeF+iQ0V11E/EqhPonaRSWEQ6a56iLiO1mFupmtN7OdZtZsZp+cpt07zcyZ2brclXj6FYRDLFtUop66iPjOjKFuZmHgHuAtwLnABjM7d5J2ZcBHgCdzXaQX0jeh1pi6iPhLNj31S4Fm51yLc24EuB+4fpJ2nwX+HhjKYX2eqauM0qrhFxHxmWxCfRmwf9zzA5l9J5jZJcAK59yvp3sjM7vVzLaa2daOjo5ZF3s61VdF6Tk+Ss/gqNeliIhk7ZQvlJpZCPgy8DcztXXO3eucW+ecWxePx0/1R8+rusrMtEYtFyAiPpJNqB8EVox7vjyzb0wZcD7wezNrBS4HNvr9YumJaY0aghERH8km1J8CmsxslZkVAjcBG8dedM71OOeqnXMrnXMrgS3Adc65rfNS8WlSN7YEr2bAiIiPzBjqzrkEcDvwELADeMA5t93M7jSz6+a7QK/EiiJUlxbpU6Ui4iuRbBo55zYBmybsu2OKttecelkLg25CLSJ+o0+UTmNstUYREb9QqE+jvirG4d4hhkaTXpciIpIVhfo06quiOAcHjqq3LiL+oFCfRp2mNYqIzyjUp1FfqVAXEX9RqE+jMlZIaVFEF0tFxDcU6tMws8zCXpqrLiL+oFCfQXoJXvXURcQfFOozqKuKsv/oIMmU87oUEZEZKdRnUF8ZYzTpaOs57nUpIiIzUqjPYGy1Rg3BiIgfKNRnMLZao+5XKiJ+oFCfQe2iEgrCprnqIuILCvUZhEPGisVR9ukOSCLiAwr1LNRpCV4R8QmFehbqK9Nz1Z3TtEYRWdgU6lmoq4rRN5zg6OCo16WIiExLoZ6FVxb20ri6iCxsCvUsnJirrmmNIrLAKdSzsEJL8IqITyjUs1BcEOaM8mKt1igiC55CPUt1Wq1RRHxAoZ6l+sqolgoQkQVPoZ6l+qooHX3DDI4kvC5FRGRKCvUs1VXFAM2AEZGFTaGeJd2EWkT8QKGepZVjPXWFuogsYAr1LFVEC6goKWCvVmsUkQVMoT4L9VqtUUQWOIX6LNRVRnWhVEQWNIX6LNRXRTl49DiJZMrrUkREJqVQn4X6yhiJlOPQsSGvSxERmZRCfRbqqsZuQq2LpSKyMCnUZ2FsCd5WXSwVkQVKoT4LS8qKKSuOsGV3l9eliIhMSqE+C6GQcfPl9Wx6oY1dR/q8LkdE5FUU6rP0/qsaKCkI87WHm70uRUTkVRTqs1QZK+QvrljJv/7pEM3t/V6XIyJyEoX6HNxy1apMb32X16WIiJwkq1A3s/VmttPMms3sk5O8/jEze9HM/mRmvzOz+tyXunBUlRZx8xX1/Otzh9jdod66iCwcM4a6mYWBe4C3AOcCG8zs3AnNngXWOecuBH4GfDHXhS40t17VQFEkzN0aWxeRBSSbnvqlQLNzrsU5NwLcD1w/voFzbrNzbmzy9hZgeW7LXHjGeuu/3HaQFvXWRWSByCbUlwH7xz0/kNk3lb8CfjPZC2Z2q5ltNbOtHR0d2Ve5QN1yVQOFkRB3b1ZvXUQWhpxeKDWz9wLrgLsme905d69zbp1zbl08Hs/lj/ZEvKyImy+v58FnD7KnU0sHiIj3sgn1g8CKcc+XZ/adxMzeCPx34Drn3HBuylv4br26Md1b19i6iCwA2YT6U0CTma0ys0LgJmDj+AZmdjHwLdKB3p77MheueFkRf35ZPQ9uO8jeLvXWRcRbM4a6cy4B3A48BOwAHnDObTezO83sukyzu4BS4Kdmts3MNk7xdoH0gdc3EAmZeusi4rlINo2cc5uATRP23TFu+405rstXasqKec9ldfzwib18+NqmE0v0ioicbvpEaY7c9vrGdG99sz5lKiLeUajnSE15MRsureMXzxxkv+5jKiIeUajn0G3XNBIKGfdo3rqIeEShnkNLyovZ8JoV/OzpA+qti4gnFOo59sFrGgmZ8fXf7/a6FBHJQwr1HFtaUcJNl67gp1v3c+Coeusicnop1OfBbeqti4hHFOrzYGlFCTe+ZgUPPLWfZ/Yd9bocEckjCvV58l/ffBa1i0r40L88Q0df3iyFIyIeU6jPk4poAd9871qODo7w4R8/QyKZ8rokEckDCvV5dG5tOf/zHRewpaWbux7a6XU5IpIHFOrz7J1rl3Pz5fV86w8tbHq+zetyRCTgFOqnwafedi4X1y3i4z99jub2Pq/LEZEAU6ifBoWREF//80soKQzzgfuepn844XVJIhJQCvXTZGlFCV/bcAmtXYN8/KfP4ZzzuiQRCSCF+ml0RWMVn1h/Fr954TDffqTF63JEJIAU6qfZLVc18NYLzuALv3mJx3d3el2OiASMQv00MzO+eMNFrKqO8eEfPUtbz3GvSxKRAFGoe6C0KMK3bl7L0GiS2/7lGYYTSa9LEpGAUKh7ZHVNGXe96yK27T/G5361w+tyRCQgFOoeeusFS/nA1Q3ct2Uv9z3R6nU5IhIAEa8LyHcf/7OzaG7v51O/3E7vUIIPXdOImXldloj4lHrqHouEQ3zz5rW8fU0tdz20k8/9egeplOawi8jcqKe+ABSEQ3z53WtYFC3ku4/u4ejACH9/w4UUhPU7V0RmR6G+QIRCxqf/07lUxQr50m9fpuf4KHe/J720gIhIttQVXEDMjA+/oYnPvv18Ht7Zzl9870l6jo96XZaI+IhCfQG6+fJ6vrbhYrbtP8aN33qC9t4hr0sSEZ9QqC9Qb7uwlu+97zXs6x7khm8+wd6uAa9LEhEfUKgvYFc1xfnRLZfTOzTKO7/xBC8e6vW6pKxs23+MHzzeqlk8Ih5QqC9wa1Ys4mcfvIKCsHHjvU+wpaXL65KmlEim+Oq/7+Kd33icT2/czid+/ieSCnaR00qzX3xgdU0ZP7vtSm7+7pPcdO8WVteUclVTNVefGefyVVULYobM/u5BPvqTbWzde5S3r6mldlEJX//9blIOvnjDhYRD+kCVyOmgUPeJZYtK+MVtV/LTrQf4w64OfvTkPv75sVYKwyFes2oxVzfFuaopzjlLy077J1IffPYgn3rwBQC+cuMa3n7xMgCKImH+8d9fxjnHXe+6SMEuchqYV3fgWbdundu6dasnPzsIhkaT/HFPN394uYNHdnWy80j63qfxsiKuWp3uxb/hnBrKigvmrYbeoVHuePAFHtx2iLX1i/nKjWtYURk9qc3dD+/iH/7tZa5fU8uX3nUREX2gSuSUmNnTzrl1U72unrpPFReEufrMOFefGQfgcM8Qj+zq4A+7Otm8s51fPHuQsqIIGy6r431XrqR2UUlOf/7W1m7++ifbaOsZ4mNvOpMPXdM4aWDffm0ToZDxxf+7k5SDf3y3gl1kPqmnHkCplOPZ/Uf5/uN72fR8Gwa87cKlvP+qBs5fVnFK751Ipvinh5u5++FdLFtcwlduvJi19Ytn/L5v/r/dfOE3L/EfL1zKV25coyUQROZIPfU8FAoZa+srWVtfySfWn8U/P9bK/X/cx4PbDnFlYxW3XN3ANWfGZz323to5wEcf2Maz+47xny9Zxt9dd17WwzsffH0jYTM+v2kHzjm+etPFCnaReaCeep7oOT7Kj/+4j+8/1srh3iHOXFLK+1/XwPUX11IUeWX2zHAiyf7uQVo6BtjTOfDKY+cAnf3DlBVH+Pw7LuC6i2rnVMd3Hmnhc7/ewfrzzuCfNlxMYST/gn1oNMnOw328fKSPhniMNSsW6yKyZG2mnrpCPc+MJFL86k+H+PYje9jR1ku8rIg3nlNDW88QezoH2N89yPip5dWlhayqjrGqOkZDvJTrLqo95fH57z26hzt/9SJvPncJd7/nkkAHe+/QKC8e6mX7oV62H+ph+8Femjv6T5q/vzhawDVn1fAfzq7h9U1xKqKzv7g9kkixqz39i6KuMsqFyxfpL6GAUqjLpJxzPNbcxb2PtPDsvqPUVUbTwV0dY1U8RkN1KSurY1SUzM/smR883sqnN27njecs4aNvaiKRdCRSjkQyRTLlGM1sp/c5EqkURZEQDfFSVlbF5vyLYGA4wfZDvTx/sIftB3vo6B+mpqyY2kXFnFFRTG1FyYnH8pLItENUzjmOjybpHhjh6MAo3YMjHBsc4cDR4+kAP9TL3q7BE+3jZUWcX1vOebUVnFdbTtOSUna09bH5pXY272zn6OAo4ZCxtn4x155dw7Vn19BUU/qqGoYT6Z7+Cwczx3Goh5fa+hhJpk60iRWGuXRVJa9dXc0VjVWcc0Y5oYD9NeCcY2/XIFtaunhyTzfb9h+jrjLK61ZX89rV1Zx9RlngjhlyFOpmth74KhAGvuOc+8KE14uAHwJrgS7gRudc63TvqVCX+55o5VO/3D7r7wuHjPrKKI01payuKWV1vPTEdmnRK5eJ+oZG2X6olxcO9vD8wR5eONhDS+cAY//J15QVsbSimPa+YY70DjHxw68lBWGWLipmaUUxS8qLGUmkODqYDvCjgyN0D4wwnEgxmRWVJZyfCe/zlqUfa8qKpzymZMqxbf8xNr/Uzu9eamdHW3pJiGWLSrj27Boa4jFeauvj+YM9vHykj0Sm2PLiCOcvqzjxddaSMnZ39PP47k4eb+6ipTO9ZlBlrJArGqq4cnUVVzZWs7Iq6rs7bDnn2NM5wJN7utnS0sWWli6O9A4D6b8o16xYzJ7OfnZ3pI+5KlbIFY1VJ0J+4nRbvzrlUDezMPAy8CbgAPAUsME59+K4Nh8CLnTOfdDMbgLe4Zy7cbr3VagLwHP7j3G4d4hIyIiEQ+nH8dthIxIKEQkbx0eS7O7op7n9la/WrgFGk6/8N3xGeTGrqmMc7k0PJ43fnw6+ci5YVsEFyyqoKX8lZBPJFB39wxw6NsThniHaeo7TNu7xSM8QRQVhFkcLqIwVsjhayOLMY2WsIPOY3hcvK6L8FD8f0NZznM0vdfDwS+081tzJ8dEki6MFJ8L7gmUVnF9bwYrKkmnDua3nOI83d/FYJuQPZ1b8rK1I/3sUhEOEQkbIIGyGmREOQcjspP2JlGM0mWI06RhJphhNpE7sG0mkTrwWChnx0vS/Qby0iHhZEdWZx7GvaOGr52ckU+m/egZHEgwOJxkcSXJ8NMHgSJJ93YM82ZIO8va+dIjHy4q4bFUllzdUcXlDFY3x2Il/h7ae4zzW3MXjzZ082tx54nvqKqO8dnU1r1tdzXm15ZhByqV/WaR/Rzqcy+zLbDsHhRGjKBKmMBKiKBI6sT3ZdZBEMkXXwAjtvcO09w3R3jd88nbfMB29Q3x8/Vm84+Llc/pvIxehfgXwGefcn2We/y2Ac+5/jWvzUKbNE2YWAQ4DcTfNmyvUJRdGkyn2dQ+eCPnd7f20dA5QU1b0SvgtqyBeVuR1qXM2NJrk2OAoS8qLTql3PdbTfWx3OvCa2/tJuXR4JZ0j5RypFKScI5lKB10qsz8SMgrCoczXq7cLI+nno8kUnf0jdPQN0zUwzGQJECsMU1VadFKQD41O/hfPmJqyIi5vqOKyhnSQN1THsvq3cM6xu6OfR3d18mhzunffP5yY6z/hSSIhS4d8QZjCcIhEyk15zIujBdSUFVNTnv7FdsPa5VzZWD2nn5uLUL8BWO+ce3/m+c3AZc6528e1eSHT5kDm+e5Mm86p3lehLhJsiWSK7sF0wHf0DZ8I+7HAD4eMaGGYaGEk8ximpDBCtCBMrCizXRgmXlpEfY6GixLJFM8d6KG1cwAzMEv/VQLpm9SEDAzL7E9/z2jSMZxIMZxIMpJIpbdHJzxPJAmZUVNWRLy8mJqyovRXeTHVpYUnzTA7VQtqnrqZ3QrcClBXV3c6f7SInGaRcCjdO53mWsLpFgmHWFu/OKsPzPlVNlMIDgIrxj1fntk3aZvM8EsF6QumJ3HO3eucW+ecWxePx+dWsYiITCmbUH8KaDKzVWZWCNwEbJzQZiPwl5ntG4CHpxtPFxGR+THj8ItzLmFmtwMPkZ7S+D3n3HYzuxPY6pzbCHwXuM/MmoFu0sEvIiKnWVZj6s65TcCmCfvuGLc9BLwrt6WJiMhs6XPEIiIBolAXEQkQhbqISIAo1EVEAsSzVRrNrAPYO8dvrwam/LSqTwXtmIJ2PBC8Ywra8UDwjmmy46l3zk35QR/PQv1UmNnW6T4m60dBO6agHQ8E75iCdjwQvGOay/Fo+EVEJEAU6iIiAeLXUL/X6wLmQdCOKWjHA8E7pqAdDwTvmGZ9PL4cUxcRkcn5tacuIiKTUKiLiASI70LdzNab2U4zazazT3pdz6kys1Yze97MtpmZL28FZWbfM7P2zB2wxvZVmtlvzWxX5tE3dyWY4ng+Y2YHM+dpm5m91csaZ8vMVpjZZjN70cy2m9lHMvt9eZ6mOR7fniczKzazP5rZc5lj+rvM/lVm9mQm836SWQJ96vfx05h6NjfB9hszawXWTXfrv4XOzK4G+oEfOufOz+z7ItDtnPtC5pfvYufcJ7ysM1tTHM9ngH7n3D94WdtcmdlSYKlz7hkzKwOeBt4OvA8fnqdpjufd+PQ8Wfp+fTHnXL+ZFQCPAh8BPgb8wjl3v5l9E3jOOfeNqd7Hbz31S4Fm51yLc24EuB+43uOa8p5z7g+k19Ef73rgB5ntH5D+H84XpjgeX3POtTnnnsls9wE7gGX49DxNczy+5dL6M08LMl8OuBb4WWb/jOfIb6G+DNg/7vkBfH4iSZ+0fzOzpzP3cA2KJc65tsz2YWCJl8XkyO1m9qfM8IwvhikmY2YrgYuBJwnAeZpwPODj82RmYTPbBrQDvwV2A8ecc4lMkxkzz2+hHkSvc85dArwF+C+ZP/0DJXNrQ/+M803uG0AjsAZoA77kbTlzY2alwM+Bv3bO9Y5/zY/naZLj8fV5cs4lnXNrSN8L+lLg7Nm+h99CPZubYPuKc+5g5rEd+D+kT2QQHMmMe46Nf7Z7XM8pcc4dyfwPlwK+jQ/PU2ac9ufA/3bO/SKz27fnabLjCcJ5AnDOHQM2A1cAi8xs7C51M2ae30I9m5tg+4aZxTIXeTCzGPBm4IXpv8s3xt+M/C+BX3pYyykbC76Md+Cz85S5CPddYIdz7svjXvLleZrqePx8nswsbmaLMtslpCeE7CAd7jdkms14jnw1+wUgM0XpK7xyE+zPe1zSnJlZA+neOaTvF/sjPx6Pmf0YuIb0MqFHgE8DDwIPAHWkl1h+t3POFxcfpziea0j/Se+AVuAD48aiFzwzex3wCPA8kMrs/m+kx6F9d56mOZ4N+PQ8mdmFpC+Ehkl3uB9wzt2ZyYn7gUrgWeC9zrnhKd/Hb6EuIiJT89vwi4iITEOhLiISIAp1EZEAUaiLiASIQl1EJEAU6iIiAaJQFxEJkP8PwGH/JxOryuQAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Many to many\n",
        "## What is \"many to many\"?\n",
        "- Sequence tagging\n",
        "  - tokenization > tagging\n",
        "  \n",
        "## Example: part of speech tagging\n",
        "### Preparing dataset"
      ],
      "metadata": {
        "id": "D1CxDvjGN547"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pprint import pprint\n",
        "%matplotlib inline\n",
        "\n",
        "# example data\n",
        "sentences = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "pos = [['pronoun', 'verb', 'adjective'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective'],\n",
        "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n",
        "\n",
        "# creating a token dictionary for word\n",
        "word_list = sum(sentences, [])\n",
        "word_list = sorted(set(word_list))\n",
        "word_list = [''] + word_list\n",
        "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
        "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
        "\n",
        "print(word2idx)\n",
        "print(idx2word)\n",
        "print(len(idx2word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U70ZR0BXOl3B",
        "outputId": "f672d01b-b66b-4ea3-80b0-5692e1b22bee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
            "{0: '', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a token dictionary for part of speech\n",
        "pos_list = sum(pos, [])\n",
        "pos_list = sorted(set(pos_list))\n",
        "pos_list = [''] + pos_list\n",
        "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
        "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
        "\n",
        "print(pos2idx)\n",
        "print(idx2pos)\n",
        "print(len(pos2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0KfeO8DOrSE",
        "outputId": "6f712590-58e7-4b75-9313-08b3b2871174"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
            "{0: '', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting sequence of tokens to sequence of indices\n",
        "max_sequence = 10\n",
        "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
        "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
        "\n",
        "# padding the sequence of indices\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence, padding='post')\n",
        "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
        "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
        "\n",
        "y_data = pad_sequences(sequences = y_data, maxlen = max_sequence, padding='post')\n",
        "\n",
        "# checking data\n",
        "print(x_data, x_data_len)\n",
        "print(x_data_mask)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06V5rGgCOshR",
        "outputId": "bc2ad4b5-4d26-4d60-bf3e-024624ef8035"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
            "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "[[6 7 1 0 0 0 0 0 0 0]\n",
            " [4 7 2 1 0 0 0 0 0 0]\n",
            " [4 7 3 4 5 1 4 0 0 0]\n",
            " [4 7 2 1 7 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model"
      ],
      "metadata": {
        "id": "scHsLjOiOA1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating rnn for \"many to many\" sequence tagging\n",
        "num_classes = len(pos2idx)\n",
        "hidden_dim = 10\n",
        "\n",
        "input_dim = len(word2idx)\n",
        "output_dim = len(word2idx)\n",
        "one_hot = np.eye(len(word2idx))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True,\n",
        "                           trainable=False, input_length=max_sequence,\n",
        "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
        "model.add(layers.SimpleRNN(units=hidden_dim, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(units=num_classes)))"
      ],
      "metadata": {
        "id": "NHz96foqOuGj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G44SvKPuOvIu",
        "outputId": "009b1eb9-6cfc-48df-e80c-efa02fb037ea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 10, 15)            225       \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, 10, 10)            260       \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 10, 8)            88        \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 573\n",
            "Trainable params: 348\n",
            "Non-trainable params: 225\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating loss function\n",
        "def loss_fn(model, x, y, x_len, max_sequence):\n",
        "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
        "    valid_time_step = tf.cast(x_len,dtype=tf.float32)    \n",
        "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True) * masking    \n",
        "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step    \n",
        "    sequence_loss = tf.reduce_mean(sequence_loss)    \n",
        "    return sequence_loss\n",
        "\n",
        "# creating and optimizer\n",
        "lr = 0.1\n",
        "epochs = 30\n",
        "batch_size = 2 \n",
        "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
      ],
      "metadata": {
        "id": "F6n2C1OcOwy_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating data pipeline\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
        "tr_dataset = tr_dataset.batch(batch_size = 2)\n",
        "\n",
        "print(tr_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF7LwFoFOxe-",
        "outputId": "c1315ad8-9cca-4773-ca64-138a985c1144"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "tr_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "    \n",
        "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
        "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
        "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    else:\n",
        "        avg_tr_loss /= tr_step\n",
        "        tr_loss_hist.append(avg_tr_loss)\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cCzVKBwOzIu",
        "outputId": "ae416455-b852-4b84-e9dd-12a15d8ad2ae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   5, tr_loss : 0.188\n",
            "epoch :  10, tr_loss : 0.015\n",
            "epoch :  15, tr_loss : 0.004\n",
            "epoch :  20, tr_loss : 0.002\n",
            "epoch :  25, tr_loss : 0.001\n",
            "epoch :  30, tr_loss : 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checing performance"
      ],
      "metadata": {
        "id": "ruLBEAq3O0Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(x_data)\n",
        "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
        "\n",
        "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
        "pprint(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPIT-Ud9O2-D",
        "outputId": "0c13cf9d-d00b-4f80-a992-b3fe6431a3d7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 250ms/step\n",
            "[['pronoun', 'verb', 'adjective', '', '', '', '', '', '', ''],\n",
            " ['noun', 'verb', 'adverb', 'adjective', '', '', '', '', '', ''],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '', '', ''],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb', '', '', '', '', '']]\n",
            "[['pronoun', 'verb', 'adjective'],\n",
            " ['noun', 'verb', 'adverb', 'adjective'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tr_loss_hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "dDhAGPwVO4tO",
        "outputId": "92efa69b-0fc6-47fc-ec35-b89514cc59ab"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cdc9bc290>]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Many to many bidirectional\n",
        "## What is \"bidirectional\"?\n",
        "- There is balance in the amount of information seen by the hidden states at different time steps\n",
        "\n",
        "## many to many bidirectional\n",
        "- weight*(forward rnn and backward rnn) + bias = output\n",
        "\n",
        "## Example: part of speech tagging\n",
        "### Prepairing dataset"
      ],
      "metadata": {
        "id": "a4sGhSeaO7dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pprint import pprint\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3uG7eEaQINM",
        "outputId": "355f08cc-9b86-49c7-802b-b124d84c74b3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example data\n",
        "sentences = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "pos = [['pronoun', 'verb', 'adjective'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective'],\n",
        "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
      ],
      "metadata": {
        "id": "nYMZNPjUQK1E"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a token dictionary for word\n",
        "word_list = sum(sentences, [])\n",
        "word_list = sorted(set(word_list))\n",
        "word_list = [''] + word_list\n",
        "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
        "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
        "\n",
        "print(word2idx)\n",
        "print(idx2word)\n",
        "print(len(idx2word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfhJULcjQNhw",
        "outputId": "d71cbc68-a890-4895-84a7-99686064f45b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
            "{0: '', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a token dictionary for part of speech\n",
        "pos_list = sum(pos, [])\n",
        "pos_list = sorted(set(pos_list))\n",
        "pos_list = [''] + pos_list\n",
        "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
        "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
        "\n",
        "print(pos2idx)\n",
        "print(idx2pos)\n",
        "print(len(pos2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ywF7K2KQPGi",
        "outputId": "ea5aa4d3-0546-4f42-8cfd-2b718c9ddddd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
            "{0: '', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting sequence of tokens to sequence of indices\n",
        "max_sequence = 10\n",
        "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
        "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
        "\n",
        "# padding the sequence of indices\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence, padding='post')\n",
        "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
        "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
        "\n",
        "y_data = pad_sequences(sequences = y_data, maxlen = max_sequence, padding='post')\n",
        "\n",
        "# checking data\n",
        "print(x_data, x_data_len)\n",
        "print(x_data_mask)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2K9vnM7QQYK",
        "outputId": "8333d18e-65be-4b3b-c9ba-9c7e2a714f86"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
            "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "[[6 7 1 0 0 0 0 0 0 0]\n",
            " [4 7 2 1 0 0 0 0 0 0]\n",
            " [4 7 3 4 5 1 4 0 0 0]\n",
            " [4 7 2 1 7 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model"
      ],
      "metadata": {
        "id": "Nn46dStGQRks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating bidirectional rnn for \"many to many\" sequence tagging\n",
        "num_classes = len(pos2idx)\n",
        "hidden_dim = 10\n",
        "\n",
        "input_dim = len(word2idx)\n",
        "output_dim = len(word2idx)\n",
        "one_hot = np.eye(len(word2idx))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.InputLayer(input_shape=(max_sequence,)))\n",
        "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True,\n",
        "                                 trainable=False, input_length=max_sequence,\n",
        "                                 embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
        "model.add(layers.Bidirectional(keras.layers.SimpleRNN(units=hidden_dim, return_sequences=True)))\n",
        "model.add(layers.TimeDistributed(keras.layers.Dense(units=num_classes)))"
      ],
      "metadata": {
        "id": "ZIatRAXNQTCp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpEvzlLZQUvM",
        "outputId": "cca2322d-7443-4aa3-e332-e7ffe6fb9137"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 10, 15)            225       \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 10, 20)           520       \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 10, 8)            168       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 913\n",
            "Trainable params: 688\n",
            "Non-trainable params: 225\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating loss function\n",
        "def loss_fn(model, x, y, x_len, max_sequence):\n",
        "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
        "    valid_time_step = tf.cast(x_len,dtype=tf.float32)\n",
        "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True) * masking    \n",
        "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
        "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
        "    return sequence_loss\n",
        "\n",
        "# creating and optimizer\n",
        "lr = 0.1\n",
        "epochs = 30\n",
        "batch_size = 2 \n",
        "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
      ],
      "metadata": {
        "id": "lman5rBaQV5n"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating data pipeline\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
        "tr_dataset = tr_dataset.batch(batch_size = 2)\n",
        "\n",
        "print(tr_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2YvBUBSQWv_",
        "outputId": "aea341c9-04cb-4023-b0ae-83f6af48f6e6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "tr_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "    \n",
        "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
        "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
        "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    else:\n",
        "        avg_tr_loss /= tr_step\n",
        "        tr_loss_hist.append(avg_tr_loss)\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vR5s67MQX1v",
        "outputId": "ee6a3489-a9dc-42ae-eda7-689bc7644bf0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   5, tr_loss : 0.019\n",
            "epoch :  10, tr_loss : 0.001\n",
            "epoch :  15, tr_loss : 0.000\n",
            "epoch :  20, tr_loss : 0.000\n",
            "epoch :  25, tr_loss : 0.000\n",
            "epoch :  30, tr_loss : 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking performance"
      ],
      "metadata": {
        "id": "0AFi8BZmQYrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(x_data)\n",
        "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
        "\n",
        "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
        "pprint(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_n8Ue1aQbOz",
        "outputId": "94995807-bb06-4e57-85c9-ed53b2fe8383"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 423ms/step\n",
            "[['pronoun', 'verb', 'adjective', '', '', '', '', '', '', ''],\n",
            " ['noun', 'verb', 'adverb', 'adjective', '', '', '', '', '', ''],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '', '', ''],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb', '', '', '', '', '']]\n",
            "[['pronoun', 'verb', 'adjective'],\n",
            " ['noun', 'verb', 'adverb', 'adjective'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tr_loss_hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "sOPElOw-Qcar",
        "outputId": "fa4a4e38-2f52-4a5d-e7d2-b58f66925377"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7cdbf52c50>]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq to seq\n",
        "## Seq2seq overview \n",
        "### Chatbot Example\n",
        "### Encoder - Decoder\n",
        "\n",
        "## Data Pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "TqtZ-2-GQe13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import font_manager, rc\n",
        "\n",
        "rc('font', family='AppleGothic') #for mac\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2x2w8xURi2Q",
        "outputId": "7beef978-aaad-493a-8108-b9a0412bb9e6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sources = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "targets = [['나는', '배가', '고프다'],\n",
        "           ['텐서플로우는', '매우', '어렵다'],\n",
        "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
        "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
      ],
      "metadata": {
        "id": "QnQHd8mARl8A"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary for sources\n",
        "s_vocab = list(set(sum(sources, [])))\n",
        "s_vocab.sort()\n",
        "s_vocab = [''] + s_vocab\n",
        "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
        "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
        "\n",
        "pprint(source2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkQaXuHHRnuO",
        "outputId": "dd03e0d2-3b0e-489c-ec44-8604ea271a83"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0,\n",
            " 'I': 1,\n",
            " 'a': 2,\n",
            " 'changing': 3,\n",
            " 'deep': 4,\n",
            " 'difficult': 5,\n",
            " 'fast': 6,\n",
            " 'feel': 7,\n",
            " 'for': 8,\n",
            " 'framework': 9,\n",
            " 'hungry': 10,\n",
            " 'is': 11,\n",
            " 'learning': 12,\n",
            " 'tensorflow': 13,\n",
            " 'very': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary for targets\n",
        "t_vocab = list(set(sum(targets, [])))\n",
        "t_vocab.sort()\n",
        "t_vocab = ['', '', ''] + t_vocab\n",
        "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
        "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
        "\n",
        "pprint(target2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lyrte0DRpJe",
        "outputId": "f2924df6-a64f-440e-e210-3e15a6e806f3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 2,\n",
            " '고프다': 3,\n",
            " '나는': 4,\n",
            " '딥러닝을': 5,\n",
            " '매우': 6,\n",
            " '배가': 7,\n",
            " '변화한다': 8,\n",
            " '빠르게': 9,\n",
            " '어렵다': 10,\n",
            " '위한': 11,\n",
            " '텐서플로우는': 12,\n",
            " '프레임워크이다': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
        "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
        "    \n",
        "    if mode == 'source':\n",
        "        # preprocessing for source (encoder)\n",
        "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
        "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
        "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        return s_len, s_input\n",
        "    \n",
        "    elif mode == 'target':\n",
        "        # preprocessing for target (decoder)\n",
        "        # input\n",
        "        t_input = list(map(lambda sentence : [''] + sentence + [''], sequences))\n",
        "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
        "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
        "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        \n",
        "        # output\n",
        "        t_output = list(map(lambda sentence : sentence + [''], sequences))\n",
        "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
        "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        \n",
        "        return t_len, t_input, t_output"
      ],
      "metadata": {
        "id": "1T7CwfZPRqhI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for source\n",
        "s_max_len = 10\n",
        "s_len, s_input = preprocess(sequences = sources,\n",
        "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
        "print(s_len, s_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSvi8y9zRt1W",
        "outputId": "05498750-abb1-438e-a703-63efe7186fd1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for target\n",
        "t_max_len = 12\n",
        "t_len, t_input, t_output = preprocess(sequences = targets,\n",
        "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
        "print(t_len, t_input, t_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gi_SKwiRu9p",
        "outputId": "3a64048a-c181-4642-c8b3-b5a94a6e7a6c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 5, 6, 6] [[ 2  4  7  3  2  0  0  0  0  0  0  0]\n",
            " [ 2 12  6 10  2  0  0  0  0  0  0  0]\n",
            " [ 2 12  5 11 13  2  0  0  0  0  0  0]\n",
            " [ 2 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
            " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
            " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
            " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder - Decoder\n"
      ],
      "metadata": {
        "id": "BDltniV5R9O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters\n",
        "epochs = 200\n",
        "batch_size = 4\n",
        "learning_rate = .005\n",
        "total_step = epochs / batch_size\n",
        "buffer_size = 100\n",
        "n_batch = buffer_size//batch_size\n",
        "embedding_dim = 32\n",
        "units = 32\n",
        "\n",
        "# input\n",
        "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
        "data = data.shuffle(buffer_size = buffer_size)\n",
        "data = data.batch(batch_size = batch_size)\n",
        "# s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
      ],
      "metadata": {
        "id": "o3tLibD7SBGh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gru(units):\n",
        "    return tf.keras.layers.GRU(units, \n",
        "                               return_sequences=True, \n",
        "                               return_state=True, \n",
        "                               recurrent_initializer='glorot_uniform')"
      ],
      "metadata": {
        "id": "-5use7KySC2Q"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "VnxXD6L6SD-B"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "                \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "metadata": {
        "id": "67hi1_jCSFkP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss & Optimizer\n"
      ],
      "metadata": {
        "id": "nevlxLdjR-xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
        "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "    \n",
        "#     print(\"real: {}\".format(real))\n",
        "#     print(\"pred: {}\".format(pred))\n",
        "#     print(\"mask: {}\".format(mask))\n",
        "#     print(\"loss: {}\".format(tf.reduce_mean(loss_)))\n",
        "    \n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "# creating optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# creating check point (Object-based saving)\n",
        "checkpoint_dir = './data_out/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                encoder=encoder,\n",
        "                                decoder=decoder)\n",
        "\n",
        "# create writer for tensorboard\n",
        "#summary_writer = tf.summary.create_file_writer(logdir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "uCHf4znnSSbU"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n"
      ],
      "metadata": {
        "id": "idX7J4RgR_m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
        "\n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "            dec_input = tf.expand_dims([target2idx['']] * batch_size, 1)\n",
        "            \n",
        "            #Teacher Forcing: feeding the target as the next input\n",
        "            for t in range(1, t_input.shape[1]):\n",
        "                \n",
        "                predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
        "                \n",
        "                loss += loss_function(t_input[:, t], predictions)\n",
        "            \n",
        "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
        "                \n",
        "        batch_loss = (loss / int(t_input.shape[1]))\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "        gradient = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradient, variables))\n",
        "        \n",
        "    if epoch % 10 == 0:\n",
        "        #save model every 10 epoch\n",
        "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch,\n",
        "                                            total_loss / n_batch,\n",
        "                                            batch_loss.numpy()))\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "JGevMp0CSXso",
        "outputId": "51f5acd1-b0cd-463d-d7db-9016ed4cedfc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-c1337ea7e7e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#using teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-986874e1d6bb>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(real, pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     print(\"real: {}\".format(real))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7164\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 12 which is outside the valid range of [0, 12).  Label values: 12 4 12 12 [Op:SparseSoftmaxCrossEntropyWithLogits]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#restore checkpoint\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28qjmvAMSZe5",
        "outputId": "f60f8860-adf4-4888-c8f3-8144101f24c1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f7cd9cdf9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "HTBqvM0NSAc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'I feel hungry'"
      ],
      "metadata": {
        "id": "YYB3LhMuTQvq"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    \n",
        "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "        \n",
        "    result = ''\n",
        "    \n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "        \n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang['']], 0)\n",
        "    \n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += idx2target[predicted_id] + ' '\n",
        "\n",
        "        if idx2target.get(predicted_id) == '':\n",
        "            return result, sentence\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)    \n",
        "    \n",
        "    return result, sentence\n",
        "    \n",
        "result, output_sentence = prediction(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)\n",
        "\n",
        "print(sentence)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O90blW8ATSPO",
        "outputId": "9ee8f5a1-138e-4cbe-f9c6-0e652bccb6bf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I feel hungry\n",
            "배가  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq to seq with attention\n",
        "## Seq2Seq Attention Overview\n",
        "- focus more mo Important information\n",
        "\n"
      ],
      "metadata": {
        "id": "rFTq1FHxUmYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "### matplotlib 한글 폰트 설정 #############################\n",
        "from matplotlib import font_manager, rc\n",
        "## for window #####\n",
        "# font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
        "# rc('font', family=font_name)\n",
        "## for mac #####\n",
        "#rc('font', family='AppleGothic') #for mac\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on24JejNsMPq",
        "outputId": "6db682f7-57d6-4167-b7bf-858431265086"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sources = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "targets = [['나는', '배가', '고프다'],\n",
        "           ['텐서플로우는', '매우', '어렵다'],\n",
        "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
        "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
      ],
      "metadata": {
        "id": "NpUuPL9jsUrK"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary for sources\n",
        "s_vocab = list(set(sum(sources, [])))\n",
        "s_vocab.sort()\n",
        "s_vocab = [''] + s_vocab\n",
        "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
        "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
        "\n",
        "pprint(source2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oI0Z8KbsVpV",
        "outputId": "07b6cc42-2593-49b4-db85-b21ef02b7989"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0,\n",
            " 'I': 1,\n",
            " 'a': 2,\n",
            " 'changing': 3,\n",
            " 'deep': 4,\n",
            " 'difficult': 5,\n",
            " 'fast': 6,\n",
            " 'feel': 7,\n",
            " 'for': 8,\n",
            " 'framework': 9,\n",
            " 'hungry': 10,\n",
            " 'is': 11,\n",
            " 'learning': 12,\n",
            " 'tensorflow': 13,\n",
            " 'very': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary for targets\n",
        "t_vocab = list(set(sum(targets, [])))\n",
        "t_vocab.sort()\n",
        "t_vocab = ['', '', ''] + t_vocab\n",
        "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
        "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
        "\n",
        "pprint(target2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvTUzI0dsXB8",
        "outputId": "8e54f339-7689-4f79-fe19-467b0d977cb7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 2,\n",
            " '고프다': 3,\n",
            " '나는': 4,\n",
            " '딥러닝을': 5,\n",
            " '매우': 6,\n",
            " '배가': 7,\n",
            " '변화한다': 8,\n",
            " '빠르게': 9,\n",
            " '어렵다': 10,\n",
            " '위한': 11,\n",
            " '텐서플로우는': 12,\n",
            " '프레임워크이다': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
        "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
        "    \n",
        "    if mode == 'source':\n",
        "        # preprocessing for source (encoder)\n",
        "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
        "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
        "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        return s_len, s_input\n",
        "    \n",
        "    elif mode == 'target':\n",
        "        # preprocessing for target (decoder)\n",
        "        # input\n",
        "        t_input = list(map(lambda sentence : [''] + sentence + [''], sequences))\n",
        "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
        "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
        "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        \n",
        "        # output\n",
        "        t_output = list(map(lambda sentence : sentence + [''], sequences))\n",
        "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
        "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        \n",
        "        return t_len, t_input, t_output"
      ],
      "metadata": {
        "id": "Df4ls5ZFsYyg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for source\n",
        "s_max_len = 10\n",
        "s_len, s_input = preprocess(sequences = sources,\n",
        "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
        "print(s_len, s_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbmgZytAsZ27",
        "outputId": "12efa58b-c94b-40df-a466-82206c3840c5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for target\n",
        "t_max_len = 12\n",
        "t_len, t_input, t_output = preprocess(sequences = targets,\n",
        "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
        "print(t_len, t_input, t_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YnAvVQJsaxV",
        "outputId": "07b9968c-881c-48b7-f179-20d882077cdf"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 5, 6, 6] [[ 2  4  7  3  2  0  0  0  0  0  0  0]\n",
            " [ 2 12  6 10  2  0  0  0  0  0  0  0]\n",
            " [ 2 12  5 11 13  2  0  0  0  0  0  0]\n",
            " [ 2 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
            " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
            " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
            " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "z0X3q1VfsLu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "learning_rate = .005\n",
        "total_step = epochs / batch_size\n",
        "buffer_size = 100\n",
        "n_batch = buffer_size//batch_size\n",
        "embedding_dim = 32\n",
        "units = 128\n",
        "\n",
        "# input\n",
        "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
        "data = data.shuffle(buffer_size = buffer_size)\n",
        "data = data.batch(batch_size = batch_size)\n",
        "# s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
      ],
      "metadata": {
        "id": "1RESJ3FBscv7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gru(units):\n",
        "    return tf.keras.layers.GRU(units, \n",
        "                               return_sequences=True, \n",
        "                               return_state=True, \n",
        "                               recurrent_activation='sigmoid', \n",
        "                               recurrent_initializer='glorot_uniform')"
      ],
      "metadata": {
        "id": "PUuiC9Fzsdnm"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "#         print(\"state: {}\".format(state.shape))\n",
        "#         print(\"output: {}\".format(state.shape))\n",
        "              \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "TcJ97Edvse7z"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "rFjdFZ-KqfVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        # * `score = FC(tanh(FC(EO) + FC(H)))`\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "                \n",
        "        #* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, 1)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        # * `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        # * `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        # * `merged vector = concat(embedding output, context vector)`\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "metadata": {
        "id": "rHEoMQclsglW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
        "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "    \n",
        "#     print(\"real: {}\".format(real))\n",
        "#     print(\"pred: {}\".format(pred))\n",
        "#     print(\"mask: {}\".format(mask))\n",
        "#     print(\"loss: {}\".format(tf.reduce_mean(loss_)))\n",
        "    \n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "# creating optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# creating check point (Object-based saving)\n",
        "checkpoint_dir = './data_out/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                encoder=encoder,\n",
        "                                decoder=decoder)\n",
        "\n",
        "# create writer for tensorboard\n",
        "summary_writer = tf.summary.create_file_writer(logdir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "81QsLcyYsizH"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "y0QQ8XR_qhk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
        "            \n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "            dec_input = tf.expand_dims([target2idx['']] * batch_size, 1)\n",
        "            \n",
        "            #Teacher Forcing: feeding the target as the next input\n",
        "            for t in range(1, t_input.shape[1]):\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                \n",
        "                loss += loss_function(t_input[:, t], predictions)\n",
        "            \n",
        "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
        "                \n",
        "        batch_loss = (loss / int(t_input.shape[1]))\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "        gradient = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradient, variables))\n",
        "        \n",
        "    if epoch % 10 == 0:\n",
        "        #save model every 10 epoch\n",
        "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch,\n",
        "                                            total_loss / n_batch,\n",
        "                                            batch_loss.numpy()))\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "ST0GzuXSskoB",
        "outputId": "1c359704-3b72-4ebe-f688-39873b70a0d2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-98e916b1f04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#using teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-b2edbf019a14>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(real, pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     print(\"real: {}\".format(real))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7164\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 12 which is outside the valid range of [0, 12).  Label values: 4 12 12 12 [Op:SparseSoftmaxCrossEntropyWithLogits]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    \n",
        "#     sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang['']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weigths to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += idx2target[predicted_id] + ' '\n",
        "\n",
        "        if idx2target.get(predicted_id) == '':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot\n",
        "\n",
        "# result, sentence, attention_plot = evaluate(sentence, encoder, decoder, source2idx, target2idx,\n",
        "#                                             s_max_len, t_max_len)"
      ],
      "metadata": {
        "id": "zNfg10DIsn6k"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    \n",
        "    fontdict = {'fontsize': 14}\n",
        "    \n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mbPqMuQrspSQ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "        \n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "metadata": {
        "id": "SOYG20jVsqkH"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#restore checkpoint\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "id": "FhALcClNsrm1",
        "outputId": "4dbea354-edaf-4ee0-e7c5-a48c852330d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f7cd0959190>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "9xLRlo_Tqihm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'I feel hungry'\n",
        "# sentence = 'tensorflow is a framework for deep learning'\n",
        "\n",
        "translate(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)"
      ],
      "metadata": {
        "id": "jKq7aAKcssy_",
        "outputId": "9a0f537b-9068-4727-d587-48a6810b7e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['AppleGothic'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I feel hungry\n",
            "Predicted translation: 변화한다 위한 고프다 배가 매우 고프다 배가 매우 고프다 배가 매우 고프다 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48320 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54868 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54620 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50948 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54532 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48176 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44032 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47588 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50864 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48320 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54868 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54620 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50948 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54532 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48176 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44032 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47588 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50864 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}