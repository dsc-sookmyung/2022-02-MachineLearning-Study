{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b660443",
   "metadata": {},
   "source": [
    "lecture 12\n",
    "\n",
    "## RNN[Recurrent Neural Network]\n",
    "\n",
    "[]()\n",
    "\n",
    "배경\n",
    "\n",
    ": 하나의 x 입력에 대한 y출력의 간단한 형태였기 때문에 sequence data를 처리하기 어려웠음\n",
    "\n",
    "Sequence data에 유리함.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92504386/204217272-2c9833fc-4035-47cc-a4f3-bb3a2c94b7aa.png)\n",
    "\n",
    "\n",
    "vanilla RNN\n",
    "\n",
    "`wx` 에 기반\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92504386/204217361-b0031386-c034-45c7-9be8-5558df657deb.png)\n",
    "\n",
    "\n",
    "*tanh: sigmoid함수와 유사\n",
    "\n",
    "전체 cell에 weight 값이 동일하게 두고 학습, 출력 함\n",
    "\n",
    "character-level language model\n",
    "\n",
    ": 자연어에 character 부여 \n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92504386/204217443-09ba8eb8-1be1-471f-94e5-48e547abccec.png)\n",
    "\n",
    "하나씩 입력 charcter 부여\n",
    "\n",
    "h0, h1, h2, ht는 다음 입력값에 예측 값 (현재 글씨 다음에 올 글씨는 뭘까?)\n",
    "\n",
    "1. 캐릭터를 벡터로 표현하여 input layer로 넣음\n",
    "2. input layer에 W_xh 값을 곱해서 hidden layer 값을 만들고, W_hy를 곱해서 output layer Y를 구함.\n",
    "3. softmax를 취해서 target character를 찾아냄. \n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92504386/204217499-1da7e832-89d7-4c51-a9b2-817eb93e561b.png)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92504386/204217612-800fb045-a2cc-4b15-8ef5-9cc7cc6cc86e.png)\n",
    "\n",
    "rnn input :  batch size, sequance length , input dimension 으로 전처리\n",
    "\n",
    " 1. 각 character에 대한 one hot encoding vector를 생성 전처리\n",
    "\n",
    "1. outputs, states는 같은 값이지만 shape이 다름  = states 변는 마지막 값에 대한 hidden state 값만 가지기 때문.\n",
    "\n",
    "Unfolding to n sequence\n",
    "\n",
    "one to many\n",
    "\n",
    ": 특정이미지 입력으로 캡션을 생성하는 이미지 캡션 분야\n",
    "\n",
    "many to many\n",
    "\n",
    ": 문장을 입력으로 받아 문장을 출력으로 내어줌\n",
    "\n",
    ": 문장을 입력받아 형태소로 출력하는 형태소 분석 분야\n",
    "\n",
    "Many to One\n",
    "\n",
    ": 자연어처리분야에서 문장/ 단어를 를 rnn 인코딩 하고, 해당 문장 단어를 classification 해줌\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92504386/204217726-c4abea4b-c4a7-43ab-9d66-ed0a03f9dc3f.png)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92504386/204217808-42e29eab-4fca-4e8c-9e24-a94f367e3917.png)\n",
    "\n",
    "- sentence → word 단위로 tokenized\n",
    "    - sentence = word sequence 로 생각하고 문장을 워드단위로 분류 할 수 있음.\n",
    "    - rnn을 활용해 토큰을 읽고 마지막 토큰을 classification polarity함\n",
    "    - 토큰된 word는 숫자가 아니라서 rnn으로 처리 불가 → 토큰을 rnn이 처리할 수 있도록 numerical하게 만들어주는 `Embedding layer`가 필요함.\n",
    "    - rnn은 토큰을 순서대로 읽어들이고, 마지막 토큰을 읽었을 때 나온 출력값과 정답간의 loss를 구하고 이를 기반으로 back propagation 통해 RNN학습.\n",
    "\n",
    "Many to one stacking\n",
    "\n",
    "Rnn을 여러개 쌓음.\n",
    "\n",
    "output과 가까운 layer는 abstract한 구조로 출력 됨. \n",
    "\n",
    "stack구조\n",
    "\n",
    ": syntatic information을 정답값과 거의 비슷하게 출력\n",
    "\n",
    "rnn을 많이쌓는 stacking 방식 으로\n",
    "\n",
    "sequence를 각각 tokenzied → embedding layer → nurmeric 하게 표현된 token → stack rnn이 순서대로 읽어들여짐\n",
    "\n",
    "- 첫번째 rnn이 t번째 시점에 토큰과 t-1번째 시점의 hidden state를 받아서 t번째 시점의 hidden state 생성\n",
    "- 2번째 rnn 은 t번째 시점에 첫번째 rnn의 hidden stated와 t-1번째 시점의 두번째 rnn의 hidden state를 받아서 t번째 시점의 hidden state 생성\n",
    "- 마지막 토큰을 읽었을 때 나온 출력과 정답의 loss를 구하고 이를 stack RNN을 back propagation을 통해 구함.\n",
    "\n",
    "Many to many\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/92504386/204217874-1d36a5cd-8131-4bc0-bb9d-5e7bd5505bed.png)\n",
    "\n",
    "rnn이 sequence를 구성하고 있는 각 토큰에 대해서 모두 출력을 내어주는 구조\n",
    "\n",
    "토큰에 대한 출력을 내고 정답값과 비교해서 loss를 계산하고 모든 loss에 대한 평균 [’sequence loss’]를  계산하고 이를 back propagation 함. \n",
    "\n",
    "<pad> 토큰을 통해 sequence length batch를 맞춰줌. → masking을 통해 padding 토큰에 대해서는 loss를 계산하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77225646",
   "metadata": {},
   "source": [
    "# lab12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a07456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential, Model\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f463f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ffb1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [[[1. 0. 0. 0.]]], shape: (1, 1, 4)\n",
      "outputs: [[[-0.75423443  0.3285001 ]]], shape: (1, 1, 2)\n",
      "states: [[-0.75423443  0.3285001 ]], shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2)\n",
    "x_data = np.array([[h]], dtype=np.float32)\n",
    "\n",
    "hidden_size = 2\n",
    "cell = layers.SimpleRNNCell(units=hidden_size) # creating SimpleRNNCell\n",
    "rnn = layers.RNN(cell, return_sequences=True, return_state=True) # analogous to tf.nn.dynamic_rnn\n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print('x_data: {}, shape: {}'.format(x_data, x_data.shape))\n",
    "print('outputs: {}, shape: {}'.format(outputs, outputs.shape))\n",
    "print('states: {}, shape: {}'.format(states, states.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c485c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [[[1. 0. 0. 0.]]], shape: (1, 1, 4)\n",
      "outputs: [[[0.6872603 0.7430854]]], shape: (1, 1, 2)\n",
      "states: [[0.6872603 0.7430854]], shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# equivalent to above case\n",
    "rnn = layers.SimpleRNN(units=hidden_size, return_sequences=True,\n",
    "                       return_state=True) # layers.SimpleRNNCell + layers.RNN\n",
    "\n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print('x_data: {}, shape: {}'.format(x_data, x_data.shape))\n",
    "print('outputs: {}, shape: {}'.format(outputs, outputs.shape))\n",
    "print('states: {}, shape: {}'.format(states, states.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739d7750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]], shape: (1, 5, 4) \n",
      "\n",
      "outputs: [[[-0.46136624  0.06071173]\n",
      "  [-0.32597393 -0.86720127]\n",
      "  [ 0.7388328  -0.7791967 ]\n",
      "  [ 0.77606374  0.02152331]\n",
      "  [ 0.65971786  0.29234266]]], shape: (1, 5, 2) \n",
      "\n",
      "states: [[0.65971786 0.29234266]], shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "x_data = np.array([[h, e, l, l, o]], dtype=np.float32)\n",
    "\n",
    "hidden_size = 2\n",
    "rnn = layers.SimpleRNN(units=2, return_sequences=True, return_state=True)    \n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print('x_data: {}, shape: {} \\n'.format(x_data, x_data.shape))\n",
    "print('outputs: {}, shape: {} \\n'.format(outputs, outputs.shape))\n",
    "print('states: {}, shape: {}'.format(states, states.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54addd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]]], shape: (3, 5, 4) \n",
      "\n",
      "outputs: [[[ 0.6378954   0.7178065 ]\n",
      "  [ 0.10106888 -0.12103489]\n",
      "  [ 0.5804097  -0.03943233]\n",
      "  [ 0.78526497 -0.31111285]\n",
      "  [-0.3978624  -0.90642565]]\n",
      "\n",
      " [[-0.6948956  -0.17374128]\n",
      "  [-0.87811625 -0.34588373]\n",
      "  [-0.18469767  0.4591737 ]\n",
      "  [ 0.7028708   0.51705664]\n",
      "  [ 0.9121008  -0.01618229]]\n",
      "\n",
      " [[ 0.5899744   0.11702058]\n",
      "  [ 0.8263871  -0.21483234]\n",
      "  [-0.40275812 -0.7225461 ]\n",
      "  [-0.92936164 -0.3794995 ]\n",
      "  [-0.24192111  0.46908256]]], shape: (3, 5, 2) \n",
      "\n",
      "states: [[-0.3978624  -0.90642565]\n",
      " [ 0.9121008  -0.01618229]\n",
      " [-0.24192111  0.46908256]], shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "# 3 batches 'hello', 'eolll', 'lleel'\n",
    "x_data = np.array([[h, e, l, l, o],\n",
    "                   [e, o, l, l, l],\n",
    "                   [l, l, e, e, l]], dtype=np.float32)\n",
    "\n",
    "hidden_size = 2\n",
    "rnn = layers.SimpleRNN(units=2, return_sequences=True, return_state=True)    \n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print('x_data: {}, shape: {} \\n'.format(x_data, x_data.shape))\n",
    "print('outputs: {}, shape: {} \\n'.format(outputs, outputs.shape))\n",
    "print('states: {}, shape: {}'.format(states, states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c357b",
   "metadata": {},
   "source": [
    "# lab 12-1. word sentiment classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c514a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "106a87f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', ' ', 'a', 'b', 'd', 'e', 'g', 'o', 'r', 's', 'w']\n",
      "{0: '<pad>', 1: ' ', 2: 'a', 3: 'b', 4: 'd', 5: 'e', 6: 'g', 7: 'o', 8: 'r', 9: 's', 10: 'w'}\n",
      "{'<pad>': 0, ' ': 1, 'a': 2, 'b': 3, 'd': 4, 'e': 5, 'g': 6, 'o': 7, 'r': 8, 's': 9, 'w': 10}\n"
     ]
    }
   ],
   "source": [
    "# example data\n",
    "words = ['good', 'bad', 'worse', 'so good']\n",
    "y_data = [1,0,0,1]\n",
    "\n",
    "# creating a token dictionary\n",
    "# pad: word를 캐릭터의 sequence로 간주했을 대 각 sequence의 길이가 달라서 딥러닝에서의 batch  연산 시, rnn일 때 서로다른 sequence길이라면 이를 맞추기 위해 pad사용\n",
    "char_set = ['<pad>'] + sorted(list(set(''.join(words))))\n",
    "idx2char = {idx : char for idx, char in enumerate(char_set)}\n",
    "char2idx = {char : idx for idx, char in enumerate(char_set)}\n",
    "\n",
    "print(char_set)\n",
    "print(idx2char)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16d7e8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]\n",
      "[4, 3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "# converting sequence of tokens to sequence of indices\n",
    "x_data = list(map(lambda word : [char2idx.get(char) for char in word], words))\n",
    "x_data_len = list(map(lambda word : len(word), x_data))\n",
    "\n",
    "print(x_data)\n",
    "print(x_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3c1b162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7  7  4  0  0  0  0  0  0]\n",
      " [ 3  2  4  0  0  0  0  0  0  0]\n",
      " [10  7  8  9  5  0  0  0  0  0]\n",
      " [ 9  7  1  6  7  7  4  0  0  0]]\n",
      "[4, 3, 5, 7]\n",
      "[1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# padding the sequence of indices\n",
    "max_sequence = 10\n",
    "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence,\n",
    "                       padding = 'post', truncating = 'post')\n",
    "\n",
    "# checking data\n",
    "print(x_data)\n",
    "print(x_data_len)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c585750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "# creating simple rnn for \"many to one\" classification\n",
    "input_dim = len(char2idx)\n",
    "output_dim = len(char2idx)\n",
    "one_hot = np.eye(len(char2idx))\n",
    "hidden_size = 10\n",
    "num_classes = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
    "                           trainable=False, mask_zero=True, input_length=max_sequence,\n",
    "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_size))\n",
    "model.add(layers.Dense(units=num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3374add1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 11)            121       \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 10)                220       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 363\n",
      "Trainable params: 242\n",
      "Non-trainable params: 121\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b24bda71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "def loss_fn(model, x, y):\n",
    "    return tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=y, logits=model(x))\n",
    "\n",
    "# creating an optimizer\n",
    "lr = .01\n",
    "epochs = 30\n",
    "batch_size = 2\n",
    "opt = tf.compat.v1.train.AdamOptimizer(learning_rate = lr)\n",
    "\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size = 4)\n",
    "tr_dataset = tr_dataset.batch(batch_size = batch_size)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3573198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.090\n",
      "epoch :  10, tr_loss : 0.022\n",
      "epoch :  15, tr_loss : 0.009\n",
      "epoch :  20, tr_loss : 0.005\n",
      "epoch :  25, tr_loss : 0.004\n",
      "epoch :  30, tr_loss : 0.003\n"
     ]
    }
   ],
   "source": [
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 ==0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "025aa94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 934ms/step\n",
      "acc : 100.00%\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1)\n",
    "print('acc : {:.2%}'.format(np.mean(yhat == y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6198020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aae88aec10>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f82ba6",
   "metadata": {},
   "source": [
    "# lab 12-2. many to one stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b50cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee7e26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data\n",
    "sentences = ['What I cannot create, I do not understand.',\n",
    "             'Intellecuals solve problems, geniuses prevent them',\n",
    "             'A person who never made a mistake never tied anything new.',\n",
    "             'The same equations have the same solutions.']\n",
    "y_data = [1,0,0,1] # 1: richard feynman, 0: albert einstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1b55c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' ', ',', '.', 'A', 'I', 'T', 'W', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
      "{0: '', 1: ' ', 2: ',', 3: '.', 4: 'A', 5: 'I', 6: 'T', 7: 'W', 8: 'a', 9: 'b', 10: 'c', 11: 'd', 12: 'e', 13: 'g', 14: 'h', 15: 'i', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'y'}\n",
      "{'': 0, ' ': 1, ',': 2, '.': 3, 'A': 4, 'I': 5, 'T': 6, 'W': 7, 'a': 8, 'b': 9, 'c': 10, 'd': 11, 'e': 12, 'g': 13, 'h': 14, 'i': 15, 'k': 16, 'l': 17, 'm': 18, 'n': 19, 'o': 20, 'p': 21, 'q': 22, 'r': 23, 's': 24, 't': 25, 'u': 26, 'v': 27, 'w': 28, 'y': 29}\n"
     ]
    }
   ],
   "source": [
    "# creating a token dictionary\n",
    "char_set = [''] + sorted(list(set(''.join(sentences))))\n",
    "idx2char = {idx : char for idx, char in enumerate(char_set)}\n",
    "char2idx = {char : idx for idx, char in enumerate(char_set)}\n",
    "\n",
    "print(char_set)\n",
    "print(idx2char)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea70d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7  7  4  0  0  0  0  0  0]\n",
      " [ 3  2  4  0  0  0  0  0  0  0]\n",
      " [10  7  8  9  5  0  0  0  0  0]\n",
      " [ 9  7  1  6  7  7  4  0  0  0]]\n",
      "[4, 3, 5, 7]\n",
      "[1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "a_len = list(map(lambda sentence : len(sentence), sentences))\n",
    "\n",
    "print(x_data)\n",
    "print(x_data_len)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8276be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7  7  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 3  2  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [10  7  8  9  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 9  7  1  6  7  7  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]]\n",
      "[4, 3, 5, 7]\n",
      "[1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# padding the sequence of indices\n",
    "max_sequence = 55\n",
    "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence,\n",
    "                       padding = 'post', truncating = 'post')\n",
    "\n",
    "# checking data\n",
    "print(x_data)\n",
    "print(x_data_len)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a4de5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 55, 30)            900       \n",
      "                                                                 \n",
      " simple_rnn_6 (SimpleRNN)    (None, 55, 10)            410       \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 55, 10)           0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 10)                210       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,542\n",
      "Trainable params: 642\n",
      "Non-trainable params: 900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating stacked rnn for \"many to one\" classification with dropout\n",
    "num_classes = 2\n",
    "hidden_dims = [10,10]\n",
    "\n",
    "input_dim = len(char2idx)\n",
    "output_dim = len(char2idx)\n",
    "one_hot = np.eye(len(char2idx))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
    "                           trainable=False, mask_zero=True, input_length=max_sequence,\n",
    "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_dims[0], return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dropout(rate = .2)))\n",
    "model.add(layers.SimpleRNN(units=hidden_dims[1]))\n",
    "model.add(layers.Dropout(rate = .2))\n",
    "model.add(layers.Dense(units=num_classes))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b27e90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 55), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# creating loss function\n",
    "def loss_fn(model, x, y, training):\n",
    "    return tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=y, logits=model(x, training))\n",
    "\n",
    "# creating and optimizer\n",
    "lr = .01\n",
    "epochs = 30\n",
    "batch_size = 2\n",
    "opt = tf.compat.v1.train.AdamOptimizer(learning_rate = lr)\n",
    "\n",
    "# generating data pipeline\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
    "tr_dataset = tr_dataset.batch(batch_size=batch_size)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0d3a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.092\n",
      "epoch :  10, tr_loss : 0.039\n",
      "epoch :  15, tr_loss : 0.011\n",
      "epoch :  20, tr_loss : 0.005\n",
      "epoch :  25, tr_loss : 0.017\n",
      "epoch :  30, tr_loss : 0.009\n"
     ]
    }
   ],
   "source": [
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, training=True)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 ==0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e46534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "accuracy : 100.00%\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1)\n",
    "print('accuracy : {:.2%}'.format(np.mean(yhat == y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3b0d7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aaea387fd0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04116841",
   "metadata": {},
   "source": [
    "# lab12-3. many to many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5111c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b60b7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data\n",
    "sentences = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "pos = [['pronoun', 'verb', 'adjective'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective'],\n",
    "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6646c137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
      "{0: '', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "word_list = sum(sentences, [])\n",
    "word_list = sorted(set(word_list))\n",
    "word_list = [''] + word_list\n",
    "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
    "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
    "\n",
    "print(word2idx)\n",
    "print(idx2word)\n",
    "print(len(idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19b7233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
      "{0: '', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "pos_list = sum(pos, [])\n",
    "pos_list = sorted(set(pos_list))\n",
    "pos_list = [''] + pos_list\n",
    "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
    "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
    "\n",
    "print(pos2idx)\n",
    "print(idx2pos)\n",
    "print(len(pos2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c401c126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "[[6 7 1 0 0 0 0 0 0 0]\n",
      " [4 7 2 1 0 0 0 0 0 0]\n",
      " [4 7 3 4 5 1 4 0 0 0]\n",
      " [4 7 2 1 7 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# converting sequence of tokens to sequence of indices\n",
    "\n",
    "\n",
    "max_sequence = 10\n",
    "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
    "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
    "\n",
    "# padding the sequence of indices\n",
    "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence, padding='post')\n",
    "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
    "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
    "\n",
    "y_data = pad_sequences(sequences = y_data, maxlen = max_sequence, padding='post')\n",
    "\n",
    "# checking data\n",
    "print(x_data, x_data_len)\n",
    "print(x_data_mask)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d35e2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 10, 15)            225       \n",
      "                                                                 \n",
      " simple_rnn_8 (SimpleRNN)    (None, 10, 10)            260       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 10, 8)            88        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 573\n",
      "Trainable params: 348\n",
      "Non-trainable params: 225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating rnn for \"many to many\" sequence tagging\n",
    "\n",
    "\n",
    "num_classes = len(pos2idx)\n",
    "hidden_dim = 10\n",
    "\n",
    "input_dim = len(word2idx)\n",
    "output_dim = len(word2idx)\n",
    "one_hot = np.eye(len(word2idx))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True,\n",
    "                           trainable=False, input_length=max_sequence,\n",
    "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_dim, return_sequences=True))\n",
    "\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.Dense(units=num_classes)))\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec5cb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating loss function\n",
    "def loss_fn(model, x, y, x_len, max_sequence):\n",
    "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
    "    valid_time_step = tf.cast(x_len,dtype=tf.float32)\n",
    "    sequence_loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=y, logits=model(x),\n",
    "                                                           reduction='none') * masking\n",
    "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
    "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
    "    return sequence_loss\n",
    "\n",
    "# creating and optimizer\n",
    "lr = 0.1\n",
    "epochs = 30\n",
    "batch_size = 2 \n",
    "opt = tf.compat.v1.train.AdamOptimizer(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c905dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# generating data pipeline\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
    "tr_dataset = tr_dataset.batch(batch_size = 2)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d130bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.243\n",
      "epoch :  10, tr_loss : 0.016\n",
      "epoch :  15, tr_loss : 0.003\n",
      "epoch :  20, tr_loss : 0.001\n",
      "epoch :  25, tr_loss : 0.001\n",
      "epoch :  30, tr_loss : 0.001\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "682b5fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[['pronoun', 'verb', 'adjective', '', '', '', '', '', '', ''],\n",
      " ['noun', 'verb', 'adverb', 'adjective', '', '', '', '', '', ''],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '', '', ''],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb', '', '', '', '', '']]\n",
      "[['pronoun', 'verb', 'adjective'],\n",
      " ['noun', 'verb', 'adverb', 'adjective'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
    "\n",
    "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
    "pprint(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdea1132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aaea576790>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6c2a9",
   "metadata": {},
   "source": [
    "# lab 12-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d83e3613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "953b2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data\n",
    "sentences = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "pos = [['pronoun', 'verb', 'adjective'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective'],\n",
    "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4a6eb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
      "{0: '', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating a token dictionary for word\n",
    "word_list = sum(sentences, [])\n",
    "word_list = sorted(set(word_list))\n",
    "word_list = [''] + word_list\n",
    "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
    "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
    "\n",
    "print(word2idx)\n",
    "print(idx2word)\n",
    "print(len(idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11af58cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
      "{0: '', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating a token dictionary for part of speech\n",
    "pos_list = sum(pos, [])\n",
    "pos_list = sorted(set(pos_list))\n",
    "pos_list = [''] + pos_list\n",
    "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
    "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
    "\n",
    "print(pos2idx)\n",
    "print(idx2pos)\n",
    "print(len(pos2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "382ea8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "[[6 7 1 0 0 0 0 0 0 0]\n",
      " [4 7 2 1 0 0 0 0 0 0]\n",
      " [4 7 3 4 5 1 4 0 0 0]\n",
      " [4 7 2 1 7 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# converting sequence of tokens to sequence of indices\n",
    "max_sequence = 10\n",
    "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
    "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
    "\n",
    "# padding the sequence of indices\n",
    "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence, padding='post')\n",
    "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
    "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
    "\n",
    "y_data = pad_sequences(sequences = y_data, maxlen = max_sequence, padding='post')\n",
    "\n",
    "# checking data\n",
    "print(x_data, x_data_len)\n",
    "print(x_data_mask)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2963b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 10, 15)            225       \n",
      "                                                                 \n",
      " simple_rnn_9 (SimpleRNN)    (None, 10, 10)            260       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 10, 8)            88        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 573\n",
      "Trainable params: 348\n",
      "Non-trainable params: 225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating rnn for \"many to many\" sequence tagging\n",
    "num_classes = len(pos2idx)\n",
    "hidden_dim = 10\n",
    "\n",
    "input_dim = len(word2idx)\n",
    "output_dim = len(word2idx)\n",
    "one_hot = np.eye(len(word2idx))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True,\n",
    "                           trainable=False, input_length=max_sequence,\n",
    "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_dim, return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(units=num_classes)))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd48e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x, y, x_len, max_sequence):\n",
    "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
    "    valid_time_step = tf.cast(x_len,dtype=tf.float32)\n",
    "    sequence_loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=y, logits=model(x),\n",
    "                                                           reduction='none') * masking\n",
    "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
    "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
    "    return sequence_loss\n",
    "\n",
    "# creating and optimizer\n",
    "lr = 0.1\n",
    "epochs = 30\n",
    "batch_size = 2 \n",
    "opt = tf.compat.v1.train.AdamOptimizer(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5398c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# generating data pipeline\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
    "tr_dataset = tr_dataset.batch(batch_size = 2)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8286eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.144\n",
      "epoch :  10, tr_loss : 0.008\n",
      "epoch :  15, tr_loss : 0.002\n",
      "epoch :  20, tr_loss : 0.001\n",
      "epoch :  25, tr_loss : 0.001\n",
      "epoch :  30, tr_loss : 0.001\n"
     ]
    }
   ],
   "source": [
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99c44e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 718ms/step\n",
      "[['pronoun', 'verb', 'adjective', '', '', '', '', '', '', ''],\n",
      " ['noun', 'verb', 'adverb', 'adjective', '', '', '', '', '', ''],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '', '', ''],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb', '', '', '', '', '']]\n",
      "[['pronoun', 'verb', 'adjective'],\n",
      " ['noun', 'verb', 'adverb', 'adjective'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
    "\n",
    "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
    "pprint(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8a259ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aaea76ac70>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31ad3d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "551b102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data\n",
    "sentences = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "pos = [['pronoun', 'verb', 'adjective'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective'],\n",
    "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8c04013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
      "{0: '', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# creating a token dictionary for word\n",
    "word_list = sum(sentences, [])\n",
    "word_list = sorted(set(word_list))\n",
    "word_list = [''] + word_list\n",
    "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
    "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
    "\n",
    "print(word2idx)\n",
    "print(idx2word)\n",
    "print(len(idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ceddd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
      "{0: '', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# creating a token dictionary for part of speech\n",
    "pos_list = sum(pos, [])\n",
    "pos_list = sorted(set(pos_list))\n",
    "pos_list = [''] + pos_list\n",
    "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
    "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
    "\n",
    "print(pos2idx)\n",
    "print(idx2pos)\n",
    "print(len(pos2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31cb31a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "[[6 7 1 0 0 0 0 0 0 0]\n",
      " [4 7 2 1 0 0 0 0 0 0]\n",
      " [4 7 3 4 5 1 4 0 0 0]\n",
      " [4 7 2 1 7 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# converting sequence of tokens to sequence of indices\n",
    "max_sequence = 10\n",
    "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
    "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
    "\n",
    "# padding the sequence of indices\n",
    "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence, padding='post')\n",
    "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
    "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
    "\n",
    "y_data = pad_sequences(sequences = y_data, maxlen = max_sequence, padding='post')\n",
    "\n",
    "# checking data\n",
    "print(x_data, x_data_len)\n",
    "print(x_data_mask)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1211915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bidirectional rnn for \"many to many\" sequence tagging\n",
    "num_classes = len(pos2idx)\n",
    "hidden_dim = 10\n",
    "\n",
    "input_dim = len(word2idx)\n",
    "output_dim = len(word2idx)\n",
    "one_hot = np.eye(len(word2idx))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(max_sequence,)))\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True,\n",
    "                                 trainable=False, input_length=max_sequence,\n",
    "                                 embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.Bidirectional(keras.layers.SimpleRNN(units=hidden_dim, return_sequences=True)))\n",
    "model.add(layers.TimeDistributed(keras.layers.Dense(units=num_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8ace5de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 10, 15)            225       \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 10, 20)           520       \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 10, 8)            168       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 913\n",
      "Trainable params: 688\n",
      "Non-trainable params: 225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41090408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating loss function\n",
    "def loss_fn(model, x, y, x_len, max_sequence):\n",
    "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
    "    valid_time_step = tf.cast(x_len,dtype=tf.float32)\n",
    "    sequence_loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=y, logits=model(x),\n",
    "                                                           reduction='none') * masking\n",
    "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
    "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
    "    return sequence_loss\n",
    "\n",
    "# creating and optimizer\n",
    "lr = 0.1\n",
    "epochs = 30\n",
    "batch_size = 2 \n",
    "opt = tf.compat.v1.train.AdamOptimizer(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9c4e56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# generating data pipeline\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
    "tr_dataset = tr_dataset.batch(batch_size = 2)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20d357e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.018\n",
      "epoch :  10, tr_loss : 0.001\n",
      "epoch :  15, tr_loss : 0.000\n",
      "epoch :  20, tr_loss : 0.000\n",
      "epoch :  25, tr_loss : 0.000\n",
      "epoch :  30, tr_loss : 0.000\n"
     ]
    }
   ],
   "source": [
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88b2772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AAEA8CC310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 969ms/step\n",
      "[['pronoun', 'verb', 'adjective', '', '', '', '', '', '', ''],\n",
      " ['noun', 'verb', 'adverb', 'adjective', '', '', '', '', '', ''],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '', '', ''],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb', '', '', '', '', '']]\n",
      "[['pronoun', 'verb', 'adjective'],\n",
      " ['noun', 'verb', 'adverb', 'adjective'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
    "\n",
    "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
    "pprint(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f4483cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aaea3c6430>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18b211",
   "metadata": {},
   "source": [
    "# lab 12-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a00299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow >= 1.10 and enable eager execution\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "rc('font', family='AppleGothic') #for mac\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "662e431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "targets = [['나는', '배가', '고프다'],\n",
    "           ['텐서플로우는', '매우', '어렵다'],\n",
    "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
    "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3a24d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0,\n",
      " 'I': 1,\n",
      " 'a': 2,\n",
      " 'changing': 3,\n",
      " 'deep': 4,\n",
      " 'difficult': 5,\n",
      " 'fast': 6,\n",
      " 'feel': 7,\n",
      " 'for': 8,\n",
      " 'framework': 9,\n",
      " 'hungry': 10,\n",
      " 'is': 11,\n",
      " 'learning': 12,\n",
      " 'tensorflow': 13,\n",
      " 'very': 14}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for sources\n",
    "s_vocab = list(set(sum(sources, [])))\n",
    "s_vocab.sort()\n",
    "s_vocab = [''] + s_vocab\n",
    "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
    "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
    "\n",
    "pprint(source2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e2c7837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 2,\n",
      " '고프다': 3,\n",
      " '나는': 4,\n",
      " '딥러닝을': 5,\n",
      " '매우': 6,\n",
      " '배가': 7,\n",
      " '변화한다': 8,\n",
      " '빠르게': 9,\n",
      " '어렵다': 10,\n",
      " '위한': 11,\n",
      " '텐서플로우는': 12,\n",
      " '프레임워크이다': 13}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for targets\n",
    "t_vocab = list(set(sum(targets, [])))\n",
    "t_vocab.sort()\n",
    "t_vocab = ['', '', ''] + t_vocab\n",
    "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
    "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
    "\n",
    "pprint(target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae271c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
    "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
    "    \n",
    "    if mode == 'source':\n",
    "        # preprocessing for source (encoder)\n",
    "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
    "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
    "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        return s_len, s_input\n",
    "    \n",
    "    elif mode == 'target':\n",
    "        # preprocessing for target (decoder)\n",
    "        # input\n",
    "        t_input = list(map(lambda sentence : [''] + sentence + [''], sequences))\n",
    "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
    "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
    "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        \n",
    "        # output\n",
    "        t_output = list(map(lambda sentence : sentence + [''], sequences))\n",
    "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
    "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        \n",
    "        return t_len, t_input, t_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "05e04e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for source\n",
    "s_max_len = 10\n",
    "s_len, s_input = preprocess(sequences = sources,\n",
    "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
    "print(s_len, s_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7894f44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 6, 6] [[ 2  4  7  3  2  0  0  0  0  0  0  0]\n",
      " [ 2 12  6 10  2  0  0  0  0  0  0  0]\n",
      " [ 2 12  5 11 13  2  0  0  0  0  0  0]\n",
      " [ 2 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
      " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
      " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
      " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for target\n",
    "t_max_len = 12\n",
    "t_len, t_input, t_output = preprocess(sequences = targets,\n",
    "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
    "print(t_len, t_input, t_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "08908c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "learning_rate = .005\n",
    "total_step = epochs / batch_size\n",
    "buffer_size = 100\n",
    "n_batch = buffer_size//batch_size\n",
    "embedding_dim = 32\n",
    "units = 32\n",
    "\n",
    "# input\n",
    "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
    "data = data.shuffle(buffer_size = buffer_size)\n",
    "data = data.batch(batch_size = batch_size)\n",
    "# s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6509ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "    if tf.test.is_gpu_available():\n",
    "        return tf.keras.layers.CuDNNGRU(units, \n",
    "                                        return_sequences=True, \n",
    "                                        return_state=True, \n",
    "                                        recurrent_initializer='glorot_uniform')\n",
    "    else:\n",
    "        return tf.keras.layers.GRU(units, \n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True, \n",
    "                                   recurrent_activation='sigmoid', \n",
    "                                   recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7ed7dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c5b6b43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "                \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "af1a8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
    "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.compat.v1.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    \n",
    "#     print(\"real: {}\".format(real))\n",
    "#     print(\"pred: {}\".format(pred))\n",
    "#     print(\"mask: {}\".format(mask))\n",
    "#     print(\"loss: {}\".format(tf.reduce_mean(loss_)))\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "# creating optimizer\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer()\n",
    "\n",
    "# creating check point (Object-based saving)\n",
    "checkpoint_dir = './data_out/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                encoder=encoder,\n",
    "                                decoder=decoder)\n",
    "\n",
    "# create writer for tensorboard\n",
    "#summary_writer = tf.contrib.summary.create_file_writer(logdir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a40edbe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__SparseSoftmaxCrossEntropyWithLogits_device_/job:localhost/replica:0/task:0/device:CPU:0}} Received a label value of 12 which is outside the valid range of [0, 12).  Label values: 12 12 12 4 [Op:SparseSoftmaxCrossEntropyWithLogits]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [104]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, t_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     20\u001b[0m         predictions, dec_hidden \u001b[38;5;241m=\u001b[39m decoder(dec_input, dec_hidden, enc_output)\n\u001b[1;32m---> 22\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m         dec_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(t_input[:, t], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#using teacher forcing\u001b[39;00m\n\u001b[0;32m     26\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m (loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mint\u001b[39m(t_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "Input \u001b[1;32mIn [103]\u001b[0m, in \u001b[0;36mloss_function\u001b[1;34m(real, pred)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_function\u001b[39m(real, pred):\n\u001b[0;32m      5\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mequal(real, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     loss_ \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_softmax_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m mask\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     print(\"real: {}\".format(real))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#     print(\"pred: {}\".format(pred))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#     print(\"mask: {}\".format(mask))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#     print(\"loss: {}\".format(tf.reduce_mean(loss_)))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(loss_)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__SparseSoftmaxCrossEntropyWithLogits_device_/job:localhost/replica:0/task:0/device:CPU:0}} Received a label value of 12 which is outside the valid range of [0, 12).  Label values: 12 12 12 4 [Op:SparseSoftmaxCrossEntropyWithLogits]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
    "\n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([target2idx['']] * batch_size, 1)\n",
    "            \n",
    "            #Teacher Forcing: feeding the target as the next input\n",
    "            for t in range(1, t_input.shape[1]):\n",
    "                \n",
    "                predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(t_input[:, t], predictions)\n",
    "            \n",
    "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
    "                \n",
    "        batch_loss = (loss / int(t_input.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradient = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradient, variables))\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        #save model every 10 epoch\n",
    "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch,\n",
    "                                            total_loss / n_batch,\n",
    "                                            batch_loss.numpy()))\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "749574cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I feel hungry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78ca4150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel hungry\n",
      "딥러닝을 위한 위한 위한 위한 위한 위한 위한 매우  \n"
     ]
    }
   ],
   "source": [
    "def prediction(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    \n",
    "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "        \n",
    "    result = ''\n",
    "    \n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "        \n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang['']], 0)\n",
    "    \n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += idx2target[predicted_id] + ' '\n",
    "\n",
    "        if idx2target.get(predicted_id) == '':\n",
    "            return result, sentence\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)    \n",
    "    \n",
    "    return result, sentence\n",
    "    \n",
    "result, output_sentence = prediction(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)\n",
    "\n",
    "print(sentence)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf332c",
   "metadata": {},
   "source": [
    "# lab 12-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a7467ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow >= 1.10 and enable eager execution\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "rc('font', family='AppleGothic') #for mac\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d67944da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "targets = [['나는', '배가', '고프다'],\n",
    "           ['텐서플로우는', '매우', '어렵다'],\n",
    "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
    "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dc6c23b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0,\n",
      " 'I': 1,\n",
      " 'a': 2,\n",
      " 'changing': 3,\n",
      " 'deep': 4,\n",
      " 'difficult': 5,\n",
      " 'fast': 6,\n",
      " 'feel': 7,\n",
      " 'for': 8,\n",
      " 'framework': 9,\n",
      " 'hungry': 10,\n",
      " 'is': 11,\n",
      " 'learning': 12,\n",
      " 'tensorflow': 13,\n",
      " 'very': 14}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for sources\n",
    "s_vocab = list(set(sum(sources, [])))\n",
    "s_vocab.sort()\n",
    "s_vocab = [''] + s_vocab\n",
    "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
    "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
    "\n",
    "pprint(source2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "58c63301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 2,\n",
      " '고프다': 3,\n",
      " '나는': 4,\n",
      " '딥러닝을': 5,\n",
      " '매우': 6,\n",
      " '배가': 7,\n",
      " '변화한다': 8,\n",
      " '빠르게': 9,\n",
      " '어렵다': 10,\n",
      " '위한': 11,\n",
      " '텐서플로우는': 12,\n",
      " '프레임워크이다': 13}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for targets\n",
    "t_vocab = list(set(sum(targets, [])))\n",
    "t_vocab.sort()\n",
    "t_vocab = ['', '', ''] + t_vocab\n",
    "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
    "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
    "\n",
    "pprint(target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f5f62349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
    "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
    "    \n",
    "    if mode == 'source':\n",
    "        # preprocessing for source (encoder)\n",
    "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
    "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
    "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        return s_len, s_input\n",
    "    \n",
    "    elif mode == 'target':\n",
    "        # preprocessing for target (decoder)\n",
    "        # input\n",
    "        t_input = list(map(lambda sentence : [''] + sentence + [''], sequences))\n",
    "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
    "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
    "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        \n",
    "        # output\n",
    "        t_output = list(map(lambda sentence : sentence + [''], sequences))\n",
    "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
    "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        \n",
    "        return t_len, t_input, t_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8ae4e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for source\n",
    "s_max_len = 10\n",
    "s_len, s_input = preprocess(sequences = sources,\n",
    "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
    "print(s_len, s_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "faf3e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 6, 6] [[ 2  4  7  3  2  0  0  0  0  0  0  0]\n",
      " [ 2 12  6 10  2  0  0  0  0  0  0  0]\n",
      " [ 2 12  5 11 13  2  0  0  0  0  0  0]\n",
      " [ 2 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
      " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
      " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
      " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for target\n",
    "t_max_len = 12\n",
    "t_len, t_input, t_output = preprocess(sequences = targets,\n",
    "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
    "print(t_len, t_input, t_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a2a3c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "learning_rate = .005\n",
    "total_step = epochs / batch_size\n",
    "buffer_size = 100\n",
    "n_batch = buffer_size//batch_size\n",
    "embedding_dim = 32\n",
    "units = 128\n",
    "\n",
    "# input\n",
    "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
    "data = data.shuffle(buffer_size = buffer_size)\n",
    "data = data.batch(batch_size = batch_size)\n",
    "# s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "834c7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "    if tf.test.is_gpu_available():\n",
    "        return tf.keras.layers.CuDNNGRU(units, \n",
    "                                        return_sequences=True, \n",
    "                                        return_state=True, \n",
    "                                        recurrent_initializer='glorot_uniform')\n",
    "    else:\n",
    "        return tf.keras.layers.GRU(units, \n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True, \n",
    "                                   recurrent_activation='sigmoid', \n",
    "                                   recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8918b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "#         print(\"state: {}\".format(state.shape))\n",
    "#         print(\"output: {}\".format(state.shape))\n",
    "              \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f0839620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    def call(self, x, hidden, enc_output):\n",
    "  \n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "      \n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "                \n",
    "       \n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    " \n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        # * `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # * `merged vector = concat(embedding output, context vector)`\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "467ec2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
    "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "# creating optimizer\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer()\n",
    "\n",
    "# creating check point (Object-based saving)\n",
    "checkpoint_dir = './data_out/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                encoder=encoder,\n",
    "                                decoder=decoder)\n",
    "\n",
    "# create writer for tensorboard\n",
    "#summary_writer = tf.contrib.summary.create_file_writer(logdir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3abbe1f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__SparseSoftmaxCrossEntropyWithLogits_device_/job:localhost/replica:0/task:0/device:CPU:0}} Received a label value of 12 which is outside the valid range of [0, 12).  Label values: 12 12 4 12 [Op:SparseSoftmaxCrossEntropyWithLogits]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [125]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, t_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     19\u001b[0m         predictions, dec_hidden, _ \u001b[38;5;241m=\u001b[39m decoder(dec_input, dec_hidden, enc_output)\n\u001b[1;32m---> 21\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m         dec_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(t_input[:, t], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#using teacher forcing\u001b[39;00m\n\u001b[0;32m     25\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m (loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mint\u001b[39m(t_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "Input \u001b[1;32mIn [124]\u001b[0m, in \u001b[0;36mloss_function\u001b[1;34m(real, pred)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_function\u001b[39m(real, pred):\n\u001b[0;32m      5\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mequal(real, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     loss_ \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_softmax_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m mask\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(loss_)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__SparseSoftmaxCrossEntropyWithLogits_device_/job:localhost/replica:0/task:0/device:CPU:0}} Received a label value of 12 which is outside the valid range of [0, 12).  Label values: 12 12 4 12 [Op:SparseSoftmaxCrossEntropyWithLogits]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([target2idx['']] * batch_size, 1)\n",
    "            \n",
    "            #Teacher Forcing: feeding the target as the next input\n",
    "            for t in range(1, t_input.shape[1]):\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(t_input[:, t], predictions)\n",
    "            \n",
    "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
    "                \n",
    "        batch_loss = (loss / int(t_input.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradient = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradient, variables))\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        #save model every 10 epoch\n",
    "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch,\n",
    "                                            total_loss / n_batch,\n",
    "                                            batch_loss.numpy()))\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "04b4d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "#     sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang['']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += idx2target[predicted_id] + ' '\n",
    "\n",
    "        if idx2target.get(predicted_id) == '':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4a0be905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1ff62444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
    "        \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4303e436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.InitializationOnlyStatus at 0x1aaed4effa0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b32aa16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I feel hungry\n",
      "Predicted translation:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kv069\\AppData\\Local\\Temp\\ipykernel_38288\\3266044770.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "C:\\Users\\kv069\\AppData\\Local\\Temp\\ipykernel_38288\\3266044770.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
      "findfont: Font family ['AppleGothic'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = 'I feel hungry'\n",
    "# sentence = 'tensorflow is a framework for deep learning'\n",
    "\n",
    "translate(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74864cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
