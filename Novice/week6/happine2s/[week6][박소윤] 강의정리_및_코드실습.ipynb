{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae839db",
   "metadata": {},
   "source": [
    "###Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed07d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee1325",
   "metadata": {},
   "source": [
    "###check point 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8352b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(model, checkpoint_dir):\n",
    "    print(\" [*] Reading checkpoints...\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt :\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        checkpoint = tf.train.Checkpoint(dnn=model)\n",
    "        checkpoint.restore(save_path=os.path.join(checkpoint_dir, ckpt_name))\n",
    "        counter = int(ckpt_name.split('-')[1])\n",
    "        print(\" [*] Success to read {}\".format(ckpt_name))\n",
    "        return True, counter\n",
    "    else:\n",
    "        print(\" [*] Failed to find a checkpoint\")\n",
    "        return False, 0\n",
    "\n",
    "def check_folder(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    return dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8b8a3",
   "metadata": {},
   "source": [
    "### 데이터 로드 및 전처리 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90a6762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist() :\n",
    "    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "    train_data = np.expand_dims(train_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1] axis=3 이라고 해도됨\n",
    "    test_data = np.expand_dims(test_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1] [batch_size,height,width,channel]\n",
    "\n",
    "    train_data, test_data = normalize(train_data, test_data)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10) # [N,] -> [N, 10] , onehotencoding\n",
    "    test_labels = to_categorical(test_labels, 10) # [N,] -> [N, 10]\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "def normalize(train_data, test_data):\n",
    "    train_data = train_data.astype(np.float32) / 255.0\n",
    "    test_data = test_data.astype(np.float32) / 255.0\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a147badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True)\n",
    "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, \n",
    "                                                                   from_logits=True))\n",
    "    return loss\n",
    "\n",
    "def accuracy_fn(model, images, labels):\n",
    "    logits = model(images, training=False)\n",
    "    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4fb5f2",
   "metadata": {},
   "source": [
    "###모델 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c49d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten() :\n",
    "    return tf.keras.layers.Flatten()\n",
    "\n",
    "def dense(label_dim, weight_init) :\n",
    "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
    "\n",
    "def relu() :\n",
    "    return tf.keras.layers.Activation(tf.keras.activations.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0657a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class.V\n",
    "class create_model_class(tf.keras.Model):\n",
    "    def __init__(self, label_dim):\n",
    "        super(create_model_class, self).__init__()\n",
    "        weight_init = tf.keras.initializers.RandomNormal()\n",
    "\n",
    "        self.model = tf.keras.Sequential() #list자료구조 타입\n",
    "        self.model.add(flatten()) #fc layer 쓸꺼기 때문에 바꿔줌\n",
    "\n",
    "        for i in range(2):\n",
    "            self.model.add(dense(256, weight_init))\n",
    "            self.model.add(relu())\n",
    "\n",
    "        self.model.add(dense(label_dim, weight_init))\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65f765ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#func.V\n",
    "def create_model_function(label_dim) :\n",
    "    weight_init = tf.keras.initializers.RandomNormal()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(flatten())\n",
    "\n",
    "    for i in range(2) :\n",
    "        model.add(dense(256, weight_init))\n",
    "        model.add(relu())\n",
    "\n",
    "    model.add(dense(label_dim, weight_init))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da8699",
   "metadata": {},
   "source": [
    "###데이터 정의 및 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edacf37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 15:59:00.690609: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" dataset \"\"\"\n",
    "train_x, train_y, test_x, test_y = load_mnist()\n",
    "\n",
    "\"\"\" parameters \"\"\"\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "training_epochs = 1\n",
    "training_iterations = len(train_x) // batch_size\n",
    "\n",
    "label_dim = 10\n",
    "\n",
    "train_flag = True\n",
    "\n",
    "\"\"\" Graph Input using Dataset API \"\"\"\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices ((train_x, train_y)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=batch_size).\\\n",
    "    batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=len(test_x)).\\\n",
    "    batch(len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b321f",
   "metadata": {},
   "source": [
    "###모델 정의 및 옵피마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f6e5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model \"\"\"\n",
    "network = create_model_function(label_dim)\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "\"\"\" Writer \"\"\"\n",
    "checkpoint_dir = 'checkpoints'\n",
    "logs_dir = 'logs'\n",
    "\n",
    "model_dir = 'nn_relu'\n",
    "\n",
    "checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "check_folder(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n",
    "logs_dir = os.path.join(logs_dir, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a4840f",
   "metadata": {},
   "source": [
    "###학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a758411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 0] [    0/  468] time: 0.5012, train_loss: 2.17186308, train_accuracy: 0.2969, test_Accuracy: 0.2039\n",
      "Epoch: [ 0] [    1/  468] time: 0.5879, train_loss: 2.13438082, train_accuracy: 0.4062, test_Accuracy: 0.3362\n",
      "Epoch: [ 0] [    2/  468] time: 0.6760, train_loss: 2.11364222, train_accuracy: 0.3906, test_Accuracy: 0.4191\n",
      "Epoch: [ 0] [    3/  468] time: 0.7697, train_loss: 1.99630046, train_accuracy: 0.5547, test_Accuracy: 0.4954\n",
      "Epoch: [ 0] [    4/  468] time: 0.8614, train_loss: 1.93817854, train_accuracy: 0.5781, test_Accuracy: 0.5981\n",
      "Epoch: [ 0] [    5/  468] time: 0.9535, train_loss: 1.82669544, train_accuracy: 0.6953, test_Accuracy: 0.6733\n",
      "Epoch: [ 0] [    6/  468] time: 1.0427, train_loss: 1.75400329, train_accuracy: 0.7109, test_Accuracy: 0.7032\n",
      "Epoch: [ 0] [    7/  468] time: 1.1275, train_loss: 1.61542606, train_accuracy: 0.8203, test_Accuracy: 0.7094\n",
      "Epoch: [ 0] [    8/  468] time: 1.2107, train_loss: 1.52590322, train_accuracy: 0.6953, test_Accuracy: 0.7259\n",
      "Epoch: [ 0] [    9/  468] time: 1.3043, train_loss: 1.44369030, train_accuracy: 0.7266, test_Accuracy: 0.7453\n",
      "Epoch: [ 0] [   10/  468] time: 1.3966, train_loss: 1.30586028, train_accuracy: 0.7969, test_Accuracy: 0.7709\n",
      "Epoch: [ 0] [   11/  468] time: 1.4899, train_loss: 1.23383260, train_accuracy: 0.8047, test_Accuracy: 0.7906\n",
      "Epoch: [ 0] [   12/  468] time: 1.5837, train_loss: 1.10339785, train_accuracy: 0.7891, test_Accuracy: 0.7941\n",
      "Epoch: [ 0] [   13/  468] time: 1.6715, train_loss: 1.06386995, train_accuracy: 0.7891, test_Accuracy: 0.7868\n",
      "Epoch: [ 0] [   14/  468] time: 1.7536, train_loss: 1.00599325, train_accuracy: 0.7734, test_Accuracy: 0.7921\n",
      "Epoch: [ 0] [   15/  468] time: 1.8436, train_loss: 0.90102875, train_accuracy: 0.7656, test_Accuracy: 0.8091\n",
      "Epoch: [ 0] [   16/  468] time: 1.9289, train_loss: 0.90165043, train_accuracy: 0.7969, test_Accuracy: 0.8196\n",
      "Epoch: [ 0] [   17/  468] time: 2.0247, train_loss: 0.69856048, train_accuracy: 0.8594, test_Accuracy: 0.8275\n",
      "Epoch: [ 0] [   18/  468] time: 2.1196, train_loss: 0.73863292, train_accuracy: 0.8125, test_Accuracy: 0.8215\n",
      "Epoch: [ 0] [   19/  468] time: 2.2149, train_loss: 0.60960442, train_accuracy: 0.8828, test_Accuracy: 0.8050\n",
      "Epoch: [ 0] [   20/  468] time: 2.3107, train_loss: 0.63432151, train_accuracy: 0.7969, test_Accuracy: 0.8033\n",
      "Epoch: [ 0] [   21/  468] time: 2.4037, train_loss: 0.58762705, train_accuracy: 0.8281, test_Accuracy: 0.8163\n",
      "Epoch: [ 0] [   22/  468] time: 2.4977, train_loss: 0.72844195, train_accuracy: 0.7422, test_Accuracy: 0.8459\n",
      "Epoch: [ 0] [   23/  468] time: 2.5928, train_loss: 0.60704350, train_accuracy: 0.8594, test_Accuracy: 0.8465\n",
      "Epoch: [ 0] [   24/  468] time: 2.6876, train_loss: 0.58127880, train_accuracy: 0.8359, test_Accuracy: 0.8257\n",
      "Epoch: [ 0] [   25/  468] time: 2.7786, train_loss: 0.54838616, train_accuracy: 0.8203, test_Accuracy: 0.8171\n",
      "Epoch: [ 0] [   26/  468] time: 2.8731, train_loss: 0.44044566, train_accuracy: 0.8750, test_Accuracy: 0.8310\n",
      "Epoch: [ 0] [   27/  468] time: 2.9667, train_loss: 0.53777194, train_accuracy: 0.8438, test_Accuracy: 0.8491\n",
      "Epoch: [ 0] [   28/  468] time: 3.0526, train_loss: 0.44967687, train_accuracy: 0.8516, test_Accuracy: 0.8523\n",
      "Epoch: [ 0] [   29/  468] time: 3.1384, train_loss: 0.45626163, train_accuracy: 0.8750, test_Accuracy: 0.8591\n",
      "Epoch: [ 0] [   30/  468] time: 3.2313, train_loss: 0.42731088, train_accuracy: 0.8750, test_Accuracy: 0.8652\n",
      "Epoch: [ 0] [   31/  468] time: 3.3211, train_loss: 0.60849738, train_accuracy: 0.8203, test_Accuracy: 0.8693\n",
      "Epoch: [ 0] [   32/  468] time: 3.4131, train_loss: 0.39978847, train_accuracy: 0.9141, test_Accuracy: 0.8729\n",
      "Epoch: [ 0] [   33/  468] time: 3.5063, train_loss: 0.38200048, train_accuracy: 0.8906, test_Accuracy: 0.8752\n",
      "Epoch: [ 0] [   34/  468] time: 3.5954, train_loss: 0.36299533, train_accuracy: 0.9141, test_Accuracy: 0.8716\n",
      "Epoch: [ 0] [   35/  468] time: 3.6843, train_loss: 0.49765322, train_accuracy: 0.8516, test_Accuracy: 0.8706\n",
      "Epoch: [ 0] [   36/  468] time: 3.7748, train_loss: 0.41338885, train_accuracy: 0.9062, test_Accuracy: 0.8710\n",
      "Epoch: [ 0] [   37/  468] time: 3.8609, train_loss: 0.60140151, train_accuracy: 0.8203, test_Accuracy: 0.8755\n",
      "Epoch: [ 0] [   38/  468] time: 3.9467, train_loss: 0.36049739, train_accuracy: 0.8906, test_Accuracy: 0.8792\n",
      "Epoch: [ 0] [   39/  468] time: 4.0393, train_loss: 0.47025961, train_accuracy: 0.8828, test_Accuracy: 0.8827\n",
      "Epoch: [ 0] [   40/  468] time: 4.1298, train_loss: 0.36425385, train_accuracy: 0.8906, test_Accuracy: 0.8764\n",
      "Epoch: [ 0] [   41/  468] time: 4.2160, train_loss: 0.57321596, train_accuracy: 0.8047, test_Accuracy: 0.8738\n",
      "Epoch: [ 0] [   42/  468] time: 4.3069, train_loss: 0.45774218, train_accuracy: 0.8906, test_Accuracy: 0.8784\n",
      "Epoch: [ 0] [   43/  468] time: 4.4025, train_loss: 0.52294874, train_accuracy: 0.8594, test_Accuracy: 0.8860\n",
      "Epoch: [ 0] [   44/  468] time: 4.4971, train_loss: 0.34765068, train_accuracy: 0.9062, test_Accuracy: 0.8874\n",
      "Epoch: [ 0] [   45/  468] time: 4.5941, train_loss: 0.43223542, train_accuracy: 0.8516, test_Accuracy: 0.8852\n",
      "Epoch: [ 0] [   46/  468] time: 4.6909, train_loss: 0.41857979, train_accuracy: 0.8906, test_Accuracy: 0.8831\n",
      "Epoch: [ 0] [   47/  468] time: 4.7859, train_loss: 0.38388798, train_accuracy: 0.8828, test_Accuracy: 0.8845\n",
      "Epoch: [ 0] [   48/  468] time: 4.8817, train_loss: 0.30435437, train_accuracy: 0.9219, test_Accuracy: 0.8820\n",
      "Epoch: [ 0] [   49/  468] time: 4.9787, train_loss: 0.37262383, train_accuracy: 0.9062, test_Accuracy: 0.8846\n",
      "Epoch: [ 0] [   50/  468] time: 5.0759, train_loss: 0.32274699, train_accuracy: 0.9297, test_Accuracy: 0.8796\n",
      "Epoch: [ 0] [   51/  468] time: 5.1772, train_loss: 0.32595107, train_accuracy: 0.8906, test_Accuracy: 0.8803\n",
      "Epoch: [ 0] [   52/  468] time: 5.2659, train_loss: 0.33063406, train_accuracy: 0.8984, test_Accuracy: 0.8778\n",
      "Epoch: [ 0] [   53/  468] time: 5.3550, train_loss: 0.33228758, train_accuracy: 0.8828, test_Accuracy: 0.8837\n",
      "Epoch: [ 0] [   54/  468] time: 5.4477, train_loss: 0.37351102, train_accuracy: 0.8672, test_Accuracy: 0.8920\n",
      "Epoch: [ 0] [   55/  468] time: 5.5355, train_loss: 0.30053961, train_accuracy: 0.9219, test_Accuracy: 0.8992\n",
      "Epoch: [ 0] [   56/  468] time: 5.6307, train_loss: 0.24886712, train_accuracy: 0.9219, test_Accuracy: 0.9010\n",
      "Epoch: [ 0] [   57/  468] time: 5.7282, train_loss: 0.49462923, train_accuracy: 0.8828, test_Accuracy: 0.9000\n",
      "Epoch: [ 0] [   58/  468] time: 5.8233, train_loss: 0.47093806, train_accuracy: 0.8906, test_Accuracy: 0.8992\n",
      "Epoch: [ 0] [   59/  468] time: 5.9152, train_loss: 0.40366077, train_accuracy: 0.8828, test_Accuracy: 0.8995\n",
      "Epoch: [ 0] [   60/  468] time: 6.0032, train_loss: 0.36148587, train_accuracy: 0.8750, test_Accuracy: 0.9018\n",
      "Epoch: [ 0] [   61/  468] time: 6.0921, train_loss: 0.36251134, train_accuracy: 0.8828, test_Accuracy: 0.9050\n",
      "Epoch: [ 0] [   62/  468] time: 6.1818, train_loss: 0.25333533, train_accuracy: 0.9453, test_Accuracy: 0.9057\n",
      "Epoch: [ 0] [   63/  468] time: 6.2792, train_loss: 0.28834656, train_accuracy: 0.9062, test_Accuracy: 0.9063\n",
      "Epoch: [ 0] [   64/  468] time: 6.3753, train_loss: 0.27193490, train_accuracy: 0.9297, test_Accuracy: 0.9082\n",
      "Epoch: [ 0] [   65/  468] time: 6.4745, train_loss: 0.38040102, train_accuracy: 0.8594, test_Accuracy: 0.9083\n",
      "Epoch: [ 0] [   66/  468] time: 6.5707, train_loss: 0.38578010, train_accuracy: 0.8516, test_Accuracy: 0.9055\n",
      "Epoch: [ 0] [   67/  468] time: 6.6637, train_loss: 0.29992253, train_accuracy: 0.9141, test_Accuracy: 0.9029\n",
      "Epoch: [ 0] [   68/  468] time: 6.7516, train_loss: 0.41298044, train_accuracy: 0.8750, test_Accuracy: 0.9030\n",
      "Epoch: [ 0] [   69/  468] time: 6.8417, train_loss: 0.42407560, train_accuracy: 0.8594, test_Accuracy: 0.9048\n",
      "Epoch: [ 0] [   70/  468] time: 6.9292, train_loss: 0.28917554, train_accuracy: 0.9219, test_Accuracy: 0.9096\n",
      "Epoch: [ 0] [   71/  468] time: 7.0161, train_loss: 0.26367682, train_accuracy: 0.9297, test_Accuracy: 0.9113\n",
      "Epoch: [ 0] [   72/  468] time: 7.1065, train_loss: 0.37448657, train_accuracy: 0.8828, test_Accuracy: 0.9115\n",
      "Epoch: [ 0] [   73/  468] time: 7.2007, train_loss: 0.34992930, train_accuracy: 0.9375, test_Accuracy: 0.9053\n",
      "Epoch: [ 0] [   74/  468] time: 7.2919, train_loss: 0.21111205, train_accuracy: 0.9531, test_Accuracy: 0.8956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [   75/  468] time: 7.3871, train_loss: 0.39713788, train_accuracy: 0.8984, test_Accuracy: 0.8955\n",
      "Epoch: [ 0] [   76/  468] time: 7.4763, train_loss: 0.23487565, train_accuracy: 0.9062, test_Accuracy: 0.8958\n",
      "Epoch: [ 0] [   77/  468] time: 7.5663, train_loss: 0.28766891, train_accuracy: 0.8828, test_Accuracy: 0.9014\n",
      "Epoch: [ 0] [   78/  468] time: 7.6562, train_loss: 0.25144169, train_accuracy: 0.9297, test_Accuracy: 0.9107\n",
      "Epoch: [ 0] [   79/  468] time: 7.7426, train_loss: 0.46445322, train_accuracy: 0.8750, test_Accuracy: 0.9170\n",
      "Epoch: [ 0] [   80/  468] time: 7.8293, train_loss: 0.33946949, train_accuracy: 0.8828, test_Accuracy: 0.9170\n",
      "Epoch: [ 0] [   81/  468] time: 7.9193, train_loss: 0.29622343, train_accuracy: 0.9375, test_Accuracy: 0.9124\n",
      "Epoch: [ 0] [   82/  468] time: 8.0076, train_loss: 0.23719591, train_accuracy: 0.9297, test_Accuracy: 0.9089\n",
      "Epoch: [ 0] [   83/  468] time: 8.0974, train_loss: 0.35545999, train_accuracy: 0.8828, test_Accuracy: 0.9082\n",
      "Epoch: [ 0] [   84/  468] time: 8.1892, train_loss: 0.35857028, train_accuracy: 0.8984, test_Accuracy: 0.9152\n",
      "Epoch: [ 0] [   85/  468] time: 8.2843, train_loss: 0.16989064, train_accuracy: 0.9531, test_Accuracy: 0.9197\n",
      "Epoch: [ 0] [   86/  468] time: 8.3754, train_loss: 0.32074791, train_accuracy: 0.8984, test_Accuracy: 0.9195\n",
      "Epoch: [ 0] [   87/  468] time: 8.4685, train_loss: 0.34526765, train_accuracy: 0.9141, test_Accuracy: 0.9190\n",
      "Epoch: [ 0] [   88/  468] time: 8.5603, train_loss: 0.33708322, train_accuracy: 0.9141, test_Accuracy: 0.9165\n",
      "Epoch: [ 0] [   89/  468] time: 8.6567, train_loss: 0.22003004, train_accuracy: 0.9219, test_Accuracy: 0.9130\n",
      "Epoch: [ 0] [   90/  468] time: 8.7482, train_loss: 0.34458193, train_accuracy: 0.8984, test_Accuracy: 0.9102\n",
      "Epoch: [ 0] [   91/  468] time: 8.8370, train_loss: 0.30166343, train_accuracy: 0.8984, test_Accuracy: 0.9085\n",
      "Epoch: [ 0] [   92/  468] time: 8.9287, train_loss: 0.22861078, train_accuracy: 0.9219, test_Accuracy: 0.9082\n",
      "Epoch: [ 0] [   93/  468] time: 9.0202, train_loss: 0.34366816, train_accuracy: 0.8828, test_Accuracy: 0.9106\n",
      "Epoch: [ 0] [   94/  468] time: 9.1128, train_loss: 0.35523066, train_accuracy: 0.9219, test_Accuracy: 0.9175\n",
      "Epoch: [ 0] [   95/  468] time: 9.2052, train_loss: 0.29776543, train_accuracy: 0.9141, test_Accuracy: 0.9207\n",
      "Epoch: [ 0] [   96/  468] time: 9.2980, train_loss: 0.41588554, train_accuracy: 0.9062, test_Accuracy: 0.9180\n",
      "Epoch: [ 0] [   97/  468] time: 9.3920, train_loss: 0.36674845, train_accuracy: 0.8828, test_Accuracy: 0.9122\n",
      "Epoch: [ 0] [   98/  468] time: 9.4843, train_loss: 0.26459995, train_accuracy: 0.9375, test_Accuracy: 0.9091\n",
      "Epoch: [ 0] [   99/  468] time: 9.5758, train_loss: 0.26807380, train_accuracy: 0.9219, test_Accuracy: 0.9130\n",
      "Epoch: [ 0] [  100/  468] time: 9.6713, train_loss: 0.28496900, train_accuracy: 0.9141, test_Accuracy: 0.9207\n",
      "Epoch: [ 0] [  101/  468] time: 9.7596, train_loss: 0.28254527, train_accuracy: 0.9062, test_Accuracy: 0.9227\n",
      "Epoch: [ 0] [  102/  468] time: 9.8503, train_loss: 0.16620040, train_accuracy: 0.9609, test_Accuracy: 0.9234\n",
      "Epoch: [ 0] [  103/  468] time: 9.9410, train_loss: 0.22531438, train_accuracy: 0.9375, test_Accuracy: 0.9204\n",
      "Epoch: [ 0] [  104/  468] time: 10.0308, train_loss: 0.27753496, train_accuracy: 0.9297, test_Accuracy: 0.9176\n",
      "Epoch: [ 0] [  105/  468] time: 10.1261, train_loss: 0.30481902, train_accuracy: 0.9062, test_Accuracy: 0.9168\n",
      "Epoch: [ 0] [  106/  468] time: 10.2206, train_loss: 0.35381421, train_accuracy: 0.8750, test_Accuracy: 0.9161\n",
      "Epoch: [ 0] [  107/  468] time: 10.3115, train_loss: 0.17915566, train_accuracy: 0.9844, test_Accuracy: 0.9173\n",
      "Epoch: [ 0] [  108/  468] time: 10.4070, train_loss: 0.23309858, train_accuracy: 0.9531, test_Accuracy: 0.9189\n",
      "Epoch: [ 0] [  109/  468] time: 10.5015, train_loss: 0.22838753, train_accuracy: 0.9297, test_Accuracy: 0.9201\n",
      "Epoch: [ 0] [  110/  468] time: 10.5890, train_loss: 0.18040591, train_accuracy: 0.9453, test_Accuracy: 0.9216\n",
      "Epoch: [ 0] [  111/  468] time: 10.6778, train_loss: 0.15401219, train_accuracy: 0.9453, test_Accuracy: 0.9223\n",
      "Epoch: [ 0] [  112/  468] time: 10.7716, train_loss: 0.31367239, train_accuracy: 0.8672, test_Accuracy: 0.9228\n",
      "Epoch: [ 0] [  113/  468] time: 10.8625, train_loss: 0.27171868, train_accuracy: 0.9297, test_Accuracy: 0.9235\n",
      "Epoch: [ 0] [  114/  468] time: 10.9499, train_loss: 0.28929734, train_accuracy: 0.9062, test_Accuracy: 0.9229\n",
      "Epoch: [ 0] [  115/  468] time: 11.0383, train_loss: 0.19951209, train_accuracy: 0.9297, test_Accuracy: 0.9241\n",
      "Epoch: [ 0] [  116/  468] time: 11.1284, train_loss: 0.21767280, train_accuracy: 0.9375, test_Accuracy: 0.9234\n",
      "Epoch: [ 0] [  117/  468] time: 11.2190, train_loss: 0.31233519, train_accuracy: 0.9219, test_Accuracy: 0.9221\n",
      "Epoch: [ 0] [  118/  468] time: 11.3103, train_loss: 0.26571193, train_accuracy: 0.9219, test_Accuracy: 0.9210\n",
      "Epoch: [ 0] [  119/  468] time: 11.4015, train_loss: 0.13522293, train_accuracy: 0.9844, test_Accuracy: 0.9202\n",
      "Epoch: [ 0] [  120/  468] time: 11.4923, train_loss: 0.27979806, train_accuracy: 0.9141, test_Accuracy: 0.9214\n",
      "Epoch: [ 0] [  121/  468] time: 11.5856, train_loss: 0.18236987, train_accuracy: 0.9375, test_Accuracy: 0.9245\n",
      "Epoch: [ 0] [  122/  468] time: 11.6823, train_loss: 0.17903499, train_accuracy: 0.9609, test_Accuracy: 0.9272\n",
      "Epoch: [ 0] [  123/  468] time: 11.7757, train_loss: 0.16822603, train_accuracy: 0.9453, test_Accuracy: 0.9283\n",
      "Epoch: [ 0] [  124/  468] time: 11.8642, train_loss: 0.18976149, train_accuracy: 0.9375, test_Accuracy: 0.9261\n",
      "Epoch: [ 0] [  125/  468] time: 11.9526, train_loss: 0.21639812, train_accuracy: 0.9375, test_Accuracy: 0.9207\n",
      "Epoch: [ 0] [  126/  468] time: 12.0427, train_loss: 0.19210988, train_accuracy: 0.9297, test_Accuracy: 0.9173\n",
      "Epoch: [ 0] [  127/  468] time: 12.1319, train_loss: 0.31821391, train_accuracy: 0.8906, test_Accuracy: 0.9177\n",
      "Epoch: [ 0] [  128/  468] time: 12.2183, train_loss: 0.31767282, train_accuracy: 0.8984, test_Accuracy: 0.9246\n",
      "Epoch: [ 0] [  129/  468] time: 12.3059, train_loss: 0.25103247, train_accuracy: 0.9453, test_Accuracy: 0.9262\n",
      "Epoch: [ 0] [  130/  468] time: 12.3946, train_loss: 0.29909804, train_accuracy: 0.9062, test_Accuracy: 0.9264\n",
      "Epoch: [ 0] [  131/  468] time: 12.4845, train_loss: 0.15440314, train_accuracy: 0.9766, test_Accuracy: 0.9226\n",
      "Epoch: [ 0] [  132/  468] time: 12.5754, train_loss: 0.24792063, train_accuracy: 0.9375, test_Accuracy: 0.9205\n",
      "Epoch: [ 0] [  133/  468] time: 12.6624, train_loss: 0.29179865, train_accuracy: 0.8750, test_Accuracy: 0.9238\n",
      "Epoch: [ 0] [  134/  468] time: 12.7529, train_loss: 0.21474262, train_accuracy: 0.9375, test_Accuracy: 0.9292\n",
      "Epoch: [ 0] [  135/  468] time: 12.8445, train_loss: 0.24992886, train_accuracy: 0.9453, test_Accuracy: 0.9306\n",
      "Epoch: [ 0] [  136/  468] time: 12.9463, train_loss: 0.18890779, train_accuracy: 0.9297, test_Accuracy: 0.9316\n",
      "Epoch: [ 0] [  137/  468] time: 13.0442, train_loss: 0.16987067, train_accuracy: 0.9453, test_Accuracy: 0.9317\n",
      "Epoch: [ 0] [  138/  468] time: 13.1367, train_loss: 0.27076083, train_accuracy: 0.9375, test_Accuracy: 0.9323\n",
      "Epoch: [ 0] [  139/  468] time: 13.2281, train_loss: 0.20921478, train_accuracy: 0.9297, test_Accuracy: 0.9319\n",
      "Epoch: [ 0] [  140/  468] time: 13.3184, train_loss: 0.16161561, train_accuracy: 0.9375, test_Accuracy: 0.9292\n",
      "Epoch: [ 0] [  141/  468] time: 13.4140, train_loss: 0.14156353, train_accuracy: 0.9609, test_Accuracy: 0.9286\n",
      "Epoch: [ 0] [  142/  468] time: 13.5064, train_loss: 0.18151033, train_accuracy: 0.9531, test_Accuracy: 0.9289\n",
      "Epoch: [ 0] [  143/  468] time: 13.5949, train_loss: 0.22846630, train_accuracy: 0.9531, test_Accuracy: 0.9292\n",
      "Epoch: [ 0] [  144/  468] time: 13.6849, train_loss: 0.26298246, train_accuracy: 0.9062, test_Accuracy: 0.9313\n",
      "Epoch: [ 0] [  145/  468] time: 13.7733, train_loss: 0.29222068, train_accuracy: 0.8984, test_Accuracy: 0.9349\n",
      "Epoch: [ 0] [  146/  468] time: 13.8593, train_loss: 0.18649280, train_accuracy: 0.9609, test_Accuracy: 0.9357\n",
      "Epoch: [ 0] [  147/  468] time: 13.9478, train_loss: 0.19667470, train_accuracy: 0.9141, test_Accuracy: 0.9340\n",
      "Epoch: [ 0] [  148/  468] time: 14.0331, train_loss: 0.19258243, train_accuracy: 0.9219, test_Accuracy: 0.9310\n",
      "Epoch: [ 0] [  149/  468] time: 14.1204, train_loss: 0.12361165, train_accuracy: 0.9688, test_Accuracy: 0.9279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  150/  468] time: 14.2086, train_loss: 0.24271187, train_accuracy: 0.9219, test_Accuracy: 0.9277\n",
      "Epoch: [ 0] [  151/  468] time: 14.2952, train_loss: 0.12989327, train_accuracy: 0.9688, test_Accuracy: 0.9281\n",
      "Epoch: [ 0] [  152/  468] time: 14.3806, train_loss: 0.30649033, train_accuracy: 0.9062, test_Accuracy: 0.9293\n",
      "Epoch: [ 0] [  153/  468] time: 14.4679, train_loss: 0.22388302, train_accuracy: 0.9219, test_Accuracy: 0.9325\n",
      "Epoch: [ 0] [  154/  468] time: 14.5579, train_loss: 0.32642668, train_accuracy: 0.9219, test_Accuracy: 0.9343\n",
      "Epoch: [ 0] [  155/  468] time: 14.6443, train_loss: 0.23854570, train_accuracy: 0.9453, test_Accuracy: 0.9359\n",
      "Epoch: [ 0] [  156/  468] time: 14.7314, train_loss: 0.24339812, train_accuracy: 0.9297, test_Accuracy: 0.9362\n",
      "Epoch: [ 0] [  157/  468] time: 14.8164, train_loss: 0.26735684, train_accuracy: 0.9062, test_Accuracy: 0.9368\n",
      "Epoch: [ 0] [  158/  468] time: 14.9028, train_loss: 0.17396173, train_accuracy: 0.9297, test_Accuracy: 0.9369\n",
      "Epoch: [ 0] [  159/  468] time: 14.9933, train_loss: 0.15420187, train_accuracy: 0.9375, test_Accuracy: 0.9365\n",
      "Epoch: [ 0] [  160/  468] time: 15.0814, train_loss: 0.18821713, train_accuracy: 0.9453, test_Accuracy: 0.9351\n",
      "Epoch: [ 0] [  161/  468] time: 15.1664, train_loss: 0.17539254, train_accuracy: 0.9531, test_Accuracy: 0.9344\n",
      "Epoch: [ 0] [  162/  468] time: 15.2534, train_loss: 0.19255818, train_accuracy: 0.9609, test_Accuracy: 0.9348\n",
      "Epoch: [ 0] [  163/  468] time: 15.3412, train_loss: 0.15940942, train_accuracy: 0.9609, test_Accuracy: 0.9324\n",
      "Epoch: [ 0] [  164/  468] time: 15.4270, train_loss: 0.13526508, train_accuracy: 0.9453, test_Accuracy: 0.9309\n",
      "Epoch: [ 0] [  165/  468] time: 15.5158, train_loss: 0.24183352, train_accuracy: 0.9141, test_Accuracy: 0.9294\n",
      "Epoch: [ 0] [  166/  468] time: 15.6034, train_loss: 0.20813276, train_accuracy: 0.9375, test_Accuracy: 0.9305\n",
      "Epoch: [ 0] [  167/  468] time: 15.6891, train_loss: 0.32470328, train_accuracy: 0.9297, test_Accuracy: 0.9326\n",
      "Epoch: [ 0] [  168/  468] time: 15.7754, train_loss: 0.28125018, train_accuracy: 0.9297, test_Accuracy: 0.9340\n",
      "Epoch: [ 0] [  169/  468] time: 15.8608, train_loss: 0.24008688, train_accuracy: 0.9297, test_Accuracy: 0.9363\n",
      "Epoch: [ 0] [  170/  468] time: 15.9470, train_loss: 0.17925821, train_accuracy: 0.9688, test_Accuracy: 0.9366\n",
      "Epoch: [ 0] [  171/  468] time: 16.0329, train_loss: 0.23006670, train_accuracy: 0.9375, test_Accuracy: 0.9344\n",
      "Epoch: [ 0] [  172/  468] time: 16.1217, train_loss: 0.15658280, train_accuracy: 0.9609, test_Accuracy: 0.9330\n",
      "Epoch: [ 0] [  173/  468] time: 16.2090, train_loss: 0.27809697, train_accuracy: 0.9062, test_Accuracy: 0.9340\n",
      "Epoch: [ 0] [  174/  468] time: 16.2961, train_loss: 0.16993703, train_accuracy: 0.9609, test_Accuracy: 0.9345\n",
      "Epoch: [ 0] [  175/  468] time: 16.3983, train_loss: 0.10718270, train_accuracy: 0.9688, test_Accuracy: 0.9364\n",
      "Epoch: [ 0] [  176/  468] time: 16.4869, train_loss: 0.28329918, train_accuracy: 0.9375, test_Accuracy: 0.9378\n",
      "Epoch: [ 0] [  177/  468] time: 16.5741, train_loss: 0.21571042, train_accuracy: 0.9297, test_Accuracy: 0.9407\n",
      "Epoch: [ 0] [  178/  468] time: 16.6605, train_loss: 0.18175626, train_accuracy: 0.9453, test_Accuracy: 0.9409\n",
      "Epoch: [ 0] [  179/  468] time: 16.7465, train_loss: 0.12423591, train_accuracy: 0.9609, test_Accuracy: 0.9403\n",
      "Epoch: [ 0] [  180/  468] time: 16.8333, train_loss: 0.14490061, train_accuracy: 0.9766, test_Accuracy: 0.9402\n",
      "Epoch: [ 0] [  181/  468] time: 16.9194, train_loss: 0.20717996, train_accuracy: 0.9375, test_Accuracy: 0.9402\n",
      "Epoch: [ 0] [  182/  468] time: 17.0038, train_loss: 0.13078059, train_accuracy: 0.9453, test_Accuracy: 0.9394\n",
      "Epoch: [ 0] [  183/  468] time: 17.0918, train_loss: 0.21840116, train_accuracy: 0.9219, test_Accuracy: 0.9400\n",
      "Epoch: [ 0] [  184/  468] time: 17.1805, train_loss: 0.21852645, train_accuracy: 0.9531, test_Accuracy: 0.9401\n",
      "Epoch: [ 0] [  185/  468] time: 17.2661, train_loss: 0.27186748, train_accuracy: 0.9297, test_Accuracy: 0.9391\n",
      "Epoch: [ 0] [  186/  468] time: 17.3539, train_loss: 0.19481471, train_accuracy: 0.9297, test_Accuracy: 0.9371\n",
      "Epoch: [ 0] [  187/  468] time: 17.4434, train_loss: 0.21583788, train_accuracy: 0.9219, test_Accuracy: 0.9359\n",
      "Epoch: [ 0] [  188/  468] time: 17.5289, train_loss: 0.18869013, train_accuracy: 0.9531, test_Accuracy: 0.9362\n",
      "Epoch: [ 0] [  189/  468] time: 17.6220, train_loss: 0.17569008, train_accuracy: 0.9531, test_Accuracy: 0.9373\n",
      "Epoch: [ 0] [  190/  468] time: 17.7085, train_loss: 0.17427993, train_accuracy: 0.9688, test_Accuracy: 0.9377\n",
      "Epoch: [ 0] [  191/  468] time: 17.7996, train_loss: 0.21780306, train_accuracy: 0.9375, test_Accuracy: 0.9397\n",
      "Epoch: [ 0] [  192/  468] time: 17.8873, train_loss: 0.12529278, train_accuracy: 0.9766, test_Accuracy: 0.9424\n",
      "Epoch: [ 0] [  193/  468] time: 17.9755, train_loss: 0.19533348, train_accuracy: 0.9453, test_Accuracy: 0.9429\n",
      "Epoch: [ 0] [  194/  468] time: 18.0647, train_loss: 0.22014633, train_accuracy: 0.9453, test_Accuracy: 0.9411\n",
      "Epoch: [ 0] [  195/  468] time: 18.1522, train_loss: 0.23370695, train_accuracy: 0.9375, test_Accuracy: 0.9420\n",
      "Epoch: [ 0] [  196/  468] time: 18.2406, train_loss: 0.22004253, train_accuracy: 0.9375, test_Accuracy: 0.9420\n",
      "Epoch: [ 0] [  197/  468] time: 18.3272, train_loss: 0.13291347, train_accuracy: 0.9609, test_Accuracy: 0.9401\n",
      "Epoch: [ 0] [  198/  468] time: 18.4133, train_loss: 0.16457918, train_accuracy: 0.9688, test_Accuracy: 0.9388\n",
      "Epoch: [ 0] [  199/  468] time: 18.5049, train_loss: 0.16863263, train_accuracy: 0.9453, test_Accuracy: 0.9394\n",
      "Epoch: [ 0] [  200/  468] time: 18.5934, train_loss: 0.17517313, train_accuracy: 0.9531, test_Accuracy: 0.9399\n",
      "Epoch: [ 0] [  201/  468] time: 18.6808, train_loss: 0.27389464, train_accuracy: 0.9219, test_Accuracy: 0.9395\n",
      "Epoch: [ 0] [  202/  468] time: 18.7662, train_loss: 0.18686274, train_accuracy: 0.9375, test_Accuracy: 0.9417\n",
      "Epoch: [ 0] [  203/  468] time: 18.8515, train_loss: 0.14519913, train_accuracy: 0.9453, test_Accuracy: 0.9410\n",
      "Epoch: [ 0] [  204/  468] time: 18.9379, train_loss: 0.16915941, train_accuracy: 0.9688, test_Accuracy: 0.9417\n",
      "Epoch: [ 0] [  205/  468] time: 19.0283, train_loss: 0.08541926, train_accuracy: 0.9922, test_Accuracy: 0.9405\n",
      "Epoch: [ 0] [  206/  468] time: 19.1240, train_loss: 0.16138870, train_accuracy: 0.9453, test_Accuracy: 0.9395\n",
      "Epoch: [ 0] [  207/  468] time: 19.2151, train_loss: 0.16021119, train_accuracy: 0.9609, test_Accuracy: 0.9393\n",
      "Epoch: [ 0] [  208/  468] time: 19.3002, train_loss: 0.16234098, train_accuracy: 0.9609, test_Accuracy: 0.9394\n",
      "Epoch: [ 0] [  209/  468] time: 19.3907, train_loss: 0.24901122, train_accuracy: 0.9219, test_Accuracy: 0.9408\n",
      "Epoch: [ 0] [  210/  468] time: 19.4790, train_loss: 0.18037322, train_accuracy: 0.9375, test_Accuracy: 0.9388\n",
      "Epoch: [ 0] [  211/  468] time: 19.5699, train_loss: 0.20538577, train_accuracy: 0.9219, test_Accuracy: 0.9381\n",
      "Epoch: [ 0] [  212/  468] time: 19.6576, train_loss: 0.26907220, train_accuracy: 0.9219, test_Accuracy: 0.9380\n",
      "Epoch: [ 0] [  213/  468] time: 19.7444, train_loss: 0.16765885, train_accuracy: 0.9375, test_Accuracy: 0.9402\n",
      "Epoch: [ 0] [  214/  468] time: 19.8298, train_loss: 0.21690948, train_accuracy: 0.9219, test_Accuracy: 0.9415\n",
      "Epoch: [ 0] [  215/  468] time: 19.9137, train_loss: 0.16290125, train_accuracy: 0.9375, test_Accuracy: 0.9425\n",
      "Epoch: [ 0] [  216/  468] time: 20.0024, train_loss: 0.16021398, train_accuracy: 0.9688, test_Accuracy: 0.9427\n",
      "Epoch: [ 0] [  217/  468] time: 20.0906, train_loss: 0.16443634, train_accuracy: 0.9531, test_Accuracy: 0.9442\n",
      "Epoch: [ 0] [  218/  468] time: 20.1778, train_loss: 0.11526604, train_accuracy: 0.9688, test_Accuracy: 0.9423\n",
      "Epoch: [ 0] [  219/  468] time: 20.2646, train_loss: 0.10178271, train_accuracy: 0.9922, test_Accuracy: 0.9426\n",
      "Epoch: [ 0] [  220/  468] time: 20.3513, train_loss: 0.12956586, train_accuracy: 0.9688, test_Accuracy: 0.9420\n",
      "Epoch: [ 0] [  221/  468] time: 20.4378, train_loss: 0.14817727, train_accuracy: 0.9609, test_Accuracy: 0.9414\n",
      "Epoch: [ 0] [  222/  468] time: 20.5272, train_loss: 0.29848132, train_accuracy: 0.9375, test_Accuracy: 0.9408\n",
      "Epoch: [ 0] [  223/  468] time: 20.6171, train_loss: 0.28688166, train_accuracy: 0.8984, test_Accuracy: 0.9418\n",
      "Epoch: [ 0] [  224/  468] time: 20.7033, train_loss: 0.19337228, train_accuracy: 0.9453, test_Accuracy: 0.9411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  225/  468] time: 20.7928, train_loss: 0.32288361, train_accuracy: 0.9297, test_Accuracy: 0.9410\n",
      "Epoch: [ 0] [  226/  468] time: 20.8871, train_loss: 0.22472426, train_accuracy: 0.9375, test_Accuracy: 0.9412\n",
      "Epoch: [ 0] [  227/  468] time: 20.9786, train_loss: 0.33764786, train_accuracy: 0.9141, test_Accuracy: 0.9426\n",
      "Epoch: [ 0] [  228/  468] time: 21.0626, train_loss: 0.17863293, train_accuracy: 0.9688, test_Accuracy: 0.9445\n",
      "Epoch: [ 0] [  229/  468] time: 21.1489, train_loss: 0.23461325, train_accuracy: 0.9453, test_Accuracy: 0.9448\n",
      "Epoch: [ 0] [  230/  468] time: 21.2325, train_loss: 0.24174951, train_accuracy: 0.9297, test_Accuracy: 0.9430\n",
      "Epoch: [ 0] [  231/  468] time: 21.3200, train_loss: 0.23720506, train_accuracy: 0.9609, test_Accuracy: 0.9438\n",
      "Epoch: [ 0] [  232/  468] time: 21.4056, train_loss: 0.22929281, train_accuracy: 0.9531, test_Accuracy: 0.9429\n",
      "Epoch: [ 0] [  233/  468] time: 21.4944, train_loss: 0.19252551, train_accuracy: 0.9375, test_Accuracy: 0.9380\n",
      "Epoch: [ 0] [  234/  468] time: 21.5808, train_loss: 0.25450289, train_accuracy: 0.8984, test_Accuracy: 0.9376\n",
      "Epoch: [ 0] [  235/  468] time: 21.6643, train_loss: 0.22738029, train_accuracy: 0.9297, test_Accuracy: 0.9399\n",
      "Epoch: [ 0] [  236/  468] time: 21.7488, train_loss: 0.15657367, train_accuracy: 0.9609, test_Accuracy: 0.9384\n",
      "Epoch: [ 0] [  237/  468] time: 21.8413, train_loss: 0.28436580, train_accuracy: 0.9375, test_Accuracy: 0.9388\n",
      "Epoch: [ 0] [  238/  468] time: 21.9250, train_loss: 0.25673816, train_accuracy: 0.9062, test_Accuracy: 0.9382\n",
      "Epoch: [ 0] [  239/  468] time: 22.0270, train_loss: 0.19684497, train_accuracy: 0.9453, test_Accuracy: 0.9388\n",
      "Epoch: [ 0] [  240/  468] time: 22.1144, train_loss: 0.18370068, train_accuracy: 0.9297, test_Accuracy: 0.9398\n",
      "Epoch: [ 0] [  241/  468] time: 22.2006, train_loss: 0.21665934, train_accuracy: 0.9375, test_Accuracy: 0.9435\n",
      "Epoch: [ 0] [  242/  468] time: 22.2928, train_loss: 0.21478076, train_accuracy: 0.9453, test_Accuracy: 0.9466\n",
      "Epoch: [ 0] [  243/  468] time: 22.3807, train_loss: 0.15015456, train_accuracy: 0.9453, test_Accuracy: 0.9461\n",
      "Epoch: [ 0] [  244/  468] time: 22.4663, train_loss: 0.19708809, train_accuracy: 0.9375, test_Accuracy: 0.9452\n",
      "Epoch: [ 0] [  245/  468] time: 22.5616, train_loss: 0.18774368, train_accuracy: 0.9297, test_Accuracy: 0.9450\n",
      "Epoch: [ 0] [  246/  468] time: 22.6473, train_loss: 0.24228339, train_accuracy: 0.9297, test_Accuracy: 0.9454\n",
      "Epoch: [ 0] [  247/  468] time: 22.7407, train_loss: 0.09980544, train_accuracy: 0.9766, test_Accuracy: 0.9454\n",
      "Epoch: [ 0] [  248/  468] time: 22.8284, train_loss: 0.12231474, train_accuracy: 0.9766, test_Accuracy: 0.9451\n",
      "Epoch: [ 0] [  249/  468] time: 22.9195, train_loss: 0.15861079, train_accuracy: 0.9609, test_Accuracy: 0.9455\n",
      "Epoch: [ 0] [  250/  468] time: 23.0084, train_loss: 0.22531255, train_accuracy: 0.9453, test_Accuracy: 0.9458\n",
      "Epoch: [ 0] [  251/  468] time: 23.0991, train_loss: 0.07885036, train_accuracy: 0.9922, test_Accuracy: 0.9450\n",
      "Epoch: [ 0] [  252/  468] time: 23.1859, train_loss: 0.27908382, train_accuracy: 0.9453, test_Accuracy: 0.9430\n",
      "Epoch: [ 0] [  253/  468] time: 23.2728, train_loss: 0.19943610, train_accuracy: 0.9531, test_Accuracy: 0.9425\n",
      "Epoch: [ 0] [  254/  468] time: 23.3664, train_loss: 0.19061357, train_accuracy: 0.9453, test_Accuracy: 0.9416\n",
      "Epoch: [ 0] [  255/  468] time: 23.4581, train_loss: 0.16731519, train_accuracy: 0.9453, test_Accuracy: 0.9425\n",
      "Epoch: [ 0] [  256/  468] time: 23.5512, train_loss: 0.17804247, train_accuracy: 0.9609, test_Accuracy: 0.9443\n",
      "Epoch: [ 0] [  257/  468] time: 23.6394, train_loss: 0.22333886, train_accuracy: 0.9297, test_Accuracy: 0.9463\n",
      "Epoch: [ 0] [  258/  468] time: 23.7264, train_loss: 0.06539194, train_accuracy: 0.9766, test_Accuracy: 0.9475\n",
      "Epoch: [ 0] [  259/  468] time: 23.8117, train_loss: 0.14252587, train_accuracy: 0.9453, test_Accuracy: 0.9468\n",
      "Epoch: [ 0] [  260/  468] time: 23.9072, train_loss: 0.22233459, train_accuracy: 0.9375, test_Accuracy: 0.9468\n",
      "Epoch: [ 0] [  261/  468] time: 23.9978, train_loss: 0.18108107, train_accuracy: 0.9375, test_Accuracy: 0.9479\n",
      "Epoch: [ 0] [  262/  468] time: 24.0845, train_loss: 0.11497475, train_accuracy: 0.9688, test_Accuracy: 0.9485\n",
      "Epoch: [ 0] [  263/  468] time: 24.1713, train_loss: 0.17000130, train_accuracy: 0.9609, test_Accuracy: 0.9483\n",
      "Epoch: [ 0] [  264/  468] time: 24.2574, train_loss: 0.21895279, train_accuracy: 0.9609, test_Accuracy: 0.9482\n",
      "Epoch: [ 0] [  265/  468] time: 24.3418, train_loss: 0.15249424, train_accuracy: 0.9531, test_Accuracy: 0.9486\n",
      "Epoch: [ 0] [  266/  468] time: 24.4270, train_loss: 0.29283631, train_accuracy: 0.9219, test_Accuracy: 0.9489\n",
      "Epoch: [ 0] [  267/  468] time: 24.5136, train_loss: 0.11147097, train_accuracy: 0.9844, test_Accuracy: 0.9488\n",
      "Epoch: [ 0] [  268/  468] time: 24.5971, train_loss: 0.16226889, train_accuracy: 0.9531, test_Accuracy: 0.9483\n",
      "Epoch: [ 0] [  269/  468] time: 24.6809, train_loss: 0.16348752, train_accuracy: 0.9219, test_Accuracy: 0.9476\n",
      "Epoch: [ 0] [  270/  468] time: 24.7675, train_loss: 0.11481918, train_accuracy: 0.9688, test_Accuracy: 0.9471\n",
      "Epoch: [ 0] [  271/  468] time: 24.8523, train_loss: 0.12391552, train_accuracy: 0.9609, test_Accuracy: 0.9476\n",
      "Epoch: [ 0] [  272/  468] time: 24.9424, train_loss: 0.17647731, train_accuracy: 0.9297, test_Accuracy: 0.9464\n",
      "Epoch: [ 0] [  273/  468] time: 25.0316, train_loss: 0.11601005, train_accuracy: 0.9609, test_Accuracy: 0.9469\n",
      "Epoch: [ 0] [  274/  468] time: 25.1186, train_loss: 0.14469558, train_accuracy: 0.9766, test_Accuracy: 0.9468\n",
      "Epoch: [ 0] [  275/  468] time: 25.2040, train_loss: 0.08846422, train_accuracy: 0.9766, test_Accuracy: 0.9474\n",
      "Epoch: [ 0] [  276/  468] time: 25.2902, train_loss: 0.26907480, train_accuracy: 0.9219, test_Accuracy: 0.9492\n",
      "Epoch: [ 0] [  277/  468] time: 25.3758, train_loss: 0.18423758, train_accuracy: 0.9531, test_Accuracy: 0.9492\n",
      "Epoch: [ 0] [  278/  468] time: 25.4633, train_loss: 0.19037154, train_accuracy: 0.9219, test_Accuracy: 0.9496\n",
      "Epoch: [ 0] [  279/  468] time: 25.5524, train_loss: 0.24634054, train_accuracy: 0.9375, test_Accuracy: 0.9494\n",
      "Epoch: [ 0] [  280/  468] time: 25.6382, train_loss: 0.10250877, train_accuracy: 0.9609, test_Accuracy: 0.9465\n",
      "Epoch: [ 0] [  281/  468] time: 25.7255, train_loss: 0.07490200, train_accuracy: 0.9844, test_Accuracy: 0.9458\n",
      "Epoch: [ 0] [  282/  468] time: 25.8147, train_loss: 0.22112274, train_accuracy: 0.9375, test_Accuracy: 0.9461\n",
      "Epoch: [ 0] [  283/  468] time: 25.9006, train_loss: 0.16116388, train_accuracy: 0.9453, test_Accuracy: 0.9456\n",
      "Epoch: [ 0] [  284/  468] time: 25.9848, train_loss: 0.18271059, train_accuracy: 0.9141, test_Accuracy: 0.9480\n",
      "Epoch: [ 0] [  285/  468] time: 26.0724, train_loss: 0.12271475, train_accuracy: 0.9766, test_Accuracy: 0.9480\n",
      "Epoch: [ 0] [  286/  468] time: 26.1563, train_loss: 0.21536539, train_accuracy: 0.9375, test_Accuracy: 0.9479\n",
      "Epoch: [ 0] [  287/  468] time: 26.2487, train_loss: 0.12449554, train_accuracy: 0.9688, test_Accuracy: 0.9486\n",
      "Epoch: [ 0] [  288/  468] time: 26.3392, train_loss: 0.14099270, train_accuracy: 0.9531, test_Accuracy: 0.9492\n",
      "Epoch: [ 0] [  289/  468] time: 26.4258, train_loss: 0.14436275, train_accuracy: 0.9609, test_Accuracy: 0.9475\n",
      "Epoch: [ 0] [  290/  468] time: 26.5215, train_loss: 0.11153415, train_accuracy: 0.9531, test_Accuracy: 0.9474\n",
      "Epoch: [ 0] [  291/  468] time: 26.6105, train_loss: 0.12964430, train_accuracy: 0.9766, test_Accuracy: 0.9455\n",
      "Epoch: [ 0] [  292/  468] time: 26.6939, train_loss: 0.15884703, train_accuracy: 0.9453, test_Accuracy: 0.9441\n",
      "Epoch: [ 0] [  293/  468] time: 26.7856, train_loss: 0.12802455, train_accuracy: 0.9453, test_Accuracy: 0.9456\n",
      "Epoch: [ 0] [  294/  468] time: 26.8720, train_loss: 0.19902718, train_accuracy: 0.9453, test_Accuracy: 0.9505\n",
      "Epoch: [ 0] [  295/  468] time: 26.9573, train_loss: 0.09152459, train_accuracy: 0.9766, test_Accuracy: 0.9532\n",
      "Epoch: [ 0] [  296/  468] time: 27.0403, train_loss: 0.20362459, train_accuracy: 0.9531, test_Accuracy: 0.9529\n",
      "Epoch: [ 0] [  297/  468] time: 27.1267, train_loss: 0.20222253, train_accuracy: 0.9531, test_Accuracy: 0.9519\n",
      "Epoch: [ 0] [  298/  468] time: 27.2116, train_loss: 0.15326133, train_accuracy: 0.9766, test_Accuracy: 0.9503\n",
      "Epoch: [ 0] [  299/  468] time: 27.3036, train_loss: 0.19761340, train_accuracy: 0.9453, test_Accuracy: 0.9482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  300/  468] time: 27.3927, train_loss: 0.13398191, train_accuracy: 0.9609, test_Accuracy: 0.9467\n",
      "Epoch: [ 0] [  301/  468] time: 27.4805, train_loss: 0.20146182, train_accuracy: 0.9375, test_Accuracy: 0.9460\n",
      "Epoch: [ 0] [  302/  468] time: 27.5662, train_loss: 0.15448633, train_accuracy: 0.9609, test_Accuracy: 0.9479\n",
      "Epoch: [ 0] [  303/  468] time: 27.6577, train_loss: 0.25520337, train_accuracy: 0.9453, test_Accuracy: 0.9503\n",
      "Epoch: [ 0] [  304/  468] time: 27.7433, train_loss: 0.07880191, train_accuracy: 0.9766, test_Accuracy: 0.9492\n",
      "Epoch: [ 0] [  305/  468] time: 27.8278, train_loss: 0.08835080, train_accuracy: 0.9766, test_Accuracy: 0.9478\n",
      "Epoch: [ 0] [  306/  468] time: 27.9211, train_loss: 0.15020545, train_accuracy: 0.9531, test_Accuracy: 0.9485\n",
      "Epoch: [ 0] [  307/  468] time: 28.0069, train_loss: 0.26754624, train_accuracy: 0.9375, test_Accuracy: 0.9509\n",
      "Epoch: [ 0] [  308/  468] time: 28.0948, train_loss: 0.22444752, train_accuracy: 0.9375, test_Accuracy: 0.9525\n",
      "Epoch: [ 0] [  309/  468] time: 28.1842, train_loss: 0.19532350, train_accuracy: 0.9219, test_Accuracy: 0.9501\n",
      "Epoch: [ 0] [  310/  468] time: 28.2696, train_loss: 0.18714890, train_accuracy: 0.9375, test_Accuracy: 0.9489\n",
      "Epoch: [ 0] [  311/  468] time: 28.3533, train_loss: 0.20587489, train_accuracy: 0.9375, test_Accuracy: 0.9464\n",
      "Epoch: [ 0] [  312/  468] time: 28.4390, train_loss: 0.13109052, train_accuracy: 0.9531, test_Accuracy: 0.9464\n",
      "Epoch: [ 0] [  313/  468] time: 28.5298, train_loss: 0.13035913, train_accuracy: 0.9609, test_Accuracy: 0.9464\n",
      "Epoch: [ 0] [  314/  468] time: 28.6163, train_loss: 0.22125837, train_accuracy: 0.9531, test_Accuracy: 0.9475\n",
      "Epoch: [ 0] [  315/  468] time: 28.7050, train_loss: 0.14337698, train_accuracy: 0.9609, test_Accuracy: 0.9496\n",
      "Epoch: [ 0] [  316/  468] time: 28.7964, train_loss: 0.11655875, train_accuracy: 0.9453, test_Accuracy: 0.9498\n",
      "Epoch: [ 0] [  317/  468] time: 28.8806, train_loss: 0.19470635, train_accuracy: 0.9531, test_Accuracy: 0.9515\n",
      "Epoch: [ 0] [  318/  468] time: 28.9664, train_loss: 0.15469395, train_accuracy: 0.9531, test_Accuracy: 0.9527\n",
      "Epoch: [ 0] [  319/  468] time: 29.0547, train_loss: 0.14958811, train_accuracy: 0.9531, test_Accuracy: 0.9531\n",
      "Epoch: [ 0] [  320/  468] time: 29.1396, train_loss: 0.10639299, train_accuracy: 0.9766, test_Accuracy: 0.9536\n",
      "Epoch: [ 0] [  321/  468] time: 29.2259, train_loss: 0.09582134, train_accuracy: 0.9688, test_Accuracy: 0.9538\n",
      "Epoch: [ 0] [  322/  468] time: 29.3133, train_loss: 0.11743180, train_accuracy: 0.9688, test_Accuracy: 0.9535\n",
      "Epoch: [ 0] [  323/  468] time: 29.4001, train_loss: 0.16151372, train_accuracy: 0.9531, test_Accuracy: 0.9539\n",
      "Epoch: [ 0] [  324/  468] time: 29.4861, train_loss: 0.15810499, train_accuracy: 0.9531, test_Accuracy: 0.9535\n",
      "Epoch: [ 0] [  325/  468] time: 29.5743, train_loss: 0.23048042, train_accuracy: 0.9375, test_Accuracy: 0.9531\n",
      "Epoch: [ 0] [  326/  468] time: 29.6575, train_loss: 0.18676898, train_accuracy: 0.9609, test_Accuracy: 0.9539\n",
      "Epoch: [ 0] [  327/  468] time: 29.7450, train_loss: 0.16341600, train_accuracy: 0.9453, test_Accuracy: 0.9526\n",
      "Epoch: [ 0] [  328/  468] time: 29.8293, train_loss: 0.14792691, train_accuracy: 0.9531, test_Accuracy: 0.9522\n",
      "Epoch: [ 0] [  329/  468] time: 29.9131, train_loss: 0.19572443, train_accuracy: 0.9453, test_Accuracy: 0.9521\n",
      "Epoch: [ 0] [  330/  468] time: 30.0066, train_loss: 0.12759954, train_accuracy: 0.9688, test_Accuracy: 0.9502\n",
      "Epoch: [ 0] [  331/  468] time: 30.0966, train_loss: 0.14313909, train_accuracy: 0.9688, test_Accuracy: 0.9497\n",
      "Epoch: [ 0] [  332/  468] time: 30.1833, train_loss: 0.13439757, train_accuracy: 0.9844, test_Accuracy: 0.9498\n",
      "Epoch: [ 0] [  333/  468] time: 30.2702, train_loss: 0.27679127, train_accuracy: 0.9375, test_Accuracy: 0.9511\n",
      "Epoch: [ 0] [  334/  468] time: 30.3540, train_loss: 0.15890980, train_accuracy: 0.9609, test_Accuracy: 0.9543\n",
      "Epoch: [ 0] [  335/  468] time: 30.4390, train_loss: 0.08276981, train_accuracy: 0.9766, test_Accuracy: 0.9556\n",
      "Epoch: [ 0] [  336/  468] time: 30.5285, train_loss: 0.15492231, train_accuracy: 0.9688, test_Accuracy: 0.9555\n",
      "Epoch: [ 0] [  337/  468] time: 30.6150, train_loss: 0.20546627, train_accuracy: 0.9219, test_Accuracy: 0.9558\n",
      "Epoch: [ 0] [  338/  468] time: 30.6995, train_loss: 0.13354740, train_accuracy: 0.9609, test_Accuracy: 0.9548\n",
      "Epoch: [ 0] [  339/  468] time: 30.7885, train_loss: 0.10177317, train_accuracy: 0.9844, test_Accuracy: 0.9518\n",
      "Epoch: [ 0] [  340/  468] time: 30.8781, train_loss: 0.25581568, train_accuracy: 0.8906, test_Accuracy: 0.9518\n",
      "Epoch: [ 0] [  341/  468] time: 30.9668, train_loss: 0.10480537, train_accuracy: 0.9766, test_Accuracy: 0.9510\n",
      "Epoch: [ 0] [  342/  468] time: 31.0617, train_loss: 0.13494426, train_accuracy: 0.9766, test_Accuracy: 0.9490\n",
      "Epoch: [ 0] [  343/  468] time: 31.1513, train_loss: 0.14863864, train_accuracy: 0.9609, test_Accuracy: 0.9504\n",
      "Epoch: [ 0] [  344/  468] time: 31.2455, train_loss: 0.10179593, train_accuracy: 0.9688, test_Accuracy: 0.9532\n",
      "Epoch: [ 0] [  345/  468] time: 31.3351, train_loss: 0.18260545, train_accuracy: 0.9609, test_Accuracy: 0.9540\n",
      "Epoch: [ 0] [  346/  468] time: 31.4213, train_loss: 0.15536650, train_accuracy: 0.9688, test_Accuracy: 0.9537\n",
      "Epoch: [ 0] [  347/  468] time: 31.5074, train_loss: 0.15533617, train_accuracy: 0.9453, test_Accuracy: 0.9531\n",
      "Epoch: [ 0] [  348/  468] time: 31.5942, train_loss: 0.21207127, train_accuracy: 0.9531, test_Accuracy: 0.9534\n",
      "Epoch: [ 0] [  349/  468] time: 31.6782, train_loss: 0.16436310, train_accuracy: 0.9688, test_Accuracy: 0.9519\n",
      "Epoch: [ 0] [  350/  468] time: 31.7655, train_loss: 0.14251059, train_accuracy: 0.9219, test_Accuracy: 0.9529\n",
      "Epoch: [ 0] [  351/  468] time: 31.8518, train_loss: 0.25368741, train_accuracy: 0.8984, test_Accuracy: 0.9539\n",
      "Epoch: [ 0] [  352/  468] time: 31.9361, train_loss: 0.17678988, train_accuracy: 0.9453, test_Accuracy: 0.9533\n",
      "Epoch: [ 0] [  353/  468] time: 32.0223, train_loss: 0.23969848, train_accuracy: 0.9375, test_Accuracy: 0.9527\n",
      "Epoch: [ 0] [  354/  468] time: 32.1235, train_loss: 0.18812826, train_accuracy: 0.9297, test_Accuracy: 0.9520\n",
      "Epoch: [ 0] [  355/  468] time: 32.2156, train_loss: 0.18957563, train_accuracy: 0.9219, test_Accuracy: 0.9510\n",
      "Epoch: [ 0] [  356/  468] time: 32.3059, train_loss: 0.11952329, train_accuracy: 0.9688, test_Accuracy: 0.9518\n",
      "Epoch: [ 0] [  357/  468] time: 32.3939, train_loss: 0.10927061, train_accuracy: 0.9688, test_Accuracy: 0.9527\n",
      "Epoch: [ 0] [  358/  468] time: 32.4824, train_loss: 0.21229452, train_accuracy: 0.9297, test_Accuracy: 0.9538\n",
      "Epoch: [ 0] [  359/  468] time: 32.5692, train_loss: 0.14580885, train_accuracy: 0.9453, test_Accuracy: 0.9550\n",
      "Epoch: [ 0] [  360/  468] time: 32.6589, train_loss: 0.08961774, train_accuracy: 0.9844, test_Accuracy: 0.9545\n",
      "Epoch: [ 0] [  361/  468] time: 32.7501, train_loss: 0.08800291, train_accuracy: 0.9766, test_Accuracy: 0.9544\n",
      "Epoch: [ 0] [  362/  468] time: 32.8417, train_loss: 0.17337862, train_accuracy: 0.9453, test_Accuracy: 0.9549\n",
      "Epoch: [ 0] [  363/  468] time: 32.9314, train_loss: 0.13011831, train_accuracy: 0.9688, test_Accuracy: 0.9556\n",
      "Epoch: [ 0] [  364/  468] time: 33.0186, train_loss: 0.11325341, train_accuracy: 0.9531, test_Accuracy: 0.9548\n",
      "Epoch: [ 0] [  365/  468] time: 33.1040, train_loss: 0.10230508, train_accuracy: 0.9609, test_Accuracy: 0.9555\n",
      "Epoch: [ 0] [  366/  468] time: 33.1916, train_loss: 0.12710857, train_accuracy: 0.9531, test_Accuracy: 0.9551\n",
      "Epoch: [ 0] [  367/  468] time: 33.2755, train_loss: 0.07346909, train_accuracy: 0.9844, test_Accuracy: 0.9550\n",
      "Epoch: [ 0] [  368/  468] time: 33.3665, train_loss: 0.15968150, train_accuracy: 0.9609, test_Accuracy: 0.9542\n",
      "Epoch: [ 0] [  369/  468] time: 33.4616, train_loss: 0.18815252, train_accuracy: 0.9297, test_Accuracy: 0.9546\n",
      "Epoch: [ 0] [  370/  468] time: 33.5533, train_loss: 0.27167830, train_accuracy: 0.9375, test_Accuracy: 0.9545\n",
      "Epoch: [ 0] [  371/  468] time: 33.6393, train_loss: 0.07829680, train_accuracy: 0.9844, test_Accuracy: 0.9548\n",
      "Epoch: [ 0] [  372/  468] time: 33.7253, train_loss: 0.18208365, train_accuracy: 0.9531, test_Accuracy: 0.9571\n",
      "Epoch: [ 0] [  373/  468] time: 33.8108, train_loss: 0.15295511, train_accuracy: 0.9688, test_Accuracy: 0.9564\n",
      "Epoch: [ 0] [  374/  468] time: 33.8981, train_loss: 0.21481320, train_accuracy: 0.9453, test_Accuracy: 0.9576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  375/  468] time: 33.9995, train_loss: 0.09185401, train_accuracy: 0.9844, test_Accuracy: 0.9566\n",
      "Epoch: [ 0] [  376/  468] time: 34.1128, train_loss: 0.12932323, train_accuracy: 0.9609, test_Accuracy: 0.9546\n",
      "Epoch: [ 0] [  377/  468] time: 34.2246, train_loss: 0.15024242, train_accuracy: 0.9688, test_Accuracy: 0.9538\n",
      "Epoch: [ 0] [  378/  468] time: 34.3113, train_loss: 0.08063377, train_accuracy: 0.9844, test_Accuracy: 0.9535\n",
      "Epoch: [ 0] [  379/  468] time: 34.3992, train_loss: 0.13662067, train_accuracy: 0.9688, test_Accuracy: 0.9538\n",
      "Epoch: [ 0] [  380/  468] time: 34.4869, train_loss: 0.11290300, train_accuracy: 0.9688, test_Accuracy: 0.9530\n",
      "Epoch: [ 0] [  381/  468] time: 34.5802, train_loss: 0.14997181, train_accuracy: 0.9609, test_Accuracy: 0.9529\n",
      "Epoch: [ 0] [  382/  468] time: 34.6697, train_loss: 0.17041759, train_accuracy: 0.9531, test_Accuracy: 0.9523\n",
      "Epoch: [ 0] [  383/  468] time: 34.7545, train_loss: 0.18390323, train_accuracy: 0.9531, test_Accuracy: 0.9496\n",
      "Epoch: [ 0] [  384/  468] time: 34.8371, train_loss: 0.11648699, train_accuracy: 0.9688, test_Accuracy: 0.9487\n",
      "Epoch: [ 0] [  385/  468] time: 34.9231, train_loss: 0.20630306, train_accuracy: 0.9531, test_Accuracy: 0.9494\n",
      "Epoch: [ 0] [  386/  468] time: 35.0256, train_loss: 0.13276376, train_accuracy: 0.9688, test_Accuracy: 0.9482\n",
      "Epoch: [ 0] [  387/  468] time: 35.1386, train_loss: 0.17656071, train_accuracy: 0.9453, test_Accuracy: 0.9488\n",
      "Epoch: [ 0] [  388/  468] time: 35.2373, train_loss: 0.11490801, train_accuracy: 0.9531, test_Accuracy: 0.9518\n",
      "Epoch: [ 0] [  389/  468] time: 35.3261, train_loss: 0.13514400, train_accuracy: 0.9609, test_Accuracy: 0.9532\n",
      "Epoch: [ 0] [  390/  468] time: 35.4121, train_loss: 0.13263512, train_accuracy: 0.9609, test_Accuracy: 0.9528\n",
      "Epoch: [ 0] [  391/  468] time: 35.5024, train_loss: 0.12153625, train_accuracy: 0.9609, test_Accuracy: 0.9521\n",
      "Epoch: [ 0] [  392/  468] time: 35.5866, train_loss: 0.15767708, train_accuracy: 0.9453, test_Accuracy: 0.9501\n",
      "Epoch: [ 0] [  393/  468] time: 35.6699, train_loss: 0.10638516, train_accuracy: 0.9609, test_Accuracy: 0.9484\n",
      "Epoch: [ 0] [  394/  468] time: 35.7558, train_loss: 0.14851375, train_accuracy: 0.9453, test_Accuracy: 0.9505\n",
      "Epoch: [ 0] [  395/  468] time: 35.8508, train_loss: 0.19103234, train_accuracy: 0.9375, test_Accuracy: 0.9531\n",
      "Epoch: [ 0] [  396/  468] time: 35.9438, train_loss: 0.12429054, train_accuracy: 0.9609, test_Accuracy: 0.9554\n",
      "Epoch: [ 0] [  397/  468] time: 36.0351, train_loss: 0.16253260, train_accuracy: 0.9609, test_Accuracy: 0.9557\n",
      "Epoch: [ 0] [  398/  468] time: 36.1210, train_loss: 0.10650809, train_accuracy: 0.9766, test_Accuracy: 0.9538\n",
      "Epoch: [ 0] [  399/  468] time: 36.2048, train_loss: 0.11596913, train_accuracy: 0.9766, test_Accuracy: 0.9518\n",
      "Epoch: [ 0] [  400/  468] time: 36.2886, train_loss: 0.17076024, train_accuracy: 0.9453, test_Accuracy: 0.9494\n",
      "Epoch: [ 0] [  401/  468] time: 36.3728, train_loss: 0.21903014, train_accuracy: 0.9219, test_Accuracy: 0.9481\n",
      "Epoch: [ 0] [  402/  468] time: 36.4639, train_loss: 0.17152619, train_accuracy: 0.9453, test_Accuracy: 0.9492\n",
      "Epoch: [ 0] [  403/  468] time: 36.5544, train_loss: 0.08781631, train_accuracy: 0.9766, test_Accuracy: 0.9539\n",
      "Epoch: [ 0] [  404/  468] time: 36.6467, train_loss: 0.15768681, train_accuracy: 0.9609, test_Accuracy: 0.9600\n",
      "Epoch: [ 0] [  405/  468] time: 36.7425, train_loss: 0.20369531, train_accuracy: 0.9609, test_Accuracy: 0.9606\n",
      "Epoch: [ 0] [  406/  468] time: 36.8363, train_loss: 0.24149492, train_accuracy: 0.9375, test_Accuracy: 0.9605\n",
      "Epoch: [ 0] [  407/  468] time: 36.9242, train_loss: 0.09626885, train_accuracy: 0.9844, test_Accuracy: 0.9596\n",
      "Epoch: [ 0] [  408/  468] time: 37.0075, train_loss: 0.08210670, train_accuracy: 0.9766, test_Accuracy: 0.9572\n",
      "Epoch: [ 0] [  409/  468] time: 37.0942, train_loss: 0.13728616, train_accuracy: 0.9453, test_Accuracy: 0.9550\n",
      "Epoch: [ 0] [  410/  468] time: 37.1787, train_loss: 0.14283726, train_accuracy: 0.9609, test_Accuracy: 0.9545\n",
      "Epoch: [ 0] [  411/  468] time: 37.2623, train_loss: 0.15333685, train_accuracy: 0.9453, test_Accuracy: 0.9545\n",
      "Epoch: [ 0] [  412/  468] time: 37.3471, train_loss: 0.12792507, train_accuracy: 0.9531, test_Accuracy: 0.9552\n",
      "Epoch: [ 0] [  413/  468] time: 37.4370, train_loss: 0.14517361, train_accuracy: 0.9609, test_Accuracy: 0.9569\n",
      "Epoch: [ 0] [  414/  468] time: 37.5255, train_loss: 0.20504619, train_accuracy: 0.9453, test_Accuracy: 0.9583\n",
      "Epoch: [ 0] [  415/  468] time: 37.6139, train_loss: 0.26480672, train_accuracy: 0.9297, test_Accuracy: 0.9590\n",
      "Epoch: [ 0] [  416/  468] time: 37.7010, train_loss: 0.11541034, train_accuracy: 0.9531, test_Accuracy: 0.9596\n",
      "Epoch: [ 0] [  417/  468] time: 37.7934, train_loss: 0.07290184, train_accuracy: 0.9766, test_Accuracy: 0.9592\n",
      "Epoch: [ 0] [  418/  468] time: 37.8866, train_loss: 0.15045771, train_accuracy: 0.9766, test_Accuracy: 0.9587\n",
      "Epoch: [ 0] [  419/  468] time: 37.9770, train_loss: 0.10886001, train_accuracy: 0.9531, test_Accuracy: 0.9586\n",
      "Epoch: [ 0] [  420/  468] time: 38.0687, train_loss: 0.22732958, train_accuracy: 0.9453, test_Accuracy: 0.9576\n",
      "Epoch: [ 0] [  421/  468] time: 38.1571, train_loss: 0.12405089, train_accuracy: 0.9766, test_Accuracy: 0.9569\n",
      "Epoch: [ 0] [  422/  468] time: 38.2415, train_loss: 0.10038599, train_accuracy: 0.9766, test_Accuracy: 0.9571\n",
      "Epoch: [ 0] [  423/  468] time: 38.3263, train_loss: 0.14629112, train_accuracy: 0.9688, test_Accuracy: 0.9568\n",
      "Epoch: [ 0] [  424/  468] time: 38.4109, train_loss: 0.20253986, train_accuracy: 0.9531, test_Accuracy: 0.9571\n",
      "Epoch: [ 0] [  425/  468] time: 38.4952, train_loss: 0.15520388, train_accuracy: 0.9375, test_Accuracy: 0.9573\n",
      "Epoch: [ 0] [  426/  468] time: 38.5828, train_loss: 0.08274007, train_accuracy: 0.9766, test_Accuracy: 0.9580\n",
      "Epoch: [ 0] [  427/  468] time: 38.6722, train_loss: 0.13276783, train_accuracy: 0.9453, test_Accuracy: 0.9582\n",
      "Epoch: [ 0] [  428/  468] time: 38.7663, train_loss: 0.07556379, train_accuracy: 0.9844, test_Accuracy: 0.9571\n",
      "Epoch: [ 0] [  429/  468] time: 38.8564, train_loss: 0.08397779, train_accuracy: 0.9844, test_Accuracy: 0.9572\n",
      "Epoch: [ 0] [  430/  468] time: 38.9412, train_loss: 0.17133769, train_accuracy: 0.9297, test_Accuracy: 0.9576\n",
      "Epoch: [ 0] [  431/  468] time: 39.0245, train_loss: 0.21457435, train_accuracy: 0.9531, test_Accuracy: 0.9578\n",
      "Epoch: [ 0] [  432/  468] time: 39.1068, train_loss: 0.17480621, train_accuracy: 0.9375, test_Accuracy: 0.9596\n",
      "Epoch: [ 0] [  433/  468] time: 39.1943, train_loss: 0.23006806, train_accuracy: 0.9141, test_Accuracy: 0.9600\n",
      "Epoch: [ 0] [  434/  468] time: 39.2800, train_loss: 0.10099249, train_accuracy: 0.9688, test_Accuracy: 0.9593\n",
      "Epoch: [ 0] [  435/  468] time: 39.3729, train_loss: 0.21972752, train_accuracy: 0.9297, test_Accuracy: 0.9595\n",
      "Epoch: [ 0] [  436/  468] time: 39.4657, train_loss: 0.17139095, train_accuracy: 0.9531, test_Accuracy: 0.9588\n",
      "Epoch: [ 0] [  437/  468] time: 39.5600, train_loss: 0.12648091, train_accuracy: 0.9531, test_Accuracy: 0.9574\n",
      "Epoch: [ 0] [  438/  468] time: 39.6482, train_loss: 0.17021981, train_accuracy: 0.9375, test_Accuracy: 0.9569\n",
      "Epoch: [ 0] [  439/  468] time: 39.7354, train_loss: 0.09998958, train_accuracy: 0.9609, test_Accuracy: 0.9587\n",
      "Epoch: [ 0] [  440/  468] time: 39.8199, train_loss: 0.10502908, train_accuracy: 0.9609, test_Accuracy: 0.9595\n",
      "Epoch: [ 0] [  441/  468] time: 39.9017, train_loss: 0.09824544, train_accuracy: 0.9766, test_Accuracy: 0.9592\n",
      "Epoch: [ 0] [  442/  468] time: 39.9875, train_loss: 0.06050880, train_accuracy: 0.9844, test_Accuracy: 0.9599\n",
      "Epoch: [ 0] [  443/  468] time: 40.0797, train_loss: 0.10491392, train_accuracy: 0.9766, test_Accuracy: 0.9606\n",
      "Epoch: [ 0] [  444/  468] time: 40.1732, train_loss: 0.09266661, train_accuracy: 0.9688, test_Accuracy: 0.9601\n",
      "Epoch: [ 0] [  445/  468] time: 40.2647, train_loss: 0.18366835, train_accuracy: 0.9219, test_Accuracy: 0.9609\n",
      "Epoch: [ 0] [  446/  468] time: 40.3491, train_loss: 0.20791358, train_accuracy: 0.9375, test_Accuracy: 0.9607\n",
      "Epoch: [ 0] [  447/  468] time: 40.4344, train_loss: 0.07773390, train_accuracy: 0.9766, test_Accuracy: 0.9597\n",
      "Epoch: [ 0] [  448/  468] time: 40.5185, train_loss: 0.09881496, train_accuracy: 0.9688, test_Accuracy: 0.9592\n",
      "Epoch: [ 0] [  449/  468] time: 40.6028, train_loss: 0.10112144, train_accuracy: 0.9531, test_Accuracy: 0.9592\n",
      "Epoch: [ 0] [  450/  468] time: 40.6868, train_loss: 0.11310300, train_accuracy: 0.9688, test_Accuracy: 0.9605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [  451/  468] time: 40.7736, train_loss: 0.08190832, train_accuracy: 0.9844, test_Accuracy: 0.9615\n",
      "Epoch: [ 0] [  452/  468] time: 40.8602, train_loss: 0.07666154, train_accuracy: 0.9688, test_Accuracy: 0.9621\n",
      "Epoch: [ 0] [  453/  468] time: 40.9497, train_loss: 0.05275073, train_accuracy: 0.9844, test_Accuracy: 0.9622\n",
      "Epoch: [ 0] [  454/  468] time: 41.0362, train_loss: 0.15831397, train_accuracy: 0.9766, test_Accuracy: 0.9626\n",
      "Epoch: [ 0] [  455/  468] time: 41.1188, train_loss: 0.15586478, train_accuracy: 0.9531, test_Accuracy: 0.9617\n",
      "Epoch: [ 0] [  456/  468] time: 41.2008, train_loss: 0.06750786, train_accuracy: 0.9922, test_Accuracy: 0.9613\n",
      "Epoch: [ 0] [  457/  468] time: 41.2892, train_loss: 0.10472396, train_accuracy: 0.9844, test_Accuracy: 0.9608\n",
      "Epoch: [ 0] [  458/  468] time: 41.3859, train_loss: 0.14222562, train_accuracy: 0.9531, test_Accuracy: 0.9598\n",
      "Epoch: [ 0] [  459/  468] time: 41.4767, train_loss: 0.16641076, train_accuracy: 0.9375, test_Accuracy: 0.9592\n",
      "Epoch: [ 0] [  460/  468] time: 41.5605, train_loss: 0.08998650, train_accuracy: 0.9609, test_Accuracy: 0.9588\n",
      "Epoch: [ 0] [  461/  468] time: 41.6434, train_loss: 0.08836123, train_accuracy: 0.9766, test_Accuracy: 0.9578\n",
      "Epoch: [ 0] [  462/  468] time: 41.7353, train_loss: 0.10158753, train_accuracy: 0.9688, test_Accuracy: 0.9582\n",
      "Epoch: [ 0] [  463/  468] time: 41.8448, train_loss: 0.12403195, train_accuracy: 0.9531, test_Accuracy: 0.9583\n",
      "Epoch: [ 0] [  464/  468] time: 41.9503, train_loss: 0.23943827, train_accuracy: 0.9375, test_Accuracy: 0.9604\n",
      "Epoch: [ 0] [  465/  468] time: 42.0605, train_loss: 0.13878170, train_accuracy: 0.9609, test_Accuracy: 0.9619\n",
      "Epoch: [ 0] [  466/  468] time: 42.1755, train_loss: 0.12822361, train_accuracy: 0.9609, test_Accuracy: 0.9626\n",
      "Epoch: [ 0] [  467/  468] time: 42.2876, train_loss: 0.10396451, train_accuracy: 0.9688, test_Accuracy: 0.9620\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if train_flag :\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(dnn=network)\n",
    "\n",
    "    # create writer for tensorboard\n",
    "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
    "    start_time = time()\n",
    "\n",
    "    # restore check-point if it exits\n",
    "    could_load, checkpoint_counter = load(network, checkpoint_dir)    \n",
    "\n",
    "    if could_load:\n",
    "        start_epoch = (int)(checkpoint_counter / training_iterations)        \n",
    "        counter = checkpoint_counter        \n",
    "        print(\" [*] Load SUCCESS\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        start_iteration = 0\n",
    "        counter = 0\n",
    "        print(\" [!] Load failed...\")\n",
    "    \n",
    "    # train phase\n",
    "    with summary_writer.as_default():  # for tensorboard\n",
    "        for epoch in range(start_epoch, training_epochs):\n",
    "            for idx, (train_input, train_label) in enumerate(train_dataset):                \n",
    "                grads = grad(network, train_input, train_label)\n",
    "                optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
    "\n",
    "                train_loss = loss_fn(network, train_input, train_label)\n",
    "                train_accuracy = accuracy_fn(network, train_input, train_label)\n",
    "\n",
    "                for test_input, test_label in test_dataset:                \n",
    "                    test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "\n",
    "                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n",
    "                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n",
    "                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n",
    "\n",
    "                print(\n",
    "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
    "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
    "                       test_accuracy))\n",
    "                counter += 1\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
    "        \n",
    "# test phase      \n",
    "else :\n",
    "    _, _ = load(network, checkpoint_dir)\n",
    "    for test_input, test_label in test_dataset:    \n",
    "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "\n",
    "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64fcaf",
   "metadata": {},
   "source": [
    "###weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6fae079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from time import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "372909ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(model, checkpoint_dir):\n",
    "    print(\" [*] Reading checkpoints...\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt :\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        checkpoint = tf.train.Checkpoint(dnn=model)\n",
    "        checkpoint.restore(save_path=os.path.join(checkpoint_dir, ckpt_name))\n",
    "        counter = int(ckpt_name.split('-')[1])\n",
    "        print(\" [*] Success to read {}\".format(ckpt_name))\n",
    "        return True, counter\n",
    "    else:\n",
    "        print(\" [*] Failed to find a checkpoint\")\n",
    "        return False, 0\n",
    "\n",
    "def check_folder(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    return dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dbdf915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist() :\n",
    "    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "    train_data = np.expand_dims(train_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n",
    "    test_data = np.expand_dims(test_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n",
    "\n",
    "    train_data, test_data = normalize(train_data, test_data)\n",
    "\n",
    "    train_labels = to_categorical(train_labels, 10) # [N,] -> [N, 10]\n",
    "    test_labels = to_categorical(test_labels, 10) # [N,] -> [N, 10]\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "def normalize(train_data, test_data):\n",
    "    train_data = train_data.astype(np.float32) / 255.0\n",
    "    test_data = test_data.astype(np.float32) / 255.0\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b979322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True)\n",
    "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, \n",
    "                                                                   from_logits=True))\n",
    "    return loss\n",
    "\n",
    "def accuracy_fn(model, images, labels):\n",
    "    logits = model(images, training=False)\n",
    "    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c6588",
   "metadata": {},
   "source": [
    "### 모델 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494bdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten() :\n",
    "    return tf.keras.layers.Flatten()\n",
    "\n",
    "def dense(label_dim, weight_init) :\n",
    "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
    "\n",
    "def relu() :\n",
    "    return tf.keras.layers.Activation(tf.keras.activations.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57cf26",
   "metadata": {},
   "source": [
    "### class.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b76cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model_class(tf.keras.Model):\n",
    "    def __init__(self, label_dim):\n",
    "        super(create_model_class, self).__init__()\n",
    "        weight_init = tf.keras.initializers.glorot_uniform() #he_uniform\n",
    "\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(flatten())\n",
    "\n",
    "        for i in range(2):\n",
    "            self.model.add(dense(256, weight_init))\n",
    "            self.model.add(relu())\n",
    "\n",
    "        self.model.add(dense(label_dim, weight_init))\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78765adc",
   "metadata": {},
   "source": [
    "### func.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7674946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_function(label_dim) :\n",
    "    weight_init = tf.keras.initializers.RandomNormal()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(flatten())\n",
    "\n",
    "    for i in range(2) :\n",
    "        model.add(dense(256, weight_init))\n",
    "        model.add(relu())\n",
    "\n",
    "    model.add(dense(label_dim, weight_init))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d42277be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" dataset \"\"\"\n",
    "train_x, train_y, test_x, test_y = load_mnist()\n",
    "\n",
    "\"\"\" parameters \"\"\"\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "training_epochs = 1\n",
    "training_iterations = len(train_x) // batch_size\n",
    "\n",
    "label_dim = 10\n",
    "\n",
    "train_flag = True\n",
    "\n",
    "\"\"\" Graph Input using Dataset API \"\"\"\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=batch_size).\\\n",
    "    batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=len(test_x)).\\\n",
    "    batch(len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ddddb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model \"\"\"\n",
    "network = create_model_function(label_dim)\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "\"\"\" Writer \"\"\"\n",
    "checkpoint_dir = 'checkpoints'\n",
    "logs_dir = 'logs'\n",
    "\n",
    "model_dir = 'nn_xavier'\n",
    "\n",
    "checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "check_folder(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n",
    "logs_dir = os.path.join(logs_dir, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f57d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      " [*] Success to read nn_xavier-468-1\n",
      " [*] Load SUCCESS\n"
     ]
    }
   ],
   "source": [
    "if train_flag :\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(dnn=network)\n",
    "\n",
    "    # create writer for tensorboard\n",
    "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
    "    start_time = time()\n",
    "\n",
    "    # restore check-point if it exits\n",
    "    could_load, checkpoint_counter = load(network, checkpoint_dir)    \n",
    "\n",
    "    if could_load:\n",
    "        start_epoch = (int)(checkpoint_counter / training_iterations)        \n",
    "        counter = checkpoint_counter        \n",
    "        print(\" [*] Load SUCCESS\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        start_iteration = 0\n",
    "        counter = 0\n",
    "        print(\" [!] Load failed...\")\n",
    "    \n",
    "    # train phase\n",
    "    with summary_writer.as_default():  # for tensorboard\n",
    "        for epoch in range(start_epoch, training_epochs):\n",
    "            for idx, (train_input, train_label) in enumerate(train_dataset):                \n",
    "                grads = grad(network, train_input, train_label)\n",
    "                optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
    "\n",
    "                train_loss = loss_fn(network, train_input, train_label)\n",
    "                train_accuracy = accuracy_fn(network, train_input, train_label)\n",
    "\n",
    "                for test_input, test_label in test_dataset:                \n",
    "                    test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "\n",
    "                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n",
    "                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n",
    "                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n",
    "\n",
    "                print(\n",
    "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
    "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
    "                       test_accuracy))\n",
    "                counter += 1\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
    "        \n",
    "# test phase      \n",
    "else :\n",
    "    _, _ = load(network, checkpoint_dir)\n",
    "    for test_input, test_label in test_dataset:    \n",
    "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "\n",
    "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f69d6",
   "metadata": {},
   "source": [
    "###Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3ef6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True) #true : dropout 사용하겟다는뜻\n",
    "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, \n",
    "                                                                   from_logits=True))\n",
    "    return loss\n",
    "\n",
    "def accuracy_fn(model, images, labels):\n",
    "    logits = model(images, training=False)\n",
    "    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "334a9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten() :\n",
    "    return tf.keras.layers.Flatten()\n",
    "\n",
    "def dense(label_dim, weight_init) :\n",
    "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
    "\n",
    "def relu() :\n",
    "    return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
    "\n",
    "def dropout(rate) :\n",
    "    return tf.keras.layers.Dropout(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac31ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model_class(tf.keras.Model):\n",
    "    def __init__(self, label_dim):\n",
    "        super(create_model_class, self).__init__()\n",
    "        weight_init = tf.keras.initializers.glorot_uniform()\n",
    "\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(flatten())\n",
    "\n",
    "        for i in range(4):\n",
    "            self.model.add(dense(512, weight_init))\n",
    "            self.model.add(relu())\n",
    "            self.model.add(dropout(rate=0.5))\n",
    "\n",
    "        self.model.add(dense(label_dim, weight_init))\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0e075b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      " [*] Success to read nn_xavier-468-1\n",
      " [*] Load SUCCESS\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorboard.summary._tf.summary' has no attribute 'always_record_summaries'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [!] Load failed...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# train phase\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m summary_writer\u001b[38;5;241m.\u001b[39mas_default(), \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malways_record_summaries\u001b[49m():  \u001b[38;5;66;03m# for tensorboard\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, training_epochs):\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iteration, training_iterations):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorboard.summary._tf.summary' has no attribute 'always_record_summaries'"
     ]
    }
   ],
   "source": [
    "if train_flag :\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(dnn=network)\n",
    "\n",
    "    # create writer for tensorboard\n",
    "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
    "    start_time = time()\n",
    "\n",
    "    # restore check-point if it exits\n",
    "    could_load, checkpoint_counter = load(network, checkpoint_dir)\n",
    "    #global_step = tf.compat.v1.train.create_global_step()\n",
    "\n",
    "    if could_load:\n",
    "        start_epoch = (int)(checkpoint_counter / training_iterations)\n",
    "        start_iteration = checkpoint_counter - start_epoch * training_iterations\n",
    "        counter = checkpoint_counter\n",
    "        global_step.assign(checkpoint_counter)\n",
    "        print(\" [*] Load SUCCESS\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        start_iteration = 0\n",
    "        counter = 0\n",
    "        print(\" [!] Load failed...\")\n",
    "    \n",
    "    # train phase\n",
    "    with summary_writer.as_default(), tf.summary.always_record_summaries():  # for tensorboard\n",
    "        for epoch in range(start_epoch, training_epochs):\n",
    "            for idx in range(start_iteration, training_iterations):\n",
    "                train_input, train_label = train_iterator.get_next()\n",
    "                grads = grad(network, train_input, train_label)\n",
    "                optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables), global_step=global_step)\n",
    "\n",
    "                train_loss = loss_fn(network, train_input, train_label)\n",
    "                train_accuracy = accuracy_fn(network, train_input, train_label)\n",
    "\n",
    "                test_input, test_label = test_iterator.get_next()\n",
    "                test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "\n",
    "                tf.contrib.summary.scalar(name='train_loss', tensor=train_loss)\n",
    "                tf.contrib.summary.scalar(name='train_accuracy', tensor=train_accuracy)\n",
    "                tf.contrib.summary.scalar(name='test_accuracy', tensor=test_accuracy)\n",
    "\n",
    "                print(\n",
    "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
    "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
    "                       test_accuracy))\n",
    "                counter += 1\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
    "        \n",
    "# test phase      \n",
    "else :\n",
    "    _, _ = load(network, checkpoint_dir)\n",
    "    test_input, test_label = test_iterator.get_next()\n",
    "    test_accuracy = accuracy_fn(network, test_input, test_label)\n",
    "\n",
    "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab78f1",
   "metadata": {},
   "source": [
    "###Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3462ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten() :\n",
    "    return tf.keras.layers.Flatten()\n",
    "\n",
    "def dense(label_dim, weight_init) :\n",
    "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
    "\n",
    "def relu() :\n",
    "    return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
    "\n",
    "def batch_norm() :\n",
    "    return tf.keras.layers.BatchNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d47a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_model_class(tf.keras.Model):\n",
    "    def __init__(self, label_dim):\n",
    "        super(create_model_class, self).__init__()\n",
    "        weight_init = tf.keras.initializers.glorot_uniform()\n",
    "\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(flatten())\n",
    "\n",
    "        for i in range(4):\n",
    "            self.model.add(dense(512, weight_init))\n",
    "            self.model.add(batch_norm())\n",
    "            self.model.add(relu())\n",
    "\n",
    "        self.model.add(dense(label_dim, weight_init))\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TF_study] *",
   "language": "python",
   "name": "conda-env-TF_study-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
