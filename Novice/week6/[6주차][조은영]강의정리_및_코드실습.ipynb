{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Relu\n",
        "## Problem of Sigmoid\n",
        "- 뉴럴 네트워크는 input을 받고 output을 출력\n",
        "- loss: output과 실제 정답 데이터와 얼마나 차이가 나는지 \n",
        "- loss를 미분한 것을 backpropagation하면서 네트워크를 학습\n",
        "- gradient: 전달되는 loss를 미분한 것, 그래프의 기울기\n",
        "- sigmoid에서 가운데 쪽은 기울기 값이 0보다 크고, 극단 좌표계에서는 0에 매우 가까운, 작은 값을 가진다.\n",
        "- deep한 학습에서 gradient값이 매우 작으면 안됨\n",
        "- Vanishing Gradient: gradient가 매우 작아 학습시 사라지는 것\n",
        "\n",
        "## Relu\n",
        "$$ f(x) = max(0,x) $$\n",
        "\n",
        "![SmartSelectImage_2022-11-13-14-00-38.png](data:image/png;base64,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)\n",
        "- 어떠한 x를 받았을 때 x가 0보다 큰 양수의 값을 가진다면 x를 output으로 추출하고 0보다 작은 음수의 값을 갖는다면 0으로 바꿔서 추출하는 것\n",
        "- Relu 함수의 gradient 값은 0보다 큰 값에서 1, 아무리 network가 deep 하더라도 값이 전달됨\n",
        "- 0보다 작은 값에서 gradient는 0\n",
        "- tanh, elu, selu 등이 있음 (tf.keras.activations)\n",
        "- leaky relu: Relo에서 0보다 작을 때의 문제점을 해결한 것 (tf.keras.layers), 어떤 a에 x를 곱한 것을 추출 (a는 매우 작음)"
      ],
      "metadata": {
        "id": "npEcFPuDVsNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "vKD7SzSnYVO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwXqOnlTViBs",
        "outputId": "e40d08e1-0ad9-4873-f722-7ac3fa462821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from time import time\n",
        "import os\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint function\n",
        "\n"
      ],
      "metadata": {
        "id": "SFJBloByNy2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(model, checkpoint_dir):\n",
        "    print(\" [*] Reading checkpoints...\")\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "    if ckpt :\n",
        "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "        checkpoint = tf.train.Checkpoint(dnn=model)\n",
        "        checkpoint.restore(save_path=os.path.join(checkpoint_dir, ckpt_name))\n",
        "        counter = int(ckpt_name.split('-')[1])\n",
        "        print(\" [*] Success to read {}\".format(ckpt_name))\n",
        "        return True, counter\n",
        "    else:\n",
        "        print(\" [*] Failed to find a checkpoint\")\n",
        "        return False, 0\n",
        "\n",
        "def check_folder(dir):\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "    return dir"
      ],
      "metadata": {
        "id": "1ylzvSYwN2Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load mnist&pre-processing\n"
      ],
      "metadata": {
        "id": "IrnR0C0RYmKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist():\n",
        "  (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "\n",
        "  # tensorflow가 input으로 받는 요소에는 [batch_size, height, width, channel]이 포함되어야 함\n",
        "  # 채널을 하나 만들어주는 역할\n",
        "  # 축 -1은 끝을 의미\n",
        "  train_data = np.expand_dims(train_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n",
        "  test_data = np.expand_dims(test_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n",
        "\n",
        "  # 이미지 숫자값의 범위를 [0~1]로 바꿔줌\n",
        "  train_data, test_data = normalize(train_data, test_data)\n",
        "\n",
        "  # one hot incoding\n",
        "  train_labels = to_categorical(train_labels, 10) # [N,] -> [N, 10]\n",
        "  test_labels = to_categorical(test_labels, 10) # [N,] -> [N, 10]\n",
        "\n",
        "  return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "def normalize(train_data, test_data):\n",
        "    train_data = train_data.astype(np.float32) / 255.0\n",
        "    test_data = test_data.astype(np.float32) / 255.0\n",
        "\n",
        "    return train_data, test_data"
      ],
      "metadata": {
        "id": "BgKmWywkYp_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create network"
      ],
      "metadata": {
        "id": "Ewp2UFidJc25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten() :\n",
        "    return tf.keras.layers.Flatten()\n",
        "\n",
        "# unit = output으로 나가는 채널 개수\n",
        "def dense(label_dim, weight_init) :\n",
        "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
        "\n",
        "def relu() :\n",
        "    return tf.keras.layers.Activation(tf.keras.activations.relu)"
      ],
      "metadata": {
        "id": "aRyvxLWlJfBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model - class"
      ],
      "metadata": {
        "id": "1VIyhyLfKrwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.Model을 상속해야 함\n",
        "class create_model_class(tf.keras.Model):\n",
        "    # label_dim: network의 로직을 구할 때 몇개의 아웃풋을 내야하는지\n",
        "    def __init__(self, label_dim):\n",
        "        super(create_model_class, self).__init__()\n",
        "\n",
        "        # 가우시안 분포\n",
        "        weight_init = tf.keras.initializers.RandomNormal()\n",
        "\n",
        "        # Sequential = 리스트 자료구조 타입\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(flatten()) # [N, 28, 28, 1] -> [N, 784]\n",
        "\n",
        "        for i in range(2):\n",
        "            # [N, 784] -> [N, 256] -> [N,256]\n",
        "            self.model.add(dense(256, weight_init))\n",
        "            self.model.add(relu())\n",
        "\n",
        "        self.model.add(dense(label_dim, weight_init)) # [N, 256] -> [N, 10]\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "taqPTwGTJ6KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model - function"
      ],
      "metadata": {
        "id": "3DRYi2PVKy-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_function(label_dim) :\n",
        "    weight_init = tf.keras.initializers.RandomNormal()\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(flatten())\n",
        "\n",
        "    for i in range(2) :\n",
        "        model.add(dense(256, weight_init))\n",
        "        model.add(relu())\n",
        "\n",
        "    model.add(dense(label_dim, weight_init))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "90J9uLbwK3p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define loss"
      ],
      "metadata": {
        "id": "gS4GUsSgLWeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(model, images, labels):\n",
        "    # model에 image를 넣어서 output 추출\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, \n",
        "                                                                   from_logits=True))\n",
        "    return loss\n",
        "\n",
        "# 정확도\n",
        "def accuracy_fn(model, images, labels):\n",
        "    # model에 images를 넣어서 logit이 뭔지 알아냄\n",
        "    logits = model(images, training=False)\n",
        "    # tf.argmax[batch size, label_dim]: 10개의 값들 중에서 가장 큰 값을 가지고 있는 것을 구함\n",
        "    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
        "    # 숫자값으로 바꿔줌\n",
        "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
        "    return accuracy\n",
        "\n",
        "# loss를 구했을 때 model weight의 gradient retrurn\n",
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ],
      "metadata": {
        "id": "1fKGKLfuLYDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define data & hyper-parameter"
      ],
      "metadata": {
        "id": "Xsx9dd0dK1bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" dataset \"\"\"\n",
        "train_x, train_y, test_x, test_y = load_mnist()\n",
        "\n",
        "\"\"\" parameters \"\"\"\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "\n",
        "training_epochs = 1\n",
        "training_iterations = len(train_x) // batch_size\n",
        "\n",
        "label_dim = 10\n",
        "\n",
        "train_flag = True\n",
        "\n",
        "\"\"\" Graph Input using Dataset API \"\"\"\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
        "    shuffle(buffer_size=100000).\\\n",
        "    prefetch(buffer_size=batch_size).\\\n",
        "    batch(batch_size, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
        "    shuffle(buffer_size=100000).\\\n",
        "    prefetch(buffer_size=len(test_x)).\\\n",
        "    batch(len(test_x))"
      ],
      "metadata": {
        "id": "LYwC1V-LK7de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model & optimizer & writer"
      ],
      "metadata": {
        "id": "RR0dg0MKK_l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Model \"\"\"\n",
        "network = create_model_function(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "\"\"\" Writer \"\"\"\n",
        "checkpoint_dir = 'checkpoints'\n",
        "logs_dir = 'logs'\n",
        "\n",
        "model_dir = 'nn_relu'\n",
        "\n",
        "checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "check_folder(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n",
        "logs_dir = os.path.join(logs_dir, model_dir)"
      ],
      "metadata": {
        "id": "p1UItvvAK_Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restore checkpoint & start train or test phase"
      ],
      "metadata": {
        "id": "NXKPwJlaLEe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if train_flag :\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(dnn=network)\n",
        "\n",
        "    # create writer for tensorboard\n",
        "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
        "    start_time = time()\n",
        "\n",
        "    # restore check-point if it exits\n",
        "    could_load, checkpoint_counter = load(network, checkpoint_dir)    \n",
        "\n",
        "    if could_load:\n",
        "        start_epoch = (int)(checkpoint_counter / training_iterations)        \n",
        "        counter = checkpoint_counter        \n",
        "        print(\" [*] Load SUCCESS\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        start_iteration = 0\n",
        "        counter = 0\n",
        "        print(\" [!] Load failed...\")\n",
        "    \n",
        "    # train phase\n",
        "    with summary_writer.as_default():  # for tensorboard\n",
        "        for epoch in range(start_epoch, training_epochs):\n",
        "            for idx, (train_input, train_label) in enumerate(train_dataset):                \n",
        "                grads = grad(network, train_input, train_label)\n",
        "                optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
        "\n",
        "                train_loss = loss_fn(network, train_input, train_label)\n",
        "                train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "\n",
        "                for test_input, test_label in test_dataset:                \n",
        "                    test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n",
        "                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n",
        "                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n",
        "\n",
        "                print(\n",
        "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
        "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
        "                       test_accuracy))\n",
        "                counter += 1\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
        "        \n",
        "# test phase      \n",
        "else :\n",
        "    _, _ = load(network, checkpoint_dir)\n",
        "    for test_input, test_label in test_dataset:    \n",
        "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddOcMTKrLI0f",
        "outputId": "9cad65f9-1ce4-4879-c3cc-0f84dea0003f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Reading checkpoints...\n",
            " [*] Failed to find a checkpoint\n",
            " [!] Load failed...\n",
            "Epoch: [ 0] [    0/  468] time: 1.1970, train_loss: 2.18015814, train_accuracy: 0.3594, test_Accuracy: 0.2053\n",
            "Epoch: [ 0] [    1/  468] time: 1.4015, train_loss: 2.13980103, train_accuracy: 0.4922, test_Accuracy: 0.4097\n",
            "Epoch: [ 0] [    2/  468] time: 1.5871, train_loss: 2.06436300, train_accuracy: 0.4375, test_Accuracy: 0.4842\n",
            "Epoch: [ 0] [    3/  468] time: 1.7775, train_loss: 2.00024700, train_accuracy: 0.5859, test_Accuracy: 0.5827\n",
            "Epoch: [ 0] [    4/  468] time: 1.9784, train_loss: 1.92871141, train_accuracy: 0.6641, test_Accuracy: 0.6325\n",
            "Epoch: [ 0] [    5/  468] time: 2.1926, train_loss: 1.84263396, train_accuracy: 0.6406, test_Accuracy: 0.6593\n",
            "Epoch: [ 0] [    6/  468] time: 2.3935, train_loss: 1.71736670, train_accuracy: 0.7656, test_Accuracy: 0.6719\n",
            "Epoch: [ 0] [    7/  468] time: 2.5944, train_loss: 1.63354254, train_accuracy: 0.7188, test_Accuracy: 0.6782\n",
            "Epoch: [ 0] [    8/  468] time: 2.9290, train_loss: 1.58459628, train_accuracy: 0.6562, test_Accuracy: 0.7006\n",
            "Epoch: [ 0] [    9/  468] time: 3.1220, train_loss: 1.41854596, train_accuracy: 0.7266, test_Accuracy: 0.7284\n",
            "Epoch: [ 0] [   10/  468] time: 3.4584, train_loss: 1.26870489, train_accuracy: 0.7812, test_Accuracy: 0.7549\n",
            "Epoch: [ 0] [   11/  468] time: 3.7916, train_loss: 1.27083349, train_accuracy: 0.7656, test_Accuracy: 0.7792\n",
            "Epoch: [ 0] [   12/  468] time: 3.9885, train_loss: 1.14146399, train_accuracy: 0.7656, test_Accuracy: 0.7989\n",
            "Epoch: [ 0] [   13/  468] time: 4.2043, train_loss: 1.00142550, train_accuracy: 0.8047, test_Accuracy: 0.7938\n",
            "Epoch: [ 0] [   14/  468] time: 4.3983, train_loss: 0.89402270, train_accuracy: 0.8203, test_Accuracy: 0.7815\n",
            "Epoch: [ 0] [   15/  468] time: 4.5956, train_loss: 0.98768735, train_accuracy: 0.7812, test_Accuracy: 0.7791\n",
            "Epoch: [ 0] [   16/  468] time: 4.9285, train_loss: 0.85680449, train_accuracy: 0.7969, test_Accuracy: 0.7924\n",
            "Epoch: [ 0] [   17/  468] time: 5.1262, train_loss: 0.82758522, train_accuracy: 0.7812, test_Accuracy: 0.8248\n",
            "Epoch: [ 0] [   18/  468] time: 5.3280, train_loss: 0.72942185, train_accuracy: 0.8203, test_Accuracy: 0.8320\n",
            "Epoch: [ 0] [   19/  468] time: 5.5336, train_loss: 0.59758204, train_accuracy: 0.8906, test_Accuracy: 0.8162\n",
            "Epoch: [ 0] [   20/  468] time: 5.7245, train_loss: 0.71881211, train_accuracy: 0.7891, test_Accuracy: 0.8109\n",
            "Epoch: [ 0] [   21/  468] time: 5.9233, train_loss: 0.62662387, train_accuracy: 0.8281, test_Accuracy: 0.8207\n",
            "Epoch: [ 0] [   22/  468] time: 6.2573, train_loss: 0.59594750, train_accuracy: 0.8516, test_Accuracy: 0.8326\n",
            "Epoch: [ 0] [   23/  468] time: 6.5887, train_loss: 0.51613021, train_accuracy: 0.9062, test_Accuracy: 0.8401\n",
            "Epoch: [ 0] [   24/  468] time: 6.7854, train_loss: 0.55773610, train_accuracy: 0.8281, test_Accuracy: 0.8513\n",
            "Epoch: [ 0] [   25/  468] time: 7.1194, train_loss: 0.45412388, train_accuracy: 0.8906, test_Accuracy: 0.8551\n",
            "Epoch: [ 0] [   26/  468] time: 7.3364, train_loss: 0.48056149, train_accuracy: 0.9141, test_Accuracy: 0.8524\n",
            "Epoch: [ 0] [   27/  468] time: 7.5360, train_loss: 0.53247046, train_accuracy: 0.8359, test_Accuracy: 0.8505\n",
            "Epoch: [ 0] [   28/  468] time: 7.7406, train_loss: 0.49663991, train_accuracy: 0.8359, test_Accuracy: 0.8509\n",
            "Epoch: [ 0] [   29/  468] time: 7.9368, train_loss: 0.53088522, train_accuracy: 0.8594, test_Accuracy: 0.8403\n",
            "Epoch: [ 0] [   30/  468] time: 8.2726, train_loss: 0.61688018, train_accuracy: 0.7812, test_Accuracy: 0.8351\n",
            "Epoch: [ 0] [   31/  468] time: 8.4873, train_loss: 0.55452067, train_accuracy: 0.8516, test_Accuracy: 0.8469\n",
            "Epoch: [ 0] [   32/  468] time: 8.8212, train_loss: 0.44549909, train_accuracy: 0.8594, test_Accuracy: 0.8649\n",
            "Epoch: [ 0] [   33/  468] time: 9.0318, train_loss: 0.42921668, train_accuracy: 0.8516, test_Accuracy: 0.8723\n",
            "Epoch: [ 0] [   34/  468] time: 9.2443, train_loss: 0.45762637, train_accuracy: 0.8750, test_Accuracy: 0.8665\n",
            "Epoch: [ 0] [   35/  468] time: 9.4672, train_loss: 0.58509886, train_accuracy: 0.8750, test_Accuracy: 0.8604\n",
            "Epoch: [ 0] [   36/  468] time: 9.8008, train_loss: 0.37013608, train_accuracy: 0.8750, test_Accuracy: 0.8608\n",
            "Epoch: [ 0] [   37/  468] time: 10.1319, train_loss: 0.48614752, train_accuracy: 0.8516, test_Accuracy: 0.8697\n",
            "Epoch: [ 0] [   38/  468] time: 10.3437, train_loss: 0.29252246, train_accuracy: 0.9062, test_Accuracy: 0.8769\n",
            "Epoch: [ 0] [   39/  468] time: 10.5366, train_loss: 0.40844914, train_accuracy: 0.9219, test_Accuracy: 0.8801\n",
            "Epoch: [ 0] [   40/  468] time: 10.7388, train_loss: 0.42306608, train_accuracy: 0.8828, test_Accuracy: 0.8765\n",
            "Epoch: [ 0] [   41/  468] time: 10.9341, train_loss: 0.35673738, train_accuracy: 0.9297, test_Accuracy: 0.8725\n",
            "Epoch: [ 0] [   42/  468] time: 11.2685, train_loss: 0.36851460, train_accuracy: 0.8828, test_Accuracy: 0.8715\n",
            "Epoch: [ 0] [   43/  468] time: 11.4823, train_loss: 0.45050314, train_accuracy: 0.8359, test_Accuracy: 0.8769\n",
            "Epoch: [ 0] [   44/  468] time: 11.8148, train_loss: 0.43048382, train_accuracy: 0.8281, test_Accuracy: 0.8866\n",
            "Epoch: [ 0] [   45/  468] time: 12.1472, train_loss: 0.27485073, train_accuracy: 0.9375, test_Accuracy: 0.8920\n",
            "Epoch: [ 0] [   46/  468] time: 12.4794, train_loss: 0.42562431, train_accuracy: 0.8594, test_Accuracy: 0.8939\n",
            "Epoch: [ 0] [   47/  468] time: 12.6730, train_loss: 0.29483485, train_accuracy: 0.8906, test_Accuracy: 0.8957\n",
            "Epoch: [ 0] [   48/  468] time: 12.8620, train_loss: 0.51529509, train_accuracy: 0.8438, test_Accuracy: 0.8944\n",
            "Epoch: [ 0] [   49/  468] time: 13.1932, train_loss: 0.31069583, train_accuracy: 0.9141, test_Accuracy: 0.8916\n",
            "Epoch: [ 0] [   50/  468] time: 13.5252, train_loss: 0.35883522, train_accuracy: 0.8906, test_Accuracy: 0.8928\n",
            "Epoch: [ 0] [   51/  468] time: 13.7469, train_loss: 0.37284026, train_accuracy: 0.9219, test_Accuracy: 0.8902\n",
            "Epoch: [ 0] [   52/  468] time: 14.0786, train_loss: 0.35754770, train_accuracy: 0.8906, test_Accuracy: 0.8876\n",
            "Epoch: [ 0] [   53/  468] time: 14.4143, train_loss: 0.49576071, train_accuracy: 0.8516, test_Accuracy: 0.8880\n",
            "Epoch: [ 0] [   54/  468] time: 14.6222, train_loss: 0.45028815, train_accuracy: 0.8438, test_Accuracy: 0.8909\n",
            "Epoch: [ 0] [   55/  468] time: 14.8101, train_loss: 0.26064932, train_accuracy: 0.8984, test_Accuracy: 0.8884\n",
            "Epoch: [ 0] [   56/  468] time: 15.1433, train_loss: 0.32768571, train_accuracy: 0.9141, test_Accuracy: 0.8873\n",
            "Epoch: [ 0] [   57/  468] time: 15.4747, train_loss: 0.36199918, train_accuracy: 0.8594, test_Accuracy: 0.8895\n",
            "Epoch: [ 0] [   58/  468] time: 15.8084, train_loss: 0.32119510, train_accuracy: 0.8984, test_Accuracy: 0.8907\n",
            "Epoch: [ 0] [   59/  468] time: 16.1406, train_loss: 0.34500295, train_accuracy: 0.8906, test_Accuracy: 0.8944\n",
            "Epoch: [ 0] [   60/  468] time: 16.4737, train_loss: 0.26771545, train_accuracy: 0.9375, test_Accuracy: 0.8945\n",
            "Epoch: [ 0] [   61/  468] time: 16.6980, train_loss: 0.42335334, train_accuracy: 0.8984, test_Accuracy: 0.8941\n",
            "Epoch: [ 0] [   62/  468] time: 16.9078, train_loss: 0.47280639, train_accuracy: 0.8438, test_Accuracy: 0.8982\n",
            "Epoch: [ 0] [   63/  468] time: 17.2471, train_loss: 0.33650291, train_accuracy: 0.8906, test_Accuracy: 0.8949\n",
            "Epoch: [ 0] [   64/  468] time: 17.4471, train_loss: 0.35587347, train_accuracy: 0.8828, test_Accuracy: 0.8934\n",
            "Epoch: [ 0] [   65/  468] time: 17.7956, train_loss: 0.41827047, train_accuracy: 0.8672, test_Accuracy: 0.8926\n",
            "Epoch: [ 0] [   66/  468] time: 17.9942, train_loss: 0.42023522, train_accuracy: 0.8594, test_Accuracy: 0.9003\n",
            "Epoch: [ 0] [   67/  468] time: 18.3288, train_loss: 0.24134603, train_accuracy: 0.9375, test_Accuracy: 0.9044\n",
            "Epoch: [ 0] [   68/  468] time: 18.5546, train_loss: 0.23384878, train_accuracy: 0.9297, test_Accuracy: 0.9076\n",
            "Epoch: [ 0] [   69/  468] time: 18.7524, train_loss: 0.41291034, train_accuracy: 0.8984, test_Accuracy: 0.9042\n",
            "Epoch: [ 0] [   70/  468] time: 18.9517, train_loss: 0.33361951, train_accuracy: 0.8906, test_Accuracy: 0.9024\n",
            "Epoch: [ 0] [   71/  468] time: 19.1496, train_loss: 0.42098704, train_accuracy: 0.9062, test_Accuracy: 0.9031\n",
            "Epoch: [ 0] [   72/  468] time: 19.3569, train_loss: 0.39383602, train_accuracy: 0.8906, test_Accuracy: 0.9029\n",
            "Epoch: [ 0] [   73/  468] time: 19.6081, train_loss: 0.36744311, train_accuracy: 0.9141, test_Accuracy: 0.9039\n",
            "Epoch: [ 0] [   74/  468] time: 19.8044, train_loss: 0.38625735, train_accuracy: 0.9141, test_Accuracy: 0.9037\n",
            "Epoch: [ 0] [   75/  468] time: 20.1395, train_loss: 0.28805292, train_accuracy: 0.9141, test_Accuracy: 0.9011\n",
            "Epoch: [ 0] [   76/  468] time: 20.3694, train_loss: 0.47011083, train_accuracy: 0.8828, test_Accuracy: 0.9016\n",
            "Epoch: [ 0] [   77/  468] time: 20.7000, train_loss: 0.27077311, train_accuracy: 0.9375, test_Accuracy: 0.9029\n",
            "Epoch: [ 0] [   78/  468] time: 21.0334, train_loss: 0.23536861, train_accuracy: 0.9141, test_Accuracy: 0.9060\n",
            "Epoch: [ 0] [   79/  468] time: 21.2285, train_loss: 0.30578104, train_accuracy: 0.9141, test_Accuracy: 0.9089\n",
            "Epoch: [ 0] [   80/  468] time: 21.4308, train_loss: 0.35084277, train_accuracy: 0.8906, test_Accuracy: 0.9095\n",
            "Epoch: [ 0] [   81/  468] time: 21.6379, train_loss: 0.25127125, train_accuracy: 0.9297, test_Accuracy: 0.9068\n",
            "Epoch: [ 0] [   82/  468] time: 21.9684, train_loss: 0.28839281, train_accuracy: 0.9062, test_Accuracy: 0.9015\n",
            "Epoch: [ 0] [   83/  468] time: 22.2996, train_loss: 0.31219947, train_accuracy: 0.9141, test_Accuracy: 0.8994\n",
            "Epoch: [ 0] [   84/  468] time: 22.6325, train_loss: 0.26233691, train_accuracy: 0.9375, test_Accuracy: 0.9025\n",
            "Epoch: [ 0] [   85/  468] time: 22.8381, train_loss: 0.34142756, train_accuracy: 0.8984, test_Accuracy: 0.9076\n",
            "Epoch: [ 0] [   86/  468] time: 23.0381, train_loss: 0.36749095, train_accuracy: 0.8984, test_Accuracy: 0.9113\n",
            "Epoch: [ 0] [   87/  468] time: 23.2421, train_loss: 0.28087533, train_accuracy: 0.8906, test_Accuracy: 0.9127\n",
            "Epoch: [ 0] [   88/  468] time: 23.5737, train_loss: 0.29051769, train_accuracy: 0.9219, test_Accuracy: 0.9125\n",
            "Epoch: [ 0] [   89/  468] time: 23.9060, train_loss: 0.39609370, train_accuracy: 0.8906, test_Accuracy: 0.9130\n",
            "Epoch: [ 0] [   90/  468] time: 24.1005, train_loss: 0.25401706, train_accuracy: 0.9297, test_Accuracy: 0.9100\n",
            "Epoch: [ 0] [   91/  468] time: 24.4394, train_loss: 0.21197706, train_accuracy: 0.9297, test_Accuracy: 0.9079\n",
            "Epoch: [ 0] [   92/  468] time: 24.7702, train_loss: 0.20227711, train_accuracy: 0.9453, test_Accuracy: 0.9075\n",
            "Epoch: [ 0] [   93/  468] time: 24.9770, train_loss: 0.31000531, train_accuracy: 0.9375, test_Accuracy: 0.9085\n",
            "Epoch: [ 0] [   94/  468] time: 25.1841, train_loss: 0.35346192, train_accuracy: 0.9297, test_Accuracy: 0.9111\n",
            "Epoch: [ 0] [   95/  468] time: 25.4009, train_loss: 0.24198338, train_accuracy: 0.9219, test_Accuracy: 0.9134\n",
            "Epoch: [ 0] [   96/  468] time: 25.5969, train_loss: 0.28738070, train_accuracy: 0.9141, test_Accuracy: 0.9122\n",
            "Epoch: [ 0] [   97/  468] time: 25.9317, train_loss: 0.31623602, train_accuracy: 0.9141, test_Accuracy: 0.9121\n",
            "Epoch: [ 0] [   98/  468] time: 26.2627, train_loss: 0.22725865, train_accuracy: 0.9453, test_Accuracy: 0.9135\n",
            "Epoch: [ 0] [   99/  468] time: 26.5942, train_loss: 0.27384412, train_accuracy: 0.9219, test_Accuracy: 0.9128\n",
            "Epoch: [ 0] [  100/  468] time: 26.7998, train_loss: 0.37761194, train_accuracy: 0.9062, test_Accuracy: 0.9150\n",
            "Epoch: [ 0] [  101/  468] time: 27.1321, train_loss: 0.16390395, train_accuracy: 0.9609, test_Accuracy: 0.9169\n",
            "Epoch: [ 0] [  102/  468] time: 27.4651, train_loss: 0.28656438, train_accuracy: 0.9062, test_Accuracy: 0.9177\n",
            "Epoch: [ 0] [  103/  468] time: 27.7962, train_loss: 0.35819679, train_accuracy: 0.9062, test_Accuracy: 0.9195\n",
            "Epoch: [ 0] [  104/  468] time: 27.9959, train_loss: 0.32294041, train_accuracy: 0.8984, test_Accuracy: 0.9201\n",
            "Epoch: [ 0] [  105/  468] time: 28.3302, train_loss: 0.29512399, train_accuracy: 0.9297, test_Accuracy: 0.9162\n",
            "Epoch: [ 0] [  106/  468] time: 28.5307, train_loss: 0.26888752, train_accuracy: 0.9375, test_Accuracy: 0.9114\n",
            "Epoch: [ 0] [  107/  468] time: 28.7395, train_loss: 0.35786760, train_accuracy: 0.8750, test_Accuracy: 0.9113\n",
            "Epoch: [ 0] [  108/  468] time: 29.0765, train_loss: 0.24323517, train_accuracy: 0.9297, test_Accuracy: 0.9151\n",
            "Epoch: [ 0] [  109/  468] time: 29.2683, train_loss: 0.25353956, train_accuracy: 0.9297, test_Accuracy: 0.9183\n",
            "Epoch: [ 0] [  110/  468] time: 29.6036, train_loss: 0.22990407, train_accuracy: 0.9453, test_Accuracy: 0.9193\n",
            "Epoch: [ 0] [  111/  468] time: 29.9352, train_loss: 0.36544272, train_accuracy: 0.9062, test_Accuracy: 0.9179\n",
            "Epoch: [ 0] [  112/  468] time: 30.2654, train_loss: 0.24362242, train_accuracy: 0.9297, test_Accuracy: 0.9170\n",
            "Epoch: [ 0] [  113/  468] time: 30.4623, train_loss: 0.40936202, train_accuracy: 0.8984, test_Accuracy: 0.9149\n",
            "Epoch: [ 0] [  114/  468] time: 30.6520, train_loss: 0.22893721, train_accuracy: 0.9141, test_Accuracy: 0.9105\n",
            "Epoch: [ 0] [  115/  468] time: 30.9859, train_loss: 0.22824764, train_accuracy: 0.9297, test_Accuracy: 0.9083\n",
            "Epoch: [ 0] [  116/  468] time: 31.1846, train_loss: 0.36416677, train_accuracy: 0.8984, test_Accuracy: 0.9125\n",
            "Epoch: [ 0] [  117/  468] time: 31.3845, train_loss: 0.16461486, train_accuracy: 0.9531, test_Accuracy: 0.9170\n",
            "Epoch: [ 0] [  118/  468] time: 31.5791, train_loss: 0.21140487, train_accuracy: 0.9375, test_Accuracy: 0.9180\n",
            "Epoch: [ 0] [  119/  468] time: 31.9200, train_loss: 0.24392639, train_accuracy: 0.9219, test_Accuracy: 0.9151\n",
            "Epoch: [ 0] [  120/  468] time: 32.1192, train_loss: 0.26016405, train_accuracy: 0.9219, test_Accuracy: 0.9140\n",
            "Epoch: [ 0] [  121/  468] time: 32.4625, train_loss: 0.30548447, train_accuracy: 0.9062, test_Accuracy: 0.9140\n",
            "Epoch: [ 0] [  122/  468] time: 32.6596, train_loss: 0.38360086, train_accuracy: 0.8516, test_Accuracy: 0.9151\n",
            "Epoch: [ 0] [  123/  468] time: 32.9954, train_loss: 0.33049619, train_accuracy: 0.9141, test_Accuracy: 0.9165\n",
            "Epoch: [ 0] [  124/  468] time: 33.1894, train_loss: 0.28407609, train_accuracy: 0.9297, test_Accuracy: 0.9193\n",
            "Epoch: [ 0] [  125/  468] time: 33.3963, train_loss: 0.26972413, train_accuracy: 0.9297, test_Accuracy: 0.9225\n",
            "Epoch: [ 0] [  126/  468] time: 33.5950, train_loss: 0.28777421, train_accuracy: 0.9297, test_Accuracy: 0.9220\n",
            "Epoch: [ 0] [  127/  468] time: 33.7923, train_loss: 0.28425133, train_accuracy: 0.8906, test_Accuracy: 0.9196\n",
            "Epoch: [ 0] [  128/  468] time: 34.1227, train_loss: 0.25621325, train_accuracy: 0.9688, test_Accuracy: 0.9165\n",
            "Epoch: [ 0] [  129/  468] time: 34.3199, train_loss: 0.38325104, train_accuracy: 0.8828, test_Accuracy: 0.9194\n",
            "Epoch: [ 0] [  130/  468] time: 34.6556, train_loss: 0.20531617, train_accuracy: 0.9297, test_Accuracy: 0.9205\n",
            "Epoch: [ 0] [  131/  468] time: 34.9916, train_loss: 0.20177698, train_accuracy: 0.9453, test_Accuracy: 0.9198\n",
            "Epoch: [ 0] [  132/  468] time: 35.1923, train_loss: 0.33126700, train_accuracy: 0.8984, test_Accuracy: 0.9176\n",
            "Epoch: [ 0] [  133/  468] time: 35.3978, train_loss: 0.24671602, train_accuracy: 0.9375, test_Accuracy: 0.9147\n",
            "Epoch: [ 0] [  134/  468] time: 35.6041, train_loss: 0.23712902, train_accuracy: 0.9141, test_Accuracy: 0.9091\n",
            "Epoch: [ 0] [  135/  468] time: 35.7994, train_loss: 0.20415652, train_accuracy: 0.9531, test_Accuracy: 0.9110\n",
            "Epoch: [ 0] [  136/  468] time: 36.0106, train_loss: 0.18985710, train_accuracy: 0.9453, test_Accuracy: 0.9125\n",
            "Epoch: [ 0] [  137/  468] time: 36.3432, train_loss: 0.22765404, train_accuracy: 0.9297, test_Accuracy: 0.9150\n",
            "Epoch: [ 0] [  138/  468] time: 36.5533, train_loss: 0.24556369, train_accuracy: 0.9062, test_Accuracy: 0.9210\n",
            "Epoch: [ 0] [  139/  468] time: 36.7623, train_loss: 0.26781881, train_accuracy: 0.9141, test_Accuracy: 0.9261\n",
            "Epoch: [ 0] [  140/  468] time: 36.9784, train_loss: 0.29143128, train_accuracy: 0.8984, test_Accuracy: 0.9263\n",
            "Epoch: [ 0] [  141/  468] time: 37.1847, train_loss: 0.21470194, train_accuracy: 0.9375, test_Accuracy: 0.9249\n",
            "Epoch: [ 0] [  142/  468] time: 37.3870, train_loss: 0.30483526, train_accuracy: 0.9062, test_Accuracy: 0.9248\n",
            "Epoch: [ 0] [  143/  468] time: 37.6019, train_loss: 0.19117922, train_accuracy: 0.9609, test_Accuracy: 0.9237\n",
            "Epoch: [ 0] [  144/  468] time: 37.9326, train_loss: 0.26827908, train_accuracy: 0.8984, test_Accuracy: 0.9241\n",
            "Epoch: [ 0] [  145/  468] time: 38.2745, train_loss: 0.23062229, train_accuracy: 0.9219, test_Accuracy: 0.9248\n",
            "Epoch: [ 0] [  146/  468] time: 38.4937, train_loss: 0.21475676, train_accuracy: 0.9297, test_Accuracy: 0.9281\n",
            "Epoch: [ 0] [  147/  468] time: 38.8290, train_loss: 0.13311991, train_accuracy: 0.9531, test_Accuracy: 0.9296\n",
            "Epoch: [ 0] [  148/  468] time: 39.0503, train_loss: 0.23676026, train_accuracy: 0.9453, test_Accuracy: 0.9293\n",
            "Epoch: [ 0] [  149/  468] time: 39.3897, train_loss: 0.32613412, train_accuracy: 0.8672, test_Accuracy: 0.9302\n",
            "Epoch: [ 0] [  150/  468] time: 39.7202, train_loss: 0.18106577, train_accuracy: 0.9531, test_Accuracy: 0.9306\n",
            "Epoch: [ 0] [  151/  468] time: 39.9116, train_loss: 0.24957407, train_accuracy: 0.9453, test_Accuracy: 0.9284\n",
            "Epoch: [ 0] [  152/  468] time: 40.1149, train_loss: 0.25332150, train_accuracy: 0.9219, test_Accuracy: 0.9265\n",
            "Epoch: [ 0] [  153/  468] time: 40.3124, train_loss: 0.24524838, train_accuracy: 0.9375, test_Accuracy: 0.9258\n",
            "Epoch: [ 0] [  154/  468] time: 40.5088, train_loss: 0.30035880, train_accuracy: 0.9062, test_Accuracy: 0.9265\n",
            "Epoch: [ 0] [  155/  468] time: 40.7075, train_loss: 0.27058738, train_accuracy: 0.9062, test_Accuracy: 0.9312\n",
            "Epoch: [ 0] [  156/  468] time: 40.9084, train_loss: 0.20445001, train_accuracy: 0.9375, test_Accuracy: 0.9313\n",
            "Epoch: [ 0] [  157/  468] time: 41.2397, train_loss: 0.16532224, train_accuracy: 0.9609, test_Accuracy: 0.9302\n",
            "Epoch: [ 0] [  158/  468] time: 41.4319, train_loss: 0.29646999, train_accuracy: 0.8984, test_Accuracy: 0.9291\n",
            "Epoch: [ 0] [  159/  468] time: 41.6336, train_loss: 0.22228074, train_accuracy: 0.9531, test_Accuracy: 0.9289\n",
            "Epoch: [ 0] [  160/  468] time: 41.8272, train_loss: 0.23474272, train_accuracy: 0.9062, test_Accuracy: 0.9286\n",
            "Epoch: [ 0] [  161/  468] time: 42.0727, train_loss: 0.20349589, train_accuracy: 0.9375, test_Accuracy: 0.9282\n",
            "Epoch: [ 0] [  162/  468] time: 42.8626, train_loss: 0.26635897, train_accuracy: 0.8828, test_Accuracy: 0.9306\n",
            "Epoch: [ 0] [  163/  468] time: 43.1941, train_loss: 0.23182477, train_accuracy: 0.9375, test_Accuracy: 0.9311\n",
            "Epoch: [ 0] [  164/  468] time: 43.8913, train_loss: 0.22956064, train_accuracy: 0.9062, test_Accuracy: 0.9290\n",
            "Epoch: [ 0] [  165/  468] time: 44.2241, train_loss: 0.22354753, train_accuracy: 0.9375, test_Accuracy: 0.9267\n",
            "Epoch: [ 0] [  166/  468] time: 44.6247, train_loss: 0.23171785, train_accuracy: 0.9453, test_Accuracy: 0.9288\n",
            "Epoch: [ 0] [  167/  468] time: 44.9559, train_loss: 0.17898645, train_accuracy: 0.9375, test_Accuracy: 0.9311\n",
            "Epoch: [ 0] [  168/  468] time: 45.2908, train_loss: 0.11884983, train_accuracy: 0.9609, test_Accuracy: 0.9339\n",
            "Epoch: [ 0] [  169/  468] time: 45.6237, train_loss: 0.22028172, train_accuracy: 0.9297, test_Accuracy: 0.9353\n",
            "Epoch: [ 0] [  170/  468] time: 45.8140, train_loss: 0.28038979, train_accuracy: 0.9141, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  171/  468] time: 46.0189, train_loss: 0.27160752, train_accuracy: 0.9375, test_Accuracy: 0.9336\n",
            "Epoch: [ 0] [  172/  468] time: 46.3541, train_loss: 0.19458491, train_accuracy: 0.9375, test_Accuracy: 0.9344\n",
            "Epoch: [ 0] [  173/  468] time: 46.6870, train_loss: 0.20220551, train_accuracy: 0.9297, test_Accuracy: 0.9333\n",
            "Epoch: [ 0] [  174/  468] time: 46.8805, train_loss: 0.28646845, train_accuracy: 0.9219, test_Accuracy: 0.9292\n",
            "Epoch: [ 0] [  175/  468] time: 47.2167, train_loss: 0.23222354, train_accuracy: 0.9141, test_Accuracy: 0.9284\n",
            "Epoch: [ 0] [  176/  468] time: 47.4453, train_loss: 0.31109872, train_accuracy: 0.8984, test_Accuracy: 0.9298\n",
            "Epoch: [ 0] [  177/  468] time: 47.7753, train_loss: 0.23237891, train_accuracy: 0.9375, test_Accuracy: 0.9312\n",
            "Epoch: [ 0] [  178/  468] time: 47.9884, train_loss: 0.16295700, train_accuracy: 0.9531, test_Accuracy: 0.9336\n",
            "Epoch: [ 0] [  179/  468] time: 48.3198, train_loss: 0.19212218, train_accuracy: 0.9297, test_Accuracy: 0.9353\n",
            "Epoch: [ 0] [  180/  468] time: 48.5132, train_loss: 0.25996432, train_accuracy: 0.9141, test_Accuracy: 0.9352\n",
            "Epoch: [ 0] [  181/  468] time: 48.8488, train_loss: 0.29732227, train_accuracy: 0.8984, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  182/  468] time: 49.1823, train_loss: 0.18556708, train_accuracy: 0.9453, test_Accuracy: 0.9369\n",
            "Epoch: [ 0] [  183/  468] time: 49.5159, train_loss: 0.16016063, train_accuracy: 0.9375, test_Accuracy: 0.9361\n",
            "Epoch: [ 0] [  184/  468] time: 49.7100, train_loss: 0.12331916, train_accuracy: 0.9609, test_Accuracy: 0.9353\n",
            "Epoch: [ 0] [  185/  468] time: 49.9065, train_loss: 0.25188440, train_accuracy: 0.9297, test_Accuracy: 0.9355\n",
            "Epoch: [ 0] [  186/  468] time: 50.0994, train_loss: 0.28121206, train_accuracy: 0.9141, test_Accuracy: 0.9336\n",
            "Epoch: [ 0] [  187/  468] time: 50.4327, train_loss: 0.26582250, train_accuracy: 0.9375, test_Accuracy: 0.9333\n",
            "Epoch: [ 0] [  188/  468] time: 50.6338, train_loss: 0.19602242, train_accuracy: 0.9453, test_Accuracy: 0.9333\n",
            "Epoch: [ 0] [  189/  468] time: 50.9675, train_loss: 0.20387693, train_accuracy: 0.9453, test_Accuracy: 0.9333\n",
            "Epoch: [ 0] [  190/  468] time: 51.2986, train_loss: 0.16269797, train_accuracy: 0.9297, test_Accuracy: 0.9318\n",
            "Epoch: [ 0] [  191/  468] time: 51.6411, train_loss: 0.21670288, train_accuracy: 0.9375, test_Accuracy: 0.9335\n",
            "Epoch: [ 0] [  192/  468] time: 51.8353, train_loss: 0.34446689, train_accuracy: 0.9141, test_Accuracy: 0.9346\n",
            "Epoch: [ 0] [  193/  468] time: 52.0260, train_loss: 0.12601054, train_accuracy: 0.9609, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [  194/  468] time: 52.3592, train_loss: 0.30275804, train_accuracy: 0.9141, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [  195/  468] time: 52.6905, train_loss: 0.22778681, train_accuracy: 0.9141, test_Accuracy: 0.9411\n",
            "Epoch: [ 0] [  196/  468] time: 52.9024, train_loss: 0.16488671, train_accuracy: 0.9609, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  197/  468] time: 53.0976, train_loss: 0.19806693, train_accuracy: 0.9375, test_Accuracy: 0.9414\n",
            "Epoch: [ 0] [  198/  468] time: 53.2963, train_loss: 0.19089594, train_accuracy: 0.9688, test_Accuracy: 0.9411\n",
            "Epoch: [ 0] [  199/  468] time: 53.6298, train_loss: 0.13941759, train_accuracy: 0.9375, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  200/  468] time: 53.9615, train_loss: 0.10708986, train_accuracy: 0.9688, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  201/  468] time: 54.2918, train_loss: 0.25036383, train_accuracy: 0.9062, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  202/  468] time: 54.4869, train_loss: 0.25282261, train_accuracy: 0.9141, test_Accuracy: 0.9392\n",
            "Epoch: [ 0] [  203/  468] time: 54.6948, train_loss: 0.15780750, train_accuracy: 0.9531, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  204/  468] time: 54.8926, train_loss: 0.20878136, train_accuracy: 0.9609, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  205/  468] time: 55.1008, train_loss: 0.18569225, train_accuracy: 0.9297, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  206/  468] time: 55.3132, train_loss: 0.15919203, train_accuracy: 0.9609, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  207/  468] time: 55.6437, train_loss: 0.16842684, train_accuracy: 0.9453, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  208/  468] time: 55.9974, train_loss: 0.15628505, train_accuracy: 0.9453, test_Accuracy: 0.9404\n",
            "Epoch: [ 0] [  209/  468] time: 56.3483, train_loss: 0.27240610, train_accuracy: 0.9375, test_Accuracy: 0.9380\n",
            "Epoch: [ 0] [  210/  468] time: 57.0112, train_loss: 0.13936064, train_accuracy: 0.9453, test_Accuracy: 0.9368\n",
            "Epoch: [ 0] [  211/  468] time: 57.6815, train_loss: 0.15141255, train_accuracy: 0.9766, test_Accuracy: 0.9374\n",
            "Epoch: [ 0] [  212/  468] time: 58.0157, train_loss: 0.33395138, train_accuracy: 0.9219, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  213/  468] time: 58.2128, train_loss: 0.20919526, train_accuracy: 0.9297, test_Accuracy: 0.9431\n",
            "Epoch: [ 0] [  214/  468] time: 58.4034, train_loss: 0.14047500, train_accuracy: 0.9453, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  215/  468] time: 58.5995, train_loss: 0.27805898, train_accuracy: 0.9219, test_Accuracy: 0.9440\n",
            "Epoch: [ 0] [  216/  468] time: 58.7915, train_loss: 0.20992786, train_accuracy: 0.9531, test_Accuracy: 0.9436\n",
            "Epoch: [ 0] [  217/  468] time: 59.1221, train_loss: 0.29410627, train_accuracy: 0.9219, test_Accuracy: 0.9433\n",
            "Epoch: [ 0] [  218/  468] time: 59.3132, train_loss: 0.17260763, train_accuracy: 0.9609, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  219/  468] time: 59.5257, train_loss: 0.20291717, train_accuracy: 0.9219, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  220/  468] time: 59.8690, train_loss: 0.19453171, train_accuracy: 0.9375, test_Accuracy: 0.9419\n",
            "Epoch: [ 0] [  221/  468] time: 60.2005, train_loss: 0.14708850, train_accuracy: 0.9531, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  222/  468] time: 60.4059, train_loss: 0.20743923, train_accuracy: 0.9531, test_Accuracy: 0.9421\n",
            "Epoch: [ 0] [  223/  468] time: 60.6194, train_loss: 0.19865456, train_accuracy: 0.9375, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  224/  468] time: 60.9517, train_loss: 0.17943956, train_accuracy: 0.9453, test_Accuracy: 0.9434\n",
            "Epoch: [ 0] [  225/  468] time: 61.1630, train_loss: 0.17004067, train_accuracy: 0.9531, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  226/  468] time: 61.4937, train_loss: 0.24006309, train_accuracy: 0.9453, test_Accuracy: 0.9465\n",
            "Epoch: [ 0] [  227/  468] time: 61.8237, train_loss: 0.14228809, train_accuracy: 0.9688, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  228/  468] time: 62.1543, train_loss: 0.15994346, train_accuracy: 0.9297, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  229/  468] time: 62.4851, train_loss: 0.18355073, train_accuracy: 0.9531, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  230/  468] time: 62.8168, train_loss: 0.21699488, train_accuracy: 0.9297, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  231/  468] time: 63.1700, train_loss: 0.16518956, train_accuracy: 0.9375, test_Accuracy: 0.9456\n",
            "Epoch: [ 0] [  232/  468] time: 63.8639, train_loss: 0.18467227, train_accuracy: 0.9453, test_Accuracy: 0.9455\n",
            "Epoch: [ 0] [  233/  468] time: 64.5655, train_loss: 0.22136481, train_accuracy: 0.9297, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  234/  468] time: 64.8980, train_loss: 0.11794060, train_accuracy: 0.9609, test_Accuracy: 0.9448\n",
            "Epoch: [ 0] [  235/  468] time: 65.2312, train_loss: 0.18070289, train_accuracy: 0.9453, test_Accuracy: 0.9425\n",
            "Epoch: [ 0] [  236/  468] time: 65.6787, train_loss: 0.23797816, train_accuracy: 0.9375, test_Accuracy: 0.9412\n",
            "Epoch: [ 0] [  237/  468] time: 65.9031, train_loss: 0.22241738, train_accuracy: 0.9453, test_Accuracy: 0.9402\n",
            "Epoch: [ 0] [  238/  468] time: 66.5810, train_loss: 0.13488218, train_accuracy: 0.9531, test_Accuracy: 0.9400\n",
            "Epoch: [ 0] [  239/  468] time: 67.3122, train_loss: 0.11543826, train_accuracy: 0.9688, test_Accuracy: 0.9404\n",
            "Epoch: [ 0] [  240/  468] time: 67.7066, train_loss: 0.27461779, train_accuracy: 0.9219, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  241/  468] time: 68.0396, train_loss: 0.20858946, train_accuracy: 0.9219, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  242/  468] time: 68.3943, train_loss: 0.16246244, train_accuracy: 0.9609, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  243/  468] time: 68.7518, train_loss: 0.15958533, train_accuracy: 0.9453, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  244/  468] time: 69.0935, train_loss: 0.16156271, train_accuracy: 0.9531, test_Accuracy: 0.9465\n",
            "Epoch: [ 0] [  245/  468] time: 69.4295, train_loss: 0.17235678, train_accuracy: 0.9531, test_Accuracy: 0.9449\n",
            "Epoch: [ 0] [  246/  468] time: 69.7616, train_loss: 0.19600630, train_accuracy: 0.9219, test_Accuracy: 0.9428\n",
            "Epoch: [ 0] [  247/  468] time: 70.1598, train_loss: 0.19624189, train_accuracy: 0.9453, test_Accuracy: 0.9416\n",
            "Epoch: [ 0] [  248/  468] time: 70.8554, train_loss: 0.29193318, train_accuracy: 0.9141, test_Accuracy: 0.9448\n",
            "Epoch: [ 0] [  249/  468] time: 71.2356, train_loss: 0.15285456, train_accuracy: 0.9453, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  250/  468] time: 71.5855, train_loss: 0.23221813, train_accuracy: 0.9531, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  251/  468] time: 71.8541, train_loss: 0.12462797, train_accuracy: 0.9688, test_Accuracy: 0.9439\n",
            "Epoch: [ 0] [  252/  468] time: 72.1263, train_loss: 0.27483004, train_accuracy: 0.9062, test_Accuracy: 0.9423\n",
            "Epoch: [ 0] [  253/  468] time: 72.3270, train_loss: 0.17510369, train_accuracy: 0.9531, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  254/  468] time: 73.0038, train_loss: 0.18884724, train_accuracy: 0.9531, test_Accuracy: 0.9393\n",
            "Epoch: [ 0] [  255/  468] time: 73.2531, train_loss: 0.16994512, train_accuracy: 0.9297, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  256/  468] time: 73.5847, train_loss: 0.19200581, train_accuracy: 0.9375, test_Accuracy: 0.9398\n",
            "Epoch: [ 0] [  257/  468] time: 74.2765, train_loss: 0.33769518, train_accuracy: 0.9219, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  258/  468] time: 74.5894, train_loss: 0.16015995, train_accuracy: 0.9531, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  259/  468] time: 74.9217, train_loss: 0.17067444, train_accuracy: 0.9375, test_Accuracy: 0.9454\n",
            "Epoch: [ 0] [  260/  468] time: 75.1410, train_loss: 0.18505314, train_accuracy: 0.9609, test_Accuracy: 0.9434\n",
            "Epoch: [ 0] [  261/  468] time: 75.4751, train_loss: 0.19202191, train_accuracy: 0.9453, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  262/  468] time: 75.6736, train_loss: 0.37385622, train_accuracy: 0.8750, test_Accuracy: 0.9444\n",
            "Epoch: [ 0] [  263/  468] time: 76.0106, train_loss: 0.15482850, train_accuracy: 0.9531, test_Accuracy: 0.9443\n",
            "Epoch: [ 0] [  264/  468] time: 76.2200, train_loss: 0.21455678, train_accuracy: 0.9375, test_Accuracy: 0.9451\n",
            "Epoch: [ 0] [  265/  468] time: 76.5552, train_loss: 0.16611317, train_accuracy: 0.9531, test_Accuracy: 0.9459\n",
            "Epoch: [ 0] [  266/  468] time: 76.8864, train_loss: 0.23320659, train_accuracy: 0.9609, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  267/  468] time: 77.0843, train_loss: 0.13422810, train_accuracy: 0.9531, test_Accuracy: 0.9457\n",
            "Epoch: [ 0] [  268/  468] time: 77.2793, train_loss: 0.17347521, train_accuracy: 0.9375, test_Accuracy: 0.9443\n",
            "Epoch: [ 0] [  269/  468] time: 77.4883, train_loss: 0.24116525, train_accuracy: 0.9375, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  270/  468] time: 77.6793, train_loss: 0.17162420, train_accuracy: 0.9375, test_Accuracy: 0.9438\n",
            "Epoch: [ 0] [  271/  468] time: 78.0168, train_loss: 0.18369782, train_accuracy: 0.9453, test_Accuracy: 0.9455\n",
            "Epoch: [ 0] [  272/  468] time: 78.7431, train_loss: 0.12507594, train_accuracy: 0.9688, test_Accuracy: 0.9451\n",
            "Epoch: [ 0] [  273/  468] time: 79.0946, train_loss: 0.21947402, train_accuracy: 0.9375, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  274/  468] time: 79.2866, train_loss: 0.11336157, train_accuracy: 0.9688, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  275/  468] time: 79.6216, train_loss: 0.23916820, train_accuracy: 0.9531, test_Accuracy: 0.9475\n",
            "Epoch: [ 0] [  276/  468] time: 79.9534, train_loss: 0.18280271, train_accuracy: 0.9297, test_Accuracy: 0.9459\n",
            "Epoch: [ 0] [  277/  468] time: 80.2867, train_loss: 0.30961680, train_accuracy: 0.8984, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  278/  468] time: 80.6193, train_loss: 0.25152814, train_accuracy: 0.9062, test_Accuracy: 0.9464\n",
            "Epoch: [ 0] [  279/  468] time: 80.9528, train_loss: 0.21778139, train_accuracy: 0.9219, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  280/  468] time: 81.1648, train_loss: 0.13076663, train_accuracy: 0.9609, test_Accuracy: 0.9453\n",
            "Epoch: [ 0] [  281/  468] time: 81.4997, train_loss: 0.16770598, train_accuracy: 0.9375, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  282/  468] time: 81.6885, train_loss: 0.13215242, train_accuracy: 0.9688, test_Accuracy: 0.9413\n",
            "Epoch: [ 0] [  283/  468] time: 81.8846, train_loss: 0.12650578, train_accuracy: 0.9688, test_Accuracy: 0.9407\n",
            "Epoch: [ 0] [  284/  468] time: 82.1008, train_loss: 0.16235490, train_accuracy: 0.9453, test_Accuracy: 0.9439\n",
            "Epoch: [ 0] [  285/  468] time: 82.4318, train_loss: 0.13200441, train_accuracy: 0.9844, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  286/  468] time: 82.6275, train_loss: 0.20697330, train_accuracy: 0.9375, test_Accuracy: 0.9500\n",
            "Epoch: [ 0] [  287/  468] time: 82.8332, train_loss: 0.12974396, train_accuracy: 0.9688, test_Accuracy: 0.9519\n",
            "Epoch: [ 0] [  288/  468] time: 83.0240, train_loss: 0.09753259, train_accuracy: 0.9688, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  289/  468] time: 83.2212, train_loss: 0.15656576, train_accuracy: 0.9688, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  290/  468] time: 83.4114, train_loss: 0.11268878, train_accuracy: 0.9609, test_Accuracy: 0.9538\n",
            "Epoch: [ 0] [  291/  468] time: 83.7497, train_loss: 0.10654830, train_accuracy: 0.9766, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  292/  468] time: 83.9362, train_loss: 0.28225133, train_accuracy: 0.9141, test_Accuracy: 0.9518\n",
            "Epoch: [ 0] [  293/  468] time: 84.2717, train_loss: 0.17858912, train_accuracy: 0.9375, test_Accuracy: 0.9512\n",
            "Epoch: [ 0] [  294/  468] time: 84.4707, train_loss: 0.09888259, train_accuracy: 0.9688, test_Accuracy: 0.9515\n",
            "Epoch: [ 0] [  295/  468] time: 84.8079, train_loss: 0.19442895, train_accuracy: 0.9609, test_Accuracy: 0.9519\n",
            "Epoch: [ 0] [  296/  468] time: 85.0053, train_loss: 0.13538989, train_accuracy: 0.9609, test_Accuracy: 0.9521\n",
            "Epoch: [ 0] [  297/  468] time: 85.2245, train_loss: 0.13088529, train_accuracy: 0.9609, test_Accuracy: 0.9512\n",
            "Epoch: [ 0] [  298/  468] time: 85.4210, train_loss: 0.19115837, train_accuracy: 0.9531, test_Accuracy: 0.9525\n",
            "Epoch: [ 0] [  299/  468] time: 85.6245, train_loss: 0.20872495, train_accuracy: 0.9297, test_Accuracy: 0.9518\n",
            "Epoch: [ 0] [  300/  468] time: 85.8245, train_loss: 0.11615787, train_accuracy: 0.9531, test_Accuracy: 0.9511\n",
            "Epoch: [ 0] [  301/  468] time: 86.1621, train_loss: 0.14225087, train_accuracy: 0.9531, test_Accuracy: 0.9514\n",
            "Epoch: [ 0] [  302/  468] time: 86.3712, train_loss: 0.14464861, train_accuracy: 0.9375, test_Accuracy: 0.9521\n",
            "Epoch: [ 0] [  303/  468] time: 86.7035, train_loss: 0.14984934, train_accuracy: 0.9297, test_Accuracy: 0.9536\n",
            "Epoch: [ 0] [  304/  468] time: 86.9113, train_loss: 0.14918834, train_accuracy: 0.9609, test_Accuracy: 0.9534\n",
            "Epoch: [ 0] [  305/  468] time: 87.1024, train_loss: 0.09240896, train_accuracy: 0.9844, test_Accuracy: 0.9525\n",
            "Epoch: [ 0] [  306/  468] time: 87.4772, train_loss: 0.23243731, train_accuracy: 0.9531, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  307/  468] time: 87.7136, train_loss: 0.22230330, train_accuracy: 0.9219, test_Accuracy: 0.9521\n",
            "Epoch: [ 0] [  308/  468] time: 87.9154, train_loss: 0.15607059, train_accuracy: 0.9531, test_Accuracy: 0.9520\n",
            "Epoch: [ 0] [  309/  468] time: 88.2655, train_loss: 0.14461395, train_accuracy: 0.9609, test_Accuracy: 0.9514\n",
            "Epoch: [ 0] [  310/  468] time: 88.5246, train_loss: 0.07083307, train_accuracy: 0.9922, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  311/  468] time: 88.7657, train_loss: 0.09550779, train_accuracy: 0.9766, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  312/  468] time: 89.1211, train_loss: 0.15398458, train_accuracy: 0.9531, test_Accuracy: 0.9500\n",
            "Epoch: [ 0] [  313/  468] time: 89.4533, train_loss: 0.14847282, train_accuracy: 0.9609, test_Accuracy: 0.9507\n",
            "Epoch: [ 0] [  314/  468] time: 89.7183, train_loss: 0.13205457, train_accuracy: 0.9766, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  315/  468] time: 90.2362, train_loss: 0.11888941, train_accuracy: 0.9609, test_Accuracy: 0.9506\n",
            "Epoch: [ 0] [  316/  468] time: 90.5629, train_loss: 0.16770677, train_accuracy: 0.9375, test_Accuracy: 0.9514\n",
            "Epoch: [ 0] [  317/  468] time: 90.7878, train_loss: 0.29544985, train_accuracy: 0.9219, test_Accuracy: 0.9510\n",
            "Epoch: [ 0] [  318/  468] time: 91.0784, train_loss: 0.16315514, train_accuracy: 0.9609, test_Accuracy: 0.9498\n",
            "Epoch: [ 0] [  319/  468] time: 91.7504, train_loss: 0.20502950, train_accuracy: 0.9375, test_Accuracy: 0.9467\n",
            "Epoch: [ 0] [  320/  468] time: 92.0152, train_loss: 0.15975226, train_accuracy: 0.9531, test_Accuracy: 0.9457\n",
            "Epoch: [ 0] [  321/  468] time: 92.3472, train_loss: 0.30702388, train_accuracy: 0.9453, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  322/  468] time: 92.5892, train_loss: 0.08921134, train_accuracy: 0.9766, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  323/  468] time: 92.9502, train_loss: 0.13679802, train_accuracy: 0.9453, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  324/  468] time: 93.3036, train_loss: 0.12596521, train_accuracy: 0.9531, test_Accuracy: 0.9512\n",
            "Epoch: [ 0] [  325/  468] time: 93.6551, train_loss: 0.11180580, train_accuracy: 0.9688, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  326/  468] time: 94.3108, train_loss: 0.14302301, train_accuracy: 0.9688, test_Accuracy: 0.9534\n",
            "Epoch: [ 0] [  327/  468] time: 94.6000, train_loss: 0.14599709, train_accuracy: 0.9531, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  328/  468] time: 94.9313, train_loss: 0.08475141, train_accuracy: 0.9766, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  329/  468] time: 95.2631, train_loss: 0.10433310, train_accuracy: 0.9766, test_Accuracy: 0.9516\n",
            "Epoch: [ 0] [  330/  468] time: 95.4964, train_loss: 0.17477670, train_accuracy: 0.9609, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  331/  468] time: 95.8399, train_loss: 0.13748284, train_accuracy: 0.9688, test_Accuracy: 0.9508\n",
            "Epoch: [ 0] [  332/  468] time: 96.1705, train_loss: 0.19346027, train_accuracy: 0.9297, test_Accuracy: 0.9501\n",
            "Epoch: [ 0] [  333/  468] time: 96.3607, train_loss: 0.09409124, train_accuracy: 0.9766, test_Accuracy: 0.9496\n",
            "Epoch: [ 0] [  334/  468] time: 97.0340, train_loss: 0.13220307, train_accuracy: 0.9609, test_Accuracy: 0.9509\n",
            "Epoch: [ 0] [  335/  468] time: 97.2692, train_loss: 0.15844667, train_accuracy: 0.9531, test_Accuracy: 0.9520\n",
            "Epoch: [ 0] [  336/  468] time: 97.6002, train_loss: 0.19592863, train_accuracy: 0.9688, test_Accuracy: 0.9530\n",
            "Epoch: [ 0] [  337/  468] time: 97.8625, train_loss: 0.28272802, train_accuracy: 0.9219, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  338/  468] time: 98.0943, train_loss: 0.07084644, train_accuracy: 0.9922, test_Accuracy: 0.9561\n",
            "Epoch: [ 0] [  339/  468] time: 98.4304, train_loss: 0.08377901, train_accuracy: 0.9766, test_Accuracy: 0.9560\n",
            "Epoch: [ 0] [  340/  468] time: 98.7399, train_loss: 0.18069309, train_accuracy: 0.9297, test_Accuracy: 0.9552\n",
            "Epoch: [ 0] [  341/  468] time: 99.0758, train_loss: 0.11056991, train_accuracy: 0.9531, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  342/  468] time: 99.3865, train_loss: 0.12522233, train_accuracy: 0.9609, test_Accuracy: 0.9511\n",
            "Epoch: [ 0] [  343/  468] time: 99.7203, train_loss: 0.15891171, train_accuracy: 0.9531, test_Accuracy: 0.9510\n",
            "Epoch: [ 0] [  344/  468] time: 100.0514, train_loss: 0.22819988, train_accuracy: 0.9531, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  345/  468] time: 100.4047, train_loss: 0.18836935, train_accuracy: 0.9531, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  346/  468] time: 100.7435, train_loss: 0.16246042, train_accuracy: 0.9453, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  347/  468] time: 100.9979, train_loss: 0.16370732, train_accuracy: 0.9609, test_Accuracy: 0.9529\n",
            "Epoch: [ 0] [  348/  468] time: 101.1989, train_loss: 0.21412674, train_accuracy: 0.9531, test_Accuracy: 0.9530\n",
            "Epoch: [ 0] [  349/  468] time: 101.5330, train_loss: 0.11146117, train_accuracy: 0.9609, test_Accuracy: 0.9527\n",
            "Epoch: [ 0] [  350/  468] time: 101.7311, train_loss: 0.14520122, train_accuracy: 0.9609, test_Accuracy: 0.9525\n",
            "Epoch: [ 0] [  351/  468] time: 102.0685, train_loss: 0.19864275, train_accuracy: 0.9531, test_Accuracy: 0.9529\n",
            "Epoch: [ 0] [  352/  468] time: 102.4003, train_loss: 0.15436667, train_accuracy: 0.9531, test_Accuracy: 0.9529\n",
            "Epoch: [ 0] [  353/  468] time: 102.7370, train_loss: 0.15236324, train_accuracy: 0.9766, test_Accuracy: 0.9536\n",
            "Epoch: [ 0] [  354/  468] time: 103.0685, train_loss: 0.06387089, train_accuracy: 0.9844, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  355/  468] time: 103.4006, train_loss: 0.18754776, train_accuracy: 0.9453, test_Accuracy: 0.9534\n",
            "Epoch: [ 0] [  356/  468] time: 103.7338, train_loss: 0.13431643, train_accuracy: 0.9375, test_Accuracy: 0.9538\n",
            "Epoch: [ 0] [  357/  468] time: 103.9240, train_loss: 0.16689350, train_accuracy: 0.9844, test_Accuracy: 0.9543\n",
            "Epoch: [ 0] [  358/  468] time: 104.1092, train_loss: 0.13564511, train_accuracy: 0.9766, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  359/  468] time: 104.2999, train_loss: 0.25931042, train_accuracy: 0.9141, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  360/  468] time: 104.5039, train_loss: 0.15461093, train_accuracy: 0.9609, test_Accuracy: 0.9560\n",
            "Epoch: [ 0] [  361/  468] time: 104.7140, train_loss: 0.07308435, train_accuracy: 0.9844, test_Accuracy: 0.9562\n",
            "Epoch: [ 0] [  362/  468] time: 105.0452, train_loss: 0.15490711, train_accuracy: 0.9297, test_Accuracy: 0.9569\n",
            "Epoch: [ 0] [  363/  468] time: 105.3845, train_loss: 0.10982095, train_accuracy: 0.9844, test_Accuracy: 0.9559\n",
            "Epoch: [ 0] [  364/  468] time: 105.5938, train_loss: 0.17744651, train_accuracy: 0.9609, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  365/  468] time: 105.8017, train_loss: 0.12523538, train_accuracy: 0.9609, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  366/  468] time: 106.0071, train_loss: 0.18513072, train_accuracy: 0.9297, test_Accuracy: 0.9534\n",
            "Epoch: [ 0] [  367/  468] time: 106.3435, train_loss: 0.22012074, train_accuracy: 0.9453, test_Accuracy: 0.9538\n",
            "Epoch: [ 0] [  368/  468] time: 106.6756, train_loss: 0.07894858, train_accuracy: 0.9688, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  369/  468] time: 106.8967, train_loss: 0.08626038, train_accuracy: 0.9922, test_Accuracy: 0.9547\n",
            "Epoch: [ 0] [  370/  468] time: 107.2289, train_loss: 0.11434872, train_accuracy: 0.9609, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  371/  468] time: 107.5616, train_loss: 0.08984891, train_accuracy: 0.9766, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  372/  468] time: 107.7889, train_loss: 0.08675756, train_accuracy: 0.9688, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  373/  468] time: 107.9730, train_loss: 0.11824168, train_accuracy: 0.9609, test_Accuracy: 0.9576\n",
            "Epoch: [ 0] [  374/  468] time: 108.1916, train_loss: 0.16947925, train_accuracy: 0.9375, test_Accuracy: 0.9576\n",
            "Epoch: [ 0] [  375/  468] time: 108.5227, train_loss: 0.11162850, train_accuracy: 0.9688, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  376/  468] time: 108.7206, train_loss: 0.08441907, train_accuracy: 0.9844, test_Accuracy: 0.9579\n",
            "Epoch: [ 0] [  377/  468] time: 108.9146, train_loss: 0.06223593, train_accuracy: 0.9844, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  378/  468] time: 109.1097, train_loss: 0.12699218, train_accuracy: 0.9297, test_Accuracy: 0.9572\n",
            "Epoch: [ 0] [  379/  468] time: 109.4477, train_loss: 0.21235722, train_accuracy: 0.9453, test_Accuracy: 0.9565\n",
            "Epoch: [ 0] [  380/  468] time: 109.6522, train_loss: 0.14003265, train_accuracy: 0.9688, test_Accuracy: 0.9552\n",
            "Epoch: [ 0] [  381/  468] time: 109.8553, train_loss: 0.16392662, train_accuracy: 0.9531, test_Accuracy: 0.9533\n",
            "Epoch: [ 0] [  382/  468] time: 110.0437, train_loss: 0.15155824, train_accuracy: 0.9453, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  383/  468] time: 110.3050, train_loss: 0.14293793, train_accuracy: 0.9531, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  384/  468] time: 110.6365, train_loss: 0.21898666, train_accuracy: 0.9531, test_Accuracy: 0.9557\n",
            "Epoch: [ 0] [  385/  468] time: 110.9222, train_loss: 0.16500571, train_accuracy: 0.9531, test_Accuracy: 0.9572\n",
            "Epoch: [ 0] [  386/  468] time: 111.2572, train_loss: 0.12703793, train_accuracy: 0.9609, test_Accuracy: 0.9584\n",
            "Epoch: [ 0] [  387/  468] time: 111.9266, train_loss: 0.08513321, train_accuracy: 0.9766, test_Accuracy: 0.9578\n",
            "Epoch: [ 0] [  388/  468] time: 112.6441, train_loss: 0.14333375, train_accuracy: 0.9688, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  389/  468] time: 113.5098, train_loss: 0.13098936, train_accuracy: 0.9688, test_Accuracy: 0.9569\n",
            "Epoch: [ 0] [  390/  468] time: 113.9074, train_loss: 0.05592494, train_accuracy: 0.9922, test_Accuracy: 0.9562\n",
            "Epoch: [ 0] [  391/  468] time: 114.2949, train_loss: 0.14945990, train_accuracy: 0.9609, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  392/  468] time: 114.6707, train_loss: 0.16767186, train_accuracy: 0.9453, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  393/  468] time: 114.9107, train_loss: 0.16927999, train_accuracy: 0.9297, test_Accuracy: 0.9561\n",
            "Epoch: [ 0] [  394/  468] time: 115.2468, train_loss: 0.14616245, train_accuracy: 0.9766, test_Accuracy: 0.9566\n",
            "Epoch: [ 0] [  395/  468] time: 115.5796, train_loss: 0.21051604, train_accuracy: 0.9297, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  396/  468] time: 115.8707, train_loss: 0.10426143, train_accuracy: 0.9688, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  397/  468] time: 116.2009, train_loss: 0.09915860, train_accuracy: 0.9766, test_Accuracy: 0.9555\n",
            "Epoch: [ 0] [  398/  468] time: 116.5624, train_loss: 0.20591182, train_accuracy: 0.9297, test_Accuracy: 0.9546\n",
            "Epoch: [ 0] [  399/  468] time: 116.9163, train_loss: 0.21146044, train_accuracy: 0.9297, test_Accuracy: 0.9544\n",
            "Epoch: [ 0] [  400/  468] time: 117.2489, train_loss: 0.09677917, train_accuracy: 0.9688, test_Accuracy: 0.9547\n",
            "Epoch: [ 0] [  401/  468] time: 117.5907, train_loss: 0.25241581, train_accuracy: 0.9297, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  402/  468] time: 117.8147, train_loss: 0.26580504, train_accuracy: 0.9375, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  403/  468] time: 118.0649, train_loss: 0.22629499, train_accuracy: 0.9297, test_Accuracy: 0.9535\n",
            "Epoch: [ 0] [  404/  468] time: 118.3762, train_loss: 0.17389780, train_accuracy: 0.9531, test_Accuracy: 0.9538\n",
            "Epoch: [ 0] [  405/  468] time: 118.7070, train_loss: 0.10530989, train_accuracy: 0.9688, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  406/  468] time: 118.9009, train_loss: 0.12075584, train_accuracy: 0.9609, test_Accuracy: 0.9536\n",
            "Epoch: [ 0] [  407/  468] time: 119.2108, train_loss: 0.10131168, train_accuracy: 0.9609, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  408/  468] time: 119.5436, train_loss: 0.13219814, train_accuracy: 0.9609, test_Accuracy: 0.9537\n",
            "Epoch: [ 0] [  409/  468] time: 119.8217, train_loss: 0.10982807, train_accuracy: 0.9766, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  410/  468] time: 120.0446, train_loss: 0.12548244, train_accuracy: 0.9766, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  411/  468] time: 120.2585, train_loss: 0.11760341, train_accuracy: 0.9688, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  412/  468] time: 120.5036, train_loss: 0.16774336, train_accuracy: 0.9688, test_Accuracy: 0.9522\n",
            "Epoch: [ 0] [  413/  468] time: 120.8356, train_loss: 0.12898791, train_accuracy: 0.9609, test_Accuracy: 0.9552\n",
            "Epoch: [ 0] [  414/  468] time: 121.1870, train_loss: 0.09859882, train_accuracy: 0.9844, test_Accuracy: 0.9571\n",
            "Epoch: [ 0] [  415/  468] time: 121.5050, train_loss: 0.10051665, train_accuracy: 0.9766, test_Accuracy: 0.9571\n",
            "Epoch: [ 0] [  416/  468] time: 121.8527, train_loss: 0.15029611, train_accuracy: 0.9688, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  417/  468] time: 122.1828, train_loss: 0.09753358, train_accuracy: 0.9531, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  418/  468] time: 122.5158, train_loss: 0.10529676, train_accuracy: 0.9609, test_Accuracy: 0.9566\n",
            "Epoch: [ 0] [  419/  468] time: 122.7169, train_loss: 0.16211534, train_accuracy: 0.9453, test_Accuracy: 0.9551\n",
            "Epoch: [ 0] [  420/  468] time: 122.9158, train_loss: 0.14263792, train_accuracy: 0.9531, test_Accuracy: 0.9551\n",
            "Epoch: [ 0] [  421/  468] time: 123.1123, train_loss: 0.06785464, train_accuracy: 0.9922, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  422/  468] time: 123.3331, train_loss: 0.08062680, train_accuracy: 0.9844, test_Accuracy: 0.9560\n",
            "Epoch: [ 0] [  423/  468] time: 123.5269, train_loss: 0.10270671, train_accuracy: 0.9688, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  424/  468] time: 123.8606, train_loss: 0.07258788, train_accuracy: 0.9844, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  425/  468] time: 124.1961, train_loss: 0.17017095, train_accuracy: 0.9297, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  426/  468] time: 124.3971, train_loss: 0.13493808, train_accuracy: 0.9531, test_Accuracy: 0.9604\n",
            "Epoch: [ 0] [  427/  468] time: 124.6022, train_loss: 0.13951913, train_accuracy: 0.9375, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  428/  468] time: 124.8022, train_loss: 0.07859135, train_accuracy: 0.9766, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  429/  468] time: 125.1358, train_loss: 0.13173674, train_accuracy: 0.9766, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  430/  468] time: 125.4005, train_loss: 0.12582082, train_accuracy: 0.9609, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  431/  468] time: 125.7337, train_loss: 0.09755240, train_accuracy: 0.9609, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  432/  468] time: 125.9267, train_loss: 0.10009106, train_accuracy: 0.9688, test_Accuracy: 0.9621\n",
            "Epoch: [ 0] [  433/  468] time: 126.1963, train_loss: 0.10180815, train_accuracy: 0.9609, test_Accuracy: 0.9617\n",
            "Epoch: [ 0] [  434/  468] time: 126.5389, train_loss: 0.08635022, train_accuracy: 0.9922, test_Accuracy: 0.9608\n",
            "Epoch: [ 0] [  435/  468] time: 126.8947, train_loss: 0.18648945, train_accuracy: 0.9453, test_Accuracy: 0.9598\n",
            "Epoch: [ 0] [  436/  468] time: 127.1451, train_loss: 0.09624349, train_accuracy: 0.9609, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  437/  468] time: 127.4834, train_loss: 0.07964236, train_accuracy: 0.9844, test_Accuracy: 0.9578\n",
            "Epoch: [ 0] [  438/  468] time: 127.8136, train_loss: 0.14239298, train_accuracy: 0.9453, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  439/  468] time: 128.1471, train_loss: 0.14505890, train_accuracy: 0.9453, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  440/  468] time: 128.5046, train_loss: 0.07829091, train_accuracy: 0.9844, test_Accuracy: 0.9599\n",
            "Epoch: [ 0] [  441/  468] time: 128.8786, train_loss: 0.06227360, train_accuracy: 0.9844, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  442/  468] time: 129.1948, train_loss: 0.17387387, train_accuracy: 0.9609, test_Accuracy: 0.9592\n",
            "Epoch: [ 0] [  443/  468] time: 129.4179, train_loss: 0.11909817, train_accuracy: 0.9688, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  444/  468] time: 129.6507, train_loss: 0.15146339, train_accuracy: 0.9766, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  445/  468] time: 129.9821, train_loss: 0.10532054, train_accuracy: 0.9766, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  446/  468] time: 130.2914, train_loss: 0.18908104, train_accuracy: 0.9453, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  447/  468] time: 130.5298, train_loss: 0.17974320, train_accuracy: 0.9453, test_Accuracy: 0.9625\n",
            "Epoch: [ 0] [  448/  468] time: 130.8394, train_loss: 0.12936300, train_accuracy: 0.9531, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  449/  468] time: 131.1729, train_loss: 0.13346219, train_accuracy: 0.9609, test_Accuracy: 0.9623\n",
            "Epoch: [ 0] [  450/  468] time: 131.7187, train_loss: 0.04131486, train_accuracy: 0.9922, test_Accuracy: 0.9602\n",
            "Epoch: [ 0] [  451/  468] time: 132.0529, train_loss: 0.10140900, train_accuracy: 0.9766, test_Accuracy: 0.9581\n",
            "Epoch: [ 0] [  452/  468] time: 132.4104, train_loss: 0.16600570, train_accuracy: 0.9609, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  453/  468] time: 132.6255, train_loss: 0.09114559, train_accuracy: 0.9688, test_Accuracy: 0.9567\n",
            "Epoch: [ 0] [  454/  468] time: 132.8454, train_loss: 0.28125036, train_accuracy: 0.9219, test_Accuracy: 0.9581\n",
            "Epoch: [ 0] [  455/  468] time: 133.1789, train_loss: 0.10092427, train_accuracy: 0.9609, test_Accuracy: 0.9597\n",
            "Epoch: [ 0] [  456/  468] time: 133.5334, train_loss: 0.10713419, train_accuracy: 0.9844, test_Accuracy: 0.9618\n",
            "Epoch: [ 0] [  457/  468] time: 133.8839, train_loss: 0.19211678, train_accuracy: 0.9531, test_Accuracy: 0.9622\n",
            "Epoch: [ 0] [  458/  468] time: 134.2176, train_loss: 0.22064435, train_accuracy: 0.9531, test_Accuracy: 0.9622\n",
            "Epoch: [ 0] [  459/  468] time: 134.5726, train_loss: 0.19773914, train_accuracy: 0.9375, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  460/  468] time: 134.8735, train_loss: 0.13598005, train_accuracy: 0.9453, test_Accuracy: 0.9599\n",
            "Epoch: [ 0] [  461/  468] time: 135.2035, train_loss: 0.15263014, train_accuracy: 0.9453, test_Accuracy: 0.9590\n",
            "Epoch: [ 0] [  462/  468] time: 135.4071, train_loss: 0.18002495, train_accuracy: 0.9531, test_Accuracy: 0.9590\n",
            "Epoch: [ 0] [  463/  468] time: 135.7466, train_loss: 0.11346216, train_accuracy: 0.9688, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  464/  468] time: 135.9493, train_loss: 0.08971701, train_accuracy: 0.9609, test_Accuracy: 0.9597\n",
            "Epoch: [ 0] [  465/  468] time: 136.1483, train_loss: 0.20591852, train_accuracy: 0.9219, test_Accuracy: 0.9601\n",
            "Epoch: [ 0] [  466/  468] time: 136.3478, train_loss: 0.23750898, train_accuracy: 0.9297, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  467/  468] time: 136.6801, train_loss: 0.12715048, train_accuracy: 0.9531, test_Accuracy: 0.9621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# weight Initialization"
      ],
      "metadata": {
        "id": "Vj4a4JOjOSky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xavier Initialization (Glorot Initialization)\n",
        "- 우리의 네트워크는 loss가 가장 최저인 지점을 찾아내는 것이 목표 \n",
        "- loss 그래프가 복잡할 때 시작점을 잘못 잡으면 local minima에 빠질 수 있고, saddle posint에 도달 할 수도 있음\n",
        "- weight 초기화는 어디서부터 출발할 지 설정해 주는것\n",
        "- Xavier의 평균은 0\n",
        "- Variance\n",
        "$$ \\frac{2}{channel\\_in+channel\\_out} $$\n",
        "\n",
        "## He Initialization\n",
        "- He Initialization은 Relu 함수에 특화된 Initialization 방법\n",
        "  - 평균 0\n",
        "  - variance\n",
        "  $$ \\frac{4}{channel\\_in+channel\\_out} $$"
      ],
      "metadata": {
        "id": "zXI6XoKSOWP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import\n"
      ],
      "metadata": {
        "id": "Zl2pDt7IQONo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from time import time\n",
        "import os\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjrMCF0qQU6Y",
        "outputId": "2d57b893-4ecc-4d94-d67d-dd09424b4888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint function"
      ],
      "metadata": {
        "id": "A-fZM1nPQj1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(model, checkpoint_dir):\n",
        "    print(\" [*] Reading checkpoints...\")\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "    if ckpt :\n",
        "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "        checkpoint = tf.train.Checkpoint(dnn=model)\n",
        "        checkpoint.restore(save_path=os.path.join(checkpoint_dir, ckpt_name))\n",
        "        counter = int(ckpt_name.split('-')[1])\n",
        "        print(\" [*] Success to read {}\".format(ckpt_name))\n",
        "        return True, counter\n",
        "    else:\n",
        "        print(\" [*] Failed to find a checkpoint\")\n",
        "        return False, 0\n",
        "\n",
        "def check_folder(dir):\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "    return dir"
      ],
      "metadata": {
        "id": "_2dbFZe3Qlx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load mnist"
      ],
      "metadata": {
        "id": "FI3g1Q70Qguk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist() :\n",
        "    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "    train_data = np.expand_dims(train_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n",
        "    test_data = np.expand_dims(test_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n",
        "\n",
        "    train_data, test_data = normalize(train_data, test_data)\n",
        "\n",
        "    train_labels = to_categorical(train_labels, 10) # [N,] -> [N, 10]\n",
        "    test_labels = to_categorical(test_labels, 10) # [N,] -> [N, 10]\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "def normalize(train_data, test_data):\n",
        "    train_data = train_data.astype(np.float32) / 255.0\n",
        "    test_data = test_data.astype(np.float32) / 255.0\n",
        "\n",
        "    return train_data, test_data"
      ],
      "metadata": {
        "id": "25vummlKQi4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance function"
      ],
      "metadata": {
        "id": "FbD1hNmdQnew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, \n",
        "                                                                   from_logits=True))\n",
        "    return loss\n",
        "\n",
        "def accuracy_fn(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
        "    return accuracy\n",
        "\n",
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ],
      "metadata": {
        "id": "C0TQzGMoQpnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create network"
      ],
      "metadata": {
        "id": "UoU7__fOQqVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten() :\n",
        "    return tf.keras.layers.Flatten()\n",
        "\n",
        "def dense(label_dim, weight_init) :\n",
        "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
        "\n",
        "def relu() :\n",
        "    return tf.keras.layers.Activation(tf.keras.activations.relu)"
      ],
      "metadata": {
        "id": "HDXPzlKyQsFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model - class"
      ],
      "metadata": {
        "id": "wSKAAMRYQuEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class create_model_class(tf.keras.Model):\n",
        "    def __init__(self, label_dim):\n",
        "        super(create_model_class, self).__init__()\n",
        "        # or tf.keras.initializers.he_uniform()\n",
        "        weight_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(flatten())\n",
        "\n",
        "        for i in range(2):\n",
        "            self.model.add(dense(256, weight_init))\n",
        "            self.model.add(relu())\n",
        "\n",
        "        self.model.add(dense(label_dim, weight_init))\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ojRkuu-CQv4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model - function"
      ],
      "metadata": {
        "id": "j7tFmG9zQxYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_function(label_dim) :\n",
        "   # or tf.keras.initializers.he_uniform()\n",
        "    weight_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(flatten())\n",
        "\n",
        "    for i in range(2) :\n",
        "        model.add(dense(256, weight_init))\n",
        "        model.add(relu())\n",
        "\n",
        "    model.add(dense(label_dim, weight_init))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KNk5F4WAQ1S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define data & hyper-parameter"
      ],
      "metadata": {
        "id": "7XIw0qmpQ2Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" dataset \"\"\"\n",
        "train_x, train_y, test_x, test_y = load_mnist()\n",
        "\n",
        "\"\"\" parameters \"\"\"\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "\n",
        "training_epochs = 1\n",
        "training_iterations = len(train_x) // batch_size\n",
        "\n",
        "label_dim = 10\n",
        "\n",
        "train_flag = True\n",
        "\n",
        "\"\"\" Graph Input using Dataset API \"\"\"\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
        "    shuffle(buffer_size=100000).\\\n",
        "    prefetch(buffer_size=batch_size).\\\n",
        "    batch(batch_size, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
        "    shuffle(buffer_size=100000).\\\n",
        "    prefetch(buffer_size=len(test_x)).\\\n",
        "    batch(len(test_x))"
      ],
      "metadata": {
        "id": "YiRxMWPoQ5bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model & optimizer & writer"
      ],
      "metadata": {
        "id": "0YDGpdglQ68x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Model \"\"\"\n",
        "network = create_model_function(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "\"\"\" Writer \"\"\"\n",
        "checkpoint_dir = 'checkpoints'\n",
        "logs_dir = 'logs'\n",
        "\n",
        "model_dir = 'nn_xavier'\n",
        "\n",
        "checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "check_folder(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n",
        "logs_dir = os.path.join(logs_dir, model_dir)"
      ],
      "metadata": {
        "id": "HsCp3IxNQ-Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restore checkpoint & start train or test phase"
      ],
      "metadata": {
        "id": "n14PKnrAQ-1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if train_flag :\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(dnn=network)\n",
        "\n",
        "    # create writer for tensorboard\n",
        "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
        "    start_time = time()\n",
        "\n",
        "    # restore check-point if it exits\n",
        "    could_load, checkpoint_counter = load(network, checkpoint_dir)    \n",
        "\n",
        "    if could_load:\n",
        "        start_epoch = (int)(checkpoint_counter / training_iterations)        \n",
        "        counter = checkpoint_counter        \n",
        "        print(\" [*] Load SUCCESS\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        start_iteration = 0\n",
        "        counter = 0\n",
        "        print(\" [!] Load failed...\")\n",
        "    \n",
        "    # train phase\n",
        "    with summary_writer.as_default():  # for tensorboard\n",
        "        for epoch in range(start_epoch, training_epochs):\n",
        "            for idx, (train_input, train_label) in enumerate(train_dataset):                \n",
        "                grads = grad(network, train_input, train_label)\n",
        "                optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
        "\n",
        "                train_loss = loss_fn(network, train_input, train_label)\n",
        "                train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "\n",
        "                for test_input, test_label in test_dataset:                \n",
        "                    test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n",
        "                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n",
        "                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n",
        "\n",
        "                print(\n",
        "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
        "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
        "                       test_accuracy))\n",
        "                counter += 1\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
        "        \n",
        "# test phase      \n",
        "else :\n",
        "    _, _ = load(network, checkpoint_dir)\n",
        "    for test_input, test_label in test_dataset:    \n",
        "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6vhMAriRCcQ",
        "outputId": "833276a9-12d4-446e-be28-dfa8d50b22ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Reading checkpoints...\n",
            " [*] Failed to find a checkpoint\n",
            " [!] Load failed...\n",
            "Epoch: [ 0] [    0/  468] time: 0.5183, train_loss: 2.02894783, train_accuracy: 0.3359, test_Accuracy: 0.1907\n",
            "Epoch: [ 0] [    1/  468] time: 0.7132, train_loss: 1.96024799, train_accuracy: 0.4375, test_Accuracy: 0.3670\n",
            "Epoch: [ 0] [    2/  468] time: 1.0506, train_loss: 1.85483813, train_accuracy: 0.5391, test_Accuracy: 0.5061\n",
            "Epoch: [ 0] [    3/  468] time: 1.7360, train_loss: 1.79507709, train_accuracy: 0.5703, test_Accuracy: 0.6344\n",
            "Epoch: [ 0] [    4/  468] time: 2.4237, train_loss: 1.70726573, train_accuracy: 0.7109, test_Accuracy: 0.7043\n",
            "Epoch: [ 0] [    5/  468] time: 3.1785, train_loss: 1.50102746, train_accuracy: 0.7188, test_Accuracy: 0.7366\n",
            "Epoch: [ 0] [    6/  468] time: 3.5981, train_loss: 1.35314465, train_accuracy: 0.7422, test_Accuracy: 0.7435\n",
            "Epoch: [ 0] [    7/  468] time: 4.1011, train_loss: 1.20339775, train_accuracy: 0.7656, test_Accuracy: 0.7501\n",
            "Epoch: [ 0] [    8/  468] time: 4.3701, train_loss: 1.11862385, train_accuracy: 0.7578, test_Accuracy: 0.7638\n",
            "Epoch: [ 0] [    9/  468] time: 4.5573, train_loss: 1.06407773, train_accuracy: 0.8125, test_Accuracy: 0.7733\n",
            "Epoch: [ 0] [   10/  468] time: 4.7690, train_loss: 0.93510801, train_accuracy: 0.7812, test_Accuracy: 0.7852\n",
            "Epoch: [ 0] [   11/  468] time: 4.9589, train_loss: 0.87422895, train_accuracy: 0.8438, test_Accuracy: 0.8031\n",
            "Epoch: [ 0] [   12/  468] time: 5.1675, train_loss: 0.78678435, train_accuracy: 0.8047, test_Accuracy: 0.8109\n",
            "Epoch: [ 0] [   13/  468] time: 5.5015, train_loss: 0.77153957, train_accuracy: 0.7891, test_Accuracy: 0.8168\n",
            "Epoch: [ 0] [   14/  468] time: 5.6992, train_loss: 0.64436030, train_accuracy: 0.8516, test_Accuracy: 0.8156\n",
            "Epoch: [ 0] [   15/  468] time: 5.9027, train_loss: 0.56464672, train_accuracy: 0.8594, test_Accuracy: 0.8310\n",
            "Epoch: [ 0] [   16/  468] time: 6.0937, train_loss: 0.57396823, train_accuracy: 0.8672, test_Accuracy: 0.8455\n",
            "Epoch: [ 0] [   17/  468] time: 6.2977, train_loss: 0.58742869, train_accuracy: 0.8125, test_Accuracy: 0.8454\n",
            "Epoch: [ 0] [   18/  468] time: 6.6282, train_loss: 0.67060983, train_accuracy: 0.8359, test_Accuracy: 0.8426\n",
            "Epoch: [ 0] [   19/  468] time: 6.8534, train_loss: 0.47917974, train_accuracy: 0.8594, test_Accuracy: 0.8422\n",
            "Epoch: [ 0] [   20/  468] time: 7.0511, train_loss: 0.52505755, train_accuracy: 0.8281, test_Accuracy: 0.8459\n",
            "Epoch: [ 0] [   21/  468] time: 7.2387, train_loss: 0.47907692, train_accuracy: 0.8750, test_Accuracy: 0.8535\n",
            "Epoch: [ 0] [   22/  468] time: 7.5687, train_loss: 0.50563002, train_accuracy: 0.8438, test_Accuracy: 0.8633\n",
            "Epoch: [ 0] [   23/  468] time: 7.9010, train_loss: 0.48150703, train_accuracy: 0.8672, test_Accuracy: 0.8706\n",
            "Epoch: [ 0] [   24/  468] time: 8.1042, train_loss: 0.29548243, train_accuracy: 0.9297, test_Accuracy: 0.8727\n",
            "Epoch: [ 0] [   25/  468] time: 8.3135, train_loss: 0.31226435, train_accuracy: 0.9453, test_Accuracy: 0.8680\n",
            "Epoch: [ 0] [   26/  468] time: 8.5099, train_loss: 0.36739451, train_accuracy: 0.9062, test_Accuracy: 0.8611\n",
            "Epoch: [ 0] [   27/  468] time: 8.8453, train_loss: 0.52406347, train_accuracy: 0.8281, test_Accuracy: 0.8650\n",
            "Epoch: [ 0] [   28/  468] time: 9.0381, train_loss: 0.26557395, train_accuracy: 0.9141, test_Accuracy: 0.8629\n",
            "Epoch: [ 0] [   29/  468] time: 9.2473, train_loss: 0.61767632, train_accuracy: 0.8125, test_Accuracy: 0.8675\n",
            "Epoch: [ 0] [   30/  468] time: 9.5796, train_loss: 0.37206292, train_accuracy: 0.8672, test_Accuracy: 0.8617\n",
            "Epoch: [ 0] [   31/  468] time: 9.7653, train_loss: 0.33184776, train_accuracy: 0.8750, test_Accuracy: 0.8580\n",
            "Epoch: [ 0] [   32/  468] time: 9.9664, train_loss: 0.55820566, train_accuracy: 0.8750, test_Accuracy: 0.8669\n",
            "Epoch: [ 0] [   33/  468] time: 10.1708, train_loss: 0.42971575, train_accuracy: 0.8672, test_Accuracy: 0.8794\n",
            "Epoch: [ 0] [   34/  468] time: 10.3666, train_loss: 0.36162740, train_accuracy: 0.9062, test_Accuracy: 0.8813\n",
            "Epoch: [ 0] [   35/  468] time: 10.5699, train_loss: 0.31885386, train_accuracy: 0.8906, test_Accuracy: 0.8809\n",
            "Epoch: [ 0] [   36/  468] time: 10.7664, train_loss: 0.32726073, train_accuracy: 0.8906, test_Accuracy: 0.8746\n",
            "Epoch: [ 0] [   37/  468] time: 10.9720, train_loss: 0.42694318, train_accuracy: 0.8672, test_Accuracy: 0.8758\n",
            "Epoch: [ 0] [   38/  468] time: 11.1678, train_loss: 0.47569463, train_accuracy: 0.8281, test_Accuracy: 0.8844\n",
            "Epoch: [ 0] [   39/  468] time: 11.3733, train_loss: 0.30909905, train_accuracy: 0.8750, test_Accuracy: 0.8937\n",
            "Epoch: [ 0] [   40/  468] time: 11.5844, train_loss: 0.38409239, train_accuracy: 0.8594, test_Accuracy: 0.8947\n",
            "Epoch: [ 0] [   41/  468] time: 11.7961, train_loss: 0.31855881, train_accuracy: 0.9297, test_Accuracy: 0.8910\n",
            "Epoch: [ 0] [   42/  468] time: 11.9918, train_loss: 0.45382759, train_accuracy: 0.8672, test_Accuracy: 0.8893\n",
            "Epoch: [ 0] [   43/  468] time: 12.1989, train_loss: 0.27529904, train_accuracy: 0.9062, test_Accuracy: 0.8871\n",
            "Epoch: [ 0] [   44/  468] time: 12.3992, train_loss: 0.40545452, train_accuracy: 0.8672, test_Accuracy: 0.8891\n",
            "Epoch: [ 0] [   45/  468] time: 12.7353, train_loss: 0.29027569, train_accuracy: 0.9141, test_Accuracy: 0.8942\n",
            "Epoch: [ 0] [   46/  468] time: 12.9308, train_loss: 0.38848245, train_accuracy: 0.9141, test_Accuracy: 0.8997\n",
            "Epoch: [ 0] [   47/  468] time: 13.1280, train_loss: 0.49051404, train_accuracy: 0.8516, test_Accuracy: 0.9023\n",
            "Epoch: [ 0] [   48/  468] time: 13.4603, train_loss: 0.38348043, train_accuracy: 0.8984, test_Accuracy: 0.9046\n",
            "Epoch: [ 0] [   49/  468] time: 13.6505, train_loss: 0.35753137, train_accuracy: 0.8984, test_Accuracy: 0.9057\n",
            "Epoch: [ 0] [   50/  468] time: 13.8604, train_loss: 0.31233892, train_accuracy: 0.9062, test_Accuracy: 0.9045\n",
            "Epoch: [ 0] [   51/  468] time: 14.0582, train_loss: 0.35814992, train_accuracy: 0.8906, test_Accuracy: 0.9033\n",
            "Epoch: [ 0] [   52/  468] time: 14.2683, train_loss: 0.30525553, train_accuracy: 0.8906, test_Accuracy: 0.9026\n",
            "Epoch: [ 0] [   53/  468] time: 14.4738, train_loss: 0.24932389, train_accuracy: 0.9141, test_Accuracy: 0.9054\n",
            "Epoch: [ 0] [   54/  468] time: 14.6741, train_loss: 0.40418535, train_accuracy: 0.8828, test_Accuracy: 0.9058\n",
            "Epoch: [ 0] [   55/  468] time: 14.8716, train_loss: 0.34512103, train_accuracy: 0.9141, test_Accuracy: 0.9043\n",
            "Epoch: [ 0] [   56/  468] time: 15.0838, train_loss: 0.39322689, train_accuracy: 0.8828, test_Accuracy: 0.9021\n",
            "Epoch: [ 0] [   57/  468] time: 15.2821, train_loss: 0.28868544, train_accuracy: 0.9062, test_Accuracy: 0.9010\n",
            "Epoch: [ 0] [   58/  468] time: 15.6156, train_loss: 0.28143996, train_accuracy: 0.8984, test_Accuracy: 0.9005\n",
            "Epoch: [ 0] [   59/  468] time: 15.8267, train_loss: 0.38389802, train_accuracy: 0.8516, test_Accuracy: 0.9056\n",
            "Epoch: [ 0] [   60/  468] time: 16.0406, train_loss: 0.31794769, train_accuracy: 0.9297, test_Accuracy: 0.9064\n",
            "Epoch: [ 0] [   61/  468] time: 16.3751, train_loss: 0.36338243, train_accuracy: 0.8906, test_Accuracy: 0.9075\n",
            "Epoch: [ 0] [   62/  468] time: 16.7064, train_loss: 0.26834592, train_accuracy: 0.9219, test_Accuracy: 0.9049\n",
            "Epoch: [ 0] [   63/  468] time: 16.9334, train_loss: 0.45011705, train_accuracy: 0.8750, test_Accuracy: 0.9003\n",
            "Epoch: [ 0] [   64/  468] time: 17.1286, train_loss: 0.26939982, train_accuracy: 0.9219, test_Accuracy: 0.8954\n",
            "Epoch: [ 0] [   65/  468] time: 17.3298, train_loss: 0.26887986, train_accuracy: 0.9141, test_Accuracy: 0.8984\n",
            "Epoch: [ 0] [   66/  468] time: 17.5209, train_loss: 0.33326754, train_accuracy: 0.9062, test_Accuracy: 0.9099\n",
            "Epoch: [ 0] [   67/  468] time: 17.7190, train_loss: 0.20506772, train_accuracy: 0.9453, test_Accuracy: 0.9169\n",
            "Epoch: [ 0] [   68/  468] time: 17.9109, train_loss: 0.21299453, train_accuracy: 0.9219, test_Accuracy: 0.9159\n",
            "Epoch: [ 0] [   69/  468] time: 18.2464, train_loss: 0.47112525, train_accuracy: 0.8672, test_Accuracy: 0.9136\n",
            "Epoch: [ 0] [   70/  468] time: 18.4736, train_loss: 0.12211984, train_accuracy: 0.9766, test_Accuracy: 0.9114\n",
            "Epoch: [ 0] [   71/  468] time: 18.8072, train_loss: 0.34254795, train_accuracy: 0.8984, test_Accuracy: 0.9088\n",
            "Epoch: [ 0] [   72/  468] time: 19.0153, train_loss: 0.23970860, train_accuracy: 0.9453, test_Accuracy: 0.9081\n",
            "Epoch: [ 0] [   73/  468] time: 19.2252, train_loss: 0.19603984, train_accuracy: 0.9375, test_Accuracy: 0.9089\n",
            "Epoch: [ 0] [   74/  468] time: 19.4313, train_loss: 0.43925741, train_accuracy: 0.8516, test_Accuracy: 0.9086\n",
            "Epoch: [ 0] [   75/  468] time: 19.6287, train_loss: 0.18768778, train_accuracy: 0.9453, test_Accuracy: 0.9061\n",
            "Epoch: [ 0] [   76/  468] time: 19.8454, train_loss: 0.32860062, train_accuracy: 0.9141, test_Accuracy: 0.9036\n",
            "Epoch: [ 0] [   77/  468] time: 20.0468, train_loss: 0.30832070, train_accuracy: 0.9062, test_Accuracy: 0.9026\n",
            "Epoch: [ 0] [   78/  468] time: 20.2395, train_loss: 0.24179250, train_accuracy: 0.9375, test_Accuracy: 0.9043\n",
            "Epoch: [ 0] [   79/  468] time: 20.4273, train_loss: 0.28706118, train_accuracy: 0.9141, test_Accuracy: 0.9053\n",
            "Epoch: [ 0] [   80/  468] time: 20.6284, train_loss: 0.27311751, train_accuracy: 0.9297, test_Accuracy: 0.9065\n",
            "Epoch: [ 0] [   81/  468] time: 20.9624, train_loss: 0.23131879, train_accuracy: 0.9297, test_Accuracy: 0.9124\n",
            "Epoch: [ 0] [   82/  468] time: 21.1591, train_loss: 0.27662730, train_accuracy: 0.9219, test_Accuracy: 0.9151\n",
            "Epoch: [ 0] [   83/  468] time: 21.3723, train_loss: 0.34180927, train_accuracy: 0.9062, test_Accuracy: 0.9163\n",
            "Epoch: [ 0] [   84/  468] time: 21.5817, train_loss: 0.24359344, train_accuracy: 0.9375, test_Accuracy: 0.9160\n",
            "Epoch: [ 0] [   85/  468] time: 21.9127, train_loss: 0.44413656, train_accuracy: 0.8438, test_Accuracy: 0.9166\n",
            "Epoch: [ 0] [   86/  468] time: 22.2439, train_loss: 0.25177342, train_accuracy: 0.9062, test_Accuracy: 0.9154\n",
            "Epoch: [ 0] [   87/  468] time: 22.4416, train_loss: 0.27352324, train_accuracy: 0.9297, test_Accuracy: 0.9185\n",
            "Epoch: [ 0] [   88/  468] time: 22.6461, train_loss: 0.34655696, train_accuracy: 0.9141, test_Accuracy: 0.9220\n",
            "Epoch: [ 0] [   89/  468] time: 22.8383, train_loss: 0.23107016, train_accuracy: 0.9375, test_Accuracy: 0.9228\n",
            "Epoch: [ 0] [   90/  468] time: 23.1812, train_loss: 0.29298729, train_accuracy: 0.9453, test_Accuracy: 0.9211\n",
            "Epoch: [ 0] [   91/  468] time: 23.3735, train_loss: 0.32390314, train_accuracy: 0.9141, test_Accuracy: 0.9192\n",
            "Epoch: [ 0] [   92/  468] time: 23.5808, train_loss: 0.25922710, train_accuracy: 0.8906, test_Accuracy: 0.9164\n",
            "Epoch: [ 0] [   93/  468] time: 23.7836, train_loss: 0.34977072, train_accuracy: 0.8672, test_Accuracy: 0.9166\n",
            "Epoch: [ 0] [   94/  468] time: 24.1171, train_loss: 0.32559156, train_accuracy: 0.8984, test_Accuracy: 0.9204\n",
            "Epoch: [ 0] [   95/  468] time: 24.4478, train_loss: 0.37246796, train_accuracy: 0.9141, test_Accuracy: 0.9246\n",
            "Epoch: [ 0] [   96/  468] time: 24.7826, train_loss: 0.24360724, train_accuracy: 0.9219, test_Accuracy: 0.9245\n",
            "Epoch: [ 0] [   97/  468] time: 24.9898, train_loss: 0.15453677, train_accuracy: 0.9609, test_Accuracy: 0.9196\n",
            "Epoch: [ 0] [   98/  468] time: 25.2004, train_loss: 0.28867206, train_accuracy: 0.9062, test_Accuracy: 0.9109\n",
            "Epoch: [ 0] [   99/  468] time: 25.5317, train_loss: 0.23905860, train_accuracy: 0.9219, test_Accuracy: 0.9108\n",
            "Epoch: [ 0] [  100/  468] time: 25.7298, train_loss: 0.20567015, train_accuracy: 0.9375, test_Accuracy: 0.9200\n",
            "Epoch: [ 0] [  101/  468] time: 26.0693, train_loss: 0.20663495, train_accuracy: 0.9453, test_Accuracy: 0.9271\n",
            "Epoch: [ 0] [  102/  468] time: 26.2816, train_loss: 0.25348017, train_accuracy: 0.9141, test_Accuracy: 0.9269\n",
            "Epoch: [ 0] [  103/  468] time: 26.4949, train_loss: 0.33875784, train_accuracy: 0.8906, test_Accuracy: 0.9222\n",
            "Epoch: [ 0] [  104/  468] time: 26.8305, train_loss: 0.17855501, train_accuracy: 0.9453, test_Accuracy: 0.9163\n",
            "Epoch: [ 0] [  105/  468] time: 27.1675, train_loss: 0.34791657, train_accuracy: 0.9141, test_Accuracy: 0.9129\n",
            "Epoch: [ 0] [  106/  468] time: 27.3709, train_loss: 0.39655226, train_accuracy: 0.8828, test_Accuracy: 0.9156\n",
            "Epoch: [ 0] [  107/  468] time: 27.7042, train_loss: 0.31917897, train_accuracy: 0.9141, test_Accuracy: 0.9212\n",
            "Epoch: [ 0] [  108/  468] time: 27.9132, train_loss: 0.20417076, train_accuracy: 0.9375, test_Accuracy: 0.9270\n",
            "Epoch: [ 0] [  109/  468] time: 28.2443, train_loss: 0.11637999, train_accuracy: 0.9609, test_Accuracy: 0.9287\n",
            "Epoch: [ 0] [  110/  468] time: 28.4453, train_loss: 0.21016456, train_accuracy: 0.9531, test_Accuracy: 0.9283\n",
            "Epoch: [ 0] [  111/  468] time: 28.6444, train_loss: 0.20754376, train_accuracy: 0.9453, test_Accuracy: 0.9231\n",
            "Epoch: [ 0] [  112/  468] time: 28.9788, train_loss: 0.35768479, train_accuracy: 0.9062, test_Accuracy: 0.9187\n",
            "Epoch: [ 0] [  113/  468] time: 29.3106, train_loss: 0.17480218, train_accuracy: 0.9531, test_Accuracy: 0.9161\n",
            "Epoch: [ 0] [  114/  468] time: 29.5046, train_loss: 0.21574546, train_accuracy: 0.9141, test_Accuracy: 0.9197\n",
            "Epoch: [ 0] [  115/  468] time: 29.7038, train_loss: 0.18548466, train_accuracy: 0.9453, test_Accuracy: 0.9248\n",
            "Epoch: [ 0] [  116/  468] time: 29.9292, train_loss: 0.26888561, train_accuracy: 0.9062, test_Accuracy: 0.9302\n",
            "Epoch: [ 0] [  117/  468] time: 30.1297, train_loss: 0.25678191, train_accuracy: 0.9219, test_Accuracy: 0.9324\n",
            "Epoch: [ 0] [  118/  468] time: 30.3305, train_loss: 0.20962456, train_accuracy: 0.9453, test_Accuracy: 0.9314\n",
            "Epoch: [ 0] [  119/  468] time: 30.6614, train_loss: 0.28532308, train_accuracy: 0.9297, test_Accuracy: 0.9292\n",
            "Epoch: [ 0] [  120/  468] time: 30.8609, train_loss: 0.30138662, train_accuracy: 0.8906, test_Accuracy: 0.9277\n",
            "Epoch: [ 0] [  121/  468] time: 31.0785, train_loss: 0.21140175, train_accuracy: 0.9453, test_Accuracy: 0.9275\n",
            "Epoch: [ 0] [  122/  468] time: 31.4112, train_loss: 0.23002085, train_accuracy: 0.9219, test_Accuracy: 0.9298\n",
            "Epoch: [ 0] [  123/  468] time: 31.7451, train_loss: 0.25066283, train_accuracy: 0.9219, test_Accuracy: 0.9278\n",
            "Epoch: [ 0] [  124/  468] time: 31.9578, train_loss: 0.24774104, train_accuracy: 0.8984, test_Accuracy: 0.9265\n",
            "Epoch: [ 0] [  125/  468] time: 32.2891, train_loss: 0.21417995, train_accuracy: 0.9141, test_Accuracy: 0.9264\n",
            "Epoch: [ 0] [  126/  468] time: 32.4942, train_loss: 0.23505123, train_accuracy: 0.9297, test_Accuracy: 0.9290\n",
            "Epoch: [ 0] [  127/  468] time: 32.6884, train_loss: 0.19531785, train_accuracy: 0.9531, test_Accuracy: 0.9296\n",
            "Epoch: [ 0] [  128/  468] time: 32.8903, train_loss: 0.13931052, train_accuracy: 0.9688, test_Accuracy: 0.9285\n",
            "Epoch: [ 0] [  129/  468] time: 33.2213, train_loss: 0.28012019, train_accuracy: 0.9375, test_Accuracy: 0.9296\n",
            "Epoch: [ 0] [  130/  468] time: 33.4163, train_loss: 0.25234216, train_accuracy: 0.9297, test_Accuracy: 0.9280\n",
            "Epoch: [ 0] [  131/  468] time: 33.6084, train_loss: 0.25504109, train_accuracy: 0.9375, test_Accuracy: 0.9274\n",
            "Epoch: [ 0] [  132/  468] time: 33.8102, train_loss: 0.15232420, train_accuracy: 0.9688, test_Accuracy: 0.9273\n",
            "Epoch: [ 0] [  133/  468] time: 34.0314, train_loss: 0.16200151, train_accuracy: 0.9531, test_Accuracy: 0.9267\n",
            "Epoch: [ 0] [  134/  468] time: 34.2248, train_loss: 0.30519572, train_accuracy: 0.9062, test_Accuracy: 0.9292\n",
            "Epoch: [ 0] [  135/  468] time: 34.4257, train_loss: 0.40783489, train_accuracy: 0.9062, test_Accuracy: 0.9313\n",
            "Epoch: [ 0] [  136/  468] time: 35.0943, train_loss: 0.32609177, train_accuracy: 0.8828, test_Accuracy: 0.9341\n",
            "Epoch: [ 0] [  137/  468] time: 35.4480, train_loss: 0.25159448, train_accuracy: 0.9141, test_Accuracy: 0.9321\n",
            "Epoch: [ 0] [  138/  468] time: 36.1153, train_loss: 0.25746995, train_accuracy: 0.9453, test_Accuracy: 0.9254\n",
            "Epoch: [ 0] [  139/  468] time: 36.4846, train_loss: 0.32236296, train_accuracy: 0.9062, test_Accuracy: 0.9187\n",
            "Epoch: [ 0] [  140/  468] time: 36.8355, train_loss: 0.20493495, train_accuracy: 0.9219, test_Accuracy: 0.9187\n",
            "Epoch: [ 0] [  141/  468] time: 37.1663, train_loss: 0.24510399, train_accuracy: 0.9141, test_Accuracy: 0.9232\n",
            "Epoch: [ 0] [  142/  468] time: 37.3669, train_loss: 0.33536375, train_accuracy: 0.8984, test_Accuracy: 0.9303\n",
            "Epoch: [ 0] [  143/  468] time: 37.5681, train_loss: 0.17190412, train_accuracy: 0.9531, test_Accuracy: 0.9323\n",
            "Epoch: [ 0] [  144/  468] time: 37.7618, train_loss: 0.23863241, train_accuracy: 0.9297, test_Accuracy: 0.9314\n",
            "Epoch: [ 0] [  145/  468] time: 38.0960, train_loss: 0.40496233, train_accuracy: 0.9062, test_Accuracy: 0.9302\n",
            "Epoch: [ 0] [  146/  468] time: 38.3165, train_loss: 0.27914080, train_accuracy: 0.8984, test_Accuracy: 0.9299\n",
            "Epoch: [ 0] [  147/  468] time: 38.5261, train_loss: 0.30731127, train_accuracy: 0.9141, test_Accuracy: 0.9313\n",
            "Epoch: [ 0] [  148/  468] time: 38.7245, train_loss: 0.23623529, train_accuracy: 0.9141, test_Accuracy: 0.9337\n",
            "Epoch: [ 0] [  149/  468] time: 38.9248, train_loss: 0.14676392, train_accuracy: 0.9531, test_Accuracy: 0.9343\n",
            "Epoch: [ 0] [  150/  468] time: 39.1356, train_loss: 0.18324624, train_accuracy: 0.9297, test_Accuracy: 0.9338\n",
            "Epoch: [ 0] [  151/  468] time: 39.4823, train_loss: 0.29226822, train_accuracy: 0.9219, test_Accuracy: 0.9331\n",
            "Epoch: [ 0] [  152/  468] time: 39.6762, train_loss: 0.17402843, train_accuracy: 0.9453, test_Accuracy: 0.9338\n",
            "Epoch: [ 0] [  153/  468] time: 39.8767, train_loss: 0.22935317, train_accuracy: 0.9375, test_Accuracy: 0.9345\n",
            "Epoch: [ 0] [  154/  468] time: 40.0674, train_loss: 0.13845974, train_accuracy: 0.9531, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  155/  468] time: 40.2843, train_loss: 0.20936707, train_accuracy: 0.9453, test_Accuracy: 0.9376\n",
            "Epoch: [ 0] [  156/  468] time: 40.4742, train_loss: 0.15205109, train_accuracy: 0.9609, test_Accuracy: 0.9390\n",
            "Epoch: [ 0] [  157/  468] time: 40.6767, train_loss: 0.21699043, train_accuracy: 0.9297, test_Accuracy: 0.9388\n",
            "Epoch: [ 0] [  158/  468] time: 41.0071, train_loss: 0.23243359, train_accuracy: 0.9453, test_Accuracy: 0.9377\n",
            "Epoch: [ 0] [  159/  468] time: 41.2235, train_loss: 0.19716536, train_accuracy: 0.9453, test_Accuracy: 0.9380\n",
            "Epoch: [ 0] [  160/  468] time: 41.5533, train_loss: 0.27072847, train_accuracy: 0.9375, test_Accuracy: 0.9386\n",
            "Epoch: [ 0] [  161/  468] time: 41.8853, train_loss: 0.22829279, train_accuracy: 0.9375, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  162/  468] time: 42.0795, train_loss: 0.17706302, train_accuracy: 0.9453, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  163/  468] time: 42.2877, train_loss: 0.25463599, train_accuracy: 0.9141, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  164/  468] time: 42.4834, train_loss: 0.09228154, train_accuracy: 0.9766, test_Accuracy: 0.9340\n",
            "Epoch: [ 0] [  165/  468] time: 42.6827, train_loss: 0.23405522, train_accuracy: 0.9609, test_Accuracy: 0.9343\n",
            "Epoch: [ 0] [  166/  468] time: 42.8771, train_loss: 0.11144122, train_accuracy: 0.9609, test_Accuracy: 0.9351\n",
            "Epoch: [ 0] [  167/  468] time: 43.2142, train_loss: 0.19223019, train_accuracy: 0.9688, test_Accuracy: 0.9377\n",
            "Epoch: [ 0] [  168/  468] time: 43.4061, train_loss: 0.40500614, train_accuracy: 0.8828, test_Accuracy: 0.9419\n",
            "Epoch: [ 0] [  169/  468] time: 43.5980, train_loss: 0.14903545, train_accuracy: 0.9531, test_Accuracy: 0.9428\n",
            "Epoch: [ 0] [  170/  468] time: 43.7911, train_loss: 0.20858596, train_accuracy: 0.9375, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  171/  468] time: 44.0003, train_loss: 0.18325575, train_accuracy: 0.9375, test_Accuracy: 0.9379\n",
            "Epoch: [ 0] [  172/  468] time: 44.2078, train_loss: 0.19045225, train_accuracy: 0.9688, test_Accuracy: 0.9360\n",
            "Epoch: [ 0] [  173/  468] time: 44.4066, train_loss: 0.25102723, train_accuracy: 0.9375, test_Accuracy: 0.9362\n",
            "Epoch: [ 0] [  174/  468] time: 44.6042, train_loss: 0.30682579, train_accuracy: 0.9375, test_Accuracy: 0.9378\n",
            "Epoch: [ 0] [  175/  468] time: 44.8037, train_loss: 0.12747280, train_accuracy: 0.9766, test_Accuracy: 0.9395\n",
            "Epoch: [ 0] [  176/  468] time: 45.1401, train_loss: 0.16365482, train_accuracy: 0.9609, test_Accuracy: 0.9408\n",
            "Epoch: [ 0] [  177/  468] time: 45.4718, train_loss: 0.13750899, train_accuracy: 0.9609, test_Accuracy: 0.9411\n",
            "Epoch: [ 0] [  178/  468] time: 45.8021, train_loss: 0.17442349, train_accuracy: 0.9297, test_Accuracy: 0.9408\n",
            "Epoch: [ 0] [  179/  468] time: 46.1348, train_loss: 0.32502991, train_accuracy: 0.9219, test_Accuracy: 0.9398\n",
            "Epoch: [ 0] [  180/  468] time: 46.3430, train_loss: 0.17217007, train_accuracy: 0.9375, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  181/  468] time: 46.5310, train_loss: 0.24837172, train_accuracy: 0.9375, test_Accuracy: 0.9350\n",
            "Epoch: [ 0] [  182/  468] time: 46.7295, train_loss: 0.23409277, train_accuracy: 0.9531, test_Accuracy: 0.9324\n",
            "Epoch: [ 0] [  183/  468] time: 46.9217, train_loss: 0.25133237, train_accuracy: 0.9375, test_Accuracy: 0.9313\n",
            "Epoch: [ 0] [  184/  468] time: 47.1278, train_loss: 0.21386516, train_accuracy: 0.9375, test_Accuracy: 0.9309\n",
            "Epoch: [ 0] [  185/  468] time: 47.3387, train_loss: 0.26398492, train_accuracy: 0.9297, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  186/  468] time: 47.6703, train_loss: 0.41026115, train_accuracy: 0.9219, test_Accuracy: 0.9415\n",
            "Epoch: [ 0] [  187/  468] time: 47.8741, train_loss: 0.22356829, train_accuracy: 0.9531, test_Accuracy: 0.9428\n",
            "Epoch: [ 0] [  188/  468] time: 48.0660, train_loss: 0.26252216, train_accuracy: 0.9375, test_Accuracy: 0.9415\n",
            "Epoch: [ 0] [  189/  468] time: 48.2616, train_loss: 0.28321165, train_accuracy: 0.8984, test_Accuracy: 0.9421\n",
            "Epoch: [ 0] [  190/  468] time: 48.5990, train_loss: 0.12796122, train_accuracy: 0.9766, test_Accuracy: 0.9414\n",
            "Epoch: [ 0] [  191/  468] time: 49.3250, train_loss: 0.13067245, train_accuracy: 0.9766, test_Accuracy: 0.9411\n",
            "Epoch: [ 0] [  192/  468] time: 49.5674, train_loss: 0.22229576, train_accuracy: 0.9531, test_Accuracy: 0.9416\n",
            "Epoch: [ 0] [  193/  468] time: 49.7878, train_loss: 0.17123099, train_accuracy: 0.9531, test_Accuracy: 0.9430\n",
            "Epoch: [ 0] [  194/  468] time: 49.9794, train_loss: 0.22397453, train_accuracy: 0.9531, test_Accuracy: 0.9427\n",
            "Epoch: [ 0] [  195/  468] time: 50.1834, train_loss: 0.15695557, train_accuracy: 0.9688, test_Accuracy: 0.9442\n",
            "Epoch: [ 0] [  196/  468] time: 50.5143, train_loss: 0.13501315, train_accuracy: 0.9375, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  197/  468] time: 50.7149, train_loss: 0.28610152, train_accuracy: 0.9141, test_Accuracy: 0.9433\n",
            "Epoch: [ 0] [  198/  468] time: 50.9131, train_loss: 0.17611155, train_accuracy: 0.9531, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  199/  468] time: 51.1010, train_loss: 0.20709014, train_accuracy: 0.9453, test_Accuracy: 0.9433\n",
            "Epoch: [ 0] [  200/  468] time: 51.3068, train_loss: 0.13459297, train_accuracy: 0.9453, test_Accuracy: 0.9432\n",
            "Epoch: [ 0] [  201/  468] time: 51.4960, train_loss: 0.23729397, train_accuracy: 0.9141, test_Accuracy: 0.9431\n",
            "Epoch: [ 0] [  202/  468] time: 51.6996, train_loss: 0.24498859, train_accuracy: 0.9375, test_Accuracy: 0.9427\n",
            "Epoch: [ 0] [  203/  468] time: 51.8920, train_loss: 0.14761153, train_accuracy: 0.9609, test_Accuracy: 0.9415\n",
            "Epoch: [ 0] [  204/  468] time: 52.0981, train_loss: 0.20853151, train_accuracy: 0.9297, test_Accuracy: 0.9432\n",
            "Epoch: [ 0] [  205/  468] time: 52.4346, train_loss: 0.24546769, train_accuracy: 0.9531, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  206/  468] time: 52.6404, train_loss: 0.19534543, train_accuracy: 0.9297, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  207/  468] time: 52.8397, train_loss: 0.17585070, train_accuracy: 0.9219, test_Accuracy: 0.9449\n",
            "Epoch: [ 0] [  208/  468] time: 53.0477, train_loss: 0.22910289, train_accuracy: 0.9375, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  209/  468] time: 53.2431, train_loss: 0.20295183, train_accuracy: 0.9375, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  210/  468] time: 53.5849, train_loss: 0.19541562, train_accuracy: 0.9531, test_Accuracy: 0.9493\n",
            "Epoch: [ 0] [  211/  468] time: 53.9163, train_loss: 0.20041779, train_accuracy: 0.9531, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  212/  468] time: 54.1136, train_loss: 0.20915169, train_accuracy: 0.9453, test_Accuracy: 0.9490\n",
            "Epoch: [ 0] [  213/  468] time: 54.3167, train_loss: 0.09009212, train_accuracy: 0.9766, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  214/  468] time: 54.6482, train_loss: 0.20480585, train_accuracy: 0.9531, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  215/  468] time: 54.8436, train_loss: 0.21523631, train_accuracy: 0.9531, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  216/  468] time: 55.0412, train_loss: 0.10094258, train_accuracy: 0.9766, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  217/  468] time: 55.2340, train_loss: 0.17961213, train_accuracy: 0.9375, test_Accuracy: 0.9472\n",
            "Epoch: [ 0] [  218/  468] time: 55.5684, train_loss: 0.09024242, train_accuracy: 0.9766, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  219/  468] time: 55.7671, train_loss: 0.18874389, train_accuracy: 0.9531, test_Accuracy: 0.9472\n",
            "Epoch: [ 0] [  220/  468] time: 55.9656, train_loss: 0.14227898, train_accuracy: 0.9609, test_Accuracy: 0.9472\n",
            "Epoch: [ 0] [  221/  468] time: 56.1702, train_loss: 0.15249474, train_accuracy: 0.9375, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  222/  468] time: 56.3685, train_loss: 0.16952878, train_accuracy: 0.9453, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  223/  468] time: 56.5690, train_loss: 0.11686020, train_accuracy: 0.9609, test_Accuracy: 0.9457\n",
            "Epoch: [ 0] [  224/  468] time: 56.8979, train_loss: 0.17537403, train_accuracy: 0.9375, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  225/  468] time: 57.2285, train_loss: 0.14493686, train_accuracy: 0.9531, test_Accuracy: 0.9456\n",
            "Epoch: [ 0] [  226/  468] time: 57.4294, train_loss: 0.08951480, train_accuracy: 0.9844, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  227/  468] time: 57.6249, train_loss: 0.17347147, train_accuracy: 0.9531, test_Accuracy: 0.9461\n",
            "Epoch: [ 0] [  228/  468] time: 57.8316, train_loss: 0.18349746, train_accuracy: 0.9453, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  229/  468] time: 58.0223, train_loss: 0.22215642, train_accuracy: 0.9375, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  230/  468] time: 58.2245, train_loss: 0.14091256, train_accuracy: 0.9688, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  231/  468] time: 58.4217, train_loss: 0.19056955, train_accuracy: 0.9531, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  232/  468] time: 58.6301, train_loss: 0.10353444, train_accuracy: 0.9766, test_Accuracy: 0.9500\n",
            "Epoch: [ 0] [  233/  468] time: 58.8205, train_loss: 0.07814039, train_accuracy: 0.9844, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  234/  468] time: 59.0274, train_loss: 0.16030440, train_accuracy: 0.9375, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  235/  468] time: 59.2158, train_loss: 0.08733921, train_accuracy: 0.9766, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  236/  468] time: 59.5517, train_loss: 0.17638656, train_accuracy: 0.9766, test_Accuracy: 0.9464\n",
            "Epoch: [ 0] [  237/  468] time: 59.7811, train_loss: 0.17206833, train_accuracy: 0.9531, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  238/  468] time: 59.9772, train_loss: 0.17085475, train_accuracy: 0.9531, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  239/  468] time: 60.1697, train_loss: 0.15268028, train_accuracy: 0.9609, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  240/  468] time: 60.3853, train_loss: 0.18588188, train_accuracy: 0.9375, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  241/  468] time: 60.7174, train_loss: 0.09388051, train_accuracy: 0.9688, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  242/  468] time: 61.0530, train_loss: 0.12621158, train_accuracy: 0.9531, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  243/  468] time: 61.2706, train_loss: 0.20805231, train_accuracy: 0.9609, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  244/  468] time: 61.4670, train_loss: 0.13542682, train_accuracy: 0.9531, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  245/  468] time: 61.6722, train_loss: 0.12845701, train_accuracy: 0.9688, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  246/  468] time: 61.8685, train_loss: 0.26388228, train_accuracy: 0.9297, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  247/  468] time: 62.0734, train_loss: 0.06910217, train_accuracy: 0.9766, test_Accuracy: 0.9506\n",
            "Epoch: [ 0] [  248/  468] time: 62.2639, train_loss: 0.23150702, train_accuracy: 0.9219, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  249/  468] time: 62.4682, train_loss: 0.12779357, train_accuracy: 0.9531, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  250/  468] time: 62.6655, train_loss: 0.10342839, train_accuracy: 0.9766, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  251/  468] time: 63.0015, train_loss: 0.20325819, train_accuracy: 0.9141, test_Accuracy: 0.9455\n",
            "Epoch: [ 0] [  252/  468] time: 63.1998, train_loss: 0.08972342, train_accuracy: 0.9688, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  253/  468] time: 63.5344, train_loss: 0.16126002, train_accuracy: 0.9453, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  254/  468] time: 63.7347, train_loss: 0.10881108, train_accuracy: 0.9688, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  255/  468] time: 63.9335, train_loss: 0.10249884, train_accuracy: 0.9844, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  256/  468] time: 64.2663, train_loss: 0.22491620, train_accuracy: 0.9531, test_Accuracy: 0.9487\n",
            "Epoch: [ 0] [  257/  468] time: 64.6058, train_loss: 0.13529852, train_accuracy: 0.9609, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  258/  468] time: 64.9381, train_loss: 0.08719040, train_accuracy: 0.9766, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  259/  468] time: 65.2869, train_loss: 0.15619576, train_accuracy: 0.9531, test_Accuracy: 0.9465\n",
            "Epoch: [ 0] [  260/  468] time: 65.9646, train_loss: 0.10742082, train_accuracy: 0.9844, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  261/  468] time: 66.1550, train_loss: 0.18487865, train_accuracy: 0.9297, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  262/  468] time: 66.3589, train_loss: 0.09229103, train_accuracy: 0.9766, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  263/  468] time: 66.6311, train_loss: 0.24293542, train_accuracy: 0.9453, test_Accuracy: 0.9499\n",
            "Epoch: [ 0] [  264/  468] time: 66.8139, train_loss: 0.17486328, train_accuracy: 0.9531, test_Accuracy: 0.9520\n",
            "Epoch: [ 0] [  265/  468] time: 67.1995, train_loss: 0.11067452, train_accuracy: 0.9844, test_Accuracy: 0.9516\n",
            "Epoch: [ 0] [  266/  468] time: 67.6879, train_loss: 0.10727549, train_accuracy: 0.9609, test_Accuracy: 0.9512\n",
            "Epoch: [ 0] [  267/  468] time: 68.0217, train_loss: 0.14686470, train_accuracy: 0.9609, test_Accuracy: 0.9510\n",
            "Epoch: [ 0] [  268/  468] time: 68.3014, train_loss: 0.25386900, train_accuracy: 0.9141, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  269/  468] time: 68.5508, train_loss: 0.17811051, train_accuracy: 0.9453, test_Accuracy: 0.9498\n",
            "Epoch: [ 0] [  270/  468] time: 68.7648, train_loss: 0.12746310, train_accuracy: 0.9609, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  271/  468] time: 69.0504, train_loss: 0.25122947, train_accuracy: 0.9297, test_Accuracy: 0.9475\n",
            "Epoch: [ 0] [  272/  468] time: 69.3828, train_loss: 0.20039946, train_accuracy: 0.9453, test_Accuracy: 0.9488\n",
            "Epoch: [ 0] [  273/  468] time: 69.7420, train_loss: 0.11869355, train_accuracy: 0.9766, test_Accuracy: 0.9491\n",
            "Epoch: [ 0] [  274/  468] time: 70.0906, train_loss: 0.13588509, train_accuracy: 0.9688, test_Accuracy: 0.9501\n",
            "Epoch: [ 0] [  275/  468] time: 70.4601, train_loss: 0.11235198, train_accuracy: 0.9609, test_Accuracy: 0.9500\n",
            "Epoch: [ 0] [  276/  468] time: 70.6472, train_loss: 0.12394859, train_accuracy: 0.9688, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  277/  468] time: 70.8774, train_loss: 0.06977247, train_accuracy: 1.0000, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  278/  468] time: 71.0718, train_loss: 0.16665499, train_accuracy: 0.9531, test_Accuracy: 0.9456\n",
            "Epoch: [ 0] [  279/  468] time: 71.2669, train_loss: 0.11472128, train_accuracy: 0.9688, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  280/  468] time: 71.4575, train_loss: 0.16293365, train_accuracy: 0.9609, test_Accuracy: 0.9487\n",
            "Epoch: [ 0] [  281/  468] time: 71.6544, train_loss: 0.10668717, train_accuracy: 0.9688, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  282/  468] time: 71.8484, train_loss: 0.14245267, train_accuracy: 0.9609, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  283/  468] time: 72.0504, train_loss: 0.18816474, train_accuracy: 0.9297, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  284/  468] time: 72.2542, train_loss: 0.13521643, train_accuracy: 0.9453, test_Accuracy: 0.9438\n",
            "Epoch: [ 0] [  285/  468] time: 72.5963, train_loss: 0.39334381, train_accuracy: 0.9219, test_Accuracy: 0.9444\n",
            "Epoch: [ 0] [  286/  468] time: 72.9263, train_loss: 0.18173411, train_accuracy: 0.9453, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  287/  468] time: 73.1153, train_loss: 0.12620638, train_accuracy: 0.9609, test_Accuracy: 0.9509\n",
            "Epoch: [ 0] [  288/  468] time: 73.4517, train_loss: 0.09457558, train_accuracy: 0.9766, test_Accuracy: 0.9520\n",
            "Epoch: [ 0] [  289/  468] time: 73.6464, train_loss: 0.17609206, train_accuracy: 0.9531, test_Accuracy: 0.9519\n",
            "Epoch: [ 0] [  290/  468] time: 73.8453, train_loss: 0.15460348, train_accuracy: 0.9609, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  291/  468] time: 74.0568, train_loss: 0.15159796, train_accuracy: 0.9766, test_Accuracy: 0.9465\n",
            "Epoch: [ 0] [  292/  468] time: 74.4442, train_loss: 0.18150374, train_accuracy: 0.9609, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  293/  468] time: 74.7952, train_loss: 0.12076677, train_accuracy: 0.9531, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  294/  468] time: 75.1546, train_loss: 0.10431509, train_accuracy: 0.9766, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  295/  468] time: 75.3813, train_loss: 0.07761602, train_accuracy: 0.9844, test_Accuracy: 0.9504\n",
            "Epoch: [ 0] [  296/  468] time: 75.5681, train_loss: 0.10902007, train_accuracy: 0.9688, test_Accuracy: 0.9525\n",
            "Epoch: [ 0] [  297/  468] time: 75.7585, train_loss: 0.15968481, train_accuracy: 0.9453, test_Accuracy: 0.9537\n",
            "Epoch: [ 0] [  298/  468] time: 76.0918, train_loss: 0.14006402, train_accuracy: 0.9688, test_Accuracy: 0.9535\n",
            "Epoch: [ 0] [  299/  468] time: 76.2829, train_loss: 0.20073423, train_accuracy: 0.9297, test_Accuracy: 0.9522\n",
            "Epoch: [ 0] [  300/  468] time: 76.4857, train_loss: 0.12737198, train_accuracy: 0.9453, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  301/  468] time: 76.6979, train_loss: 0.15966004, train_accuracy: 0.9453, test_Accuracy: 0.9451\n",
            "Epoch: [ 0] [  302/  468] time: 76.9153, train_loss: 0.08053628, train_accuracy: 0.9844, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  303/  468] time: 77.1144, train_loss: 0.16323002, train_accuracy: 0.9453, test_Accuracy: 0.9440\n",
            "Epoch: [ 0] [  304/  468] time: 77.3046, train_loss: 0.13453549, train_accuracy: 0.9531, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  305/  468] time: 77.4907, train_loss: 0.10894540, train_accuracy: 0.9531, test_Accuracy: 0.9506\n",
            "Epoch: [ 0] [  306/  468] time: 77.6887, train_loss: 0.11569842, train_accuracy: 0.9609, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  307/  468] time: 77.8811, train_loss: 0.11019944, train_accuracy: 0.9766, test_Accuracy: 0.9559\n",
            "Epoch: [ 0] [  308/  468] time: 78.2174, train_loss: 0.19181293, train_accuracy: 0.9297, test_Accuracy: 0.9561\n",
            "Epoch: [ 0] [  309/  468] time: 78.4069, train_loss: 0.16785663, train_accuracy: 0.9688, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  310/  468] time: 78.6048, train_loss: 0.27633065, train_accuracy: 0.9453, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  311/  468] time: 78.9361, train_loss: 0.07383835, train_accuracy: 0.9844, test_Accuracy: 0.9532\n",
            "Epoch: [ 0] [  312/  468] time: 79.1235, train_loss: 0.14195944, train_accuracy: 0.9609, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  313/  468] time: 79.3165, train_loss: 0.07824972, train_accuracy: 0.9766, test_Accuracy: 0.9544\n",
            "Epoch: [ 0] [  314/  468] time: 79.6469, train_loss: 0.05684824, train_accuracy: 0.9922, test_Accuracy: 0.9546\n",
            "Epoch: [ 0] [  315/  468] time: 79.8432, train_loss: 0.19363494, train_accuracy: 0.9609, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  316/  468] time: 80.1792, train_loss: 0.06766643, train_accuracy: 0.9844, test_Accuracy: 0.9562\n",
            "Epoch: [ 0] [  317/  468] time: 80.5108, train_loss: 0.04758874, train_accuracy: 0.9844, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  318/  468] time: 80.7014, train_loss: 0.11253291, train_accuracy: 0.9688, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  319/  468] time: 80.8955, train_loss: 0.13112901, train_accuracy: 0.9531, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  320/  468] time: 81.0926, train_loss: 0.20480306, train_accuracy: 0.9297, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  321/  468] time: 81.2873, train_loss: 0.15115073, train_accuracy: 0.9531, test_Accuracy: 0.9567\n",
            "Epoch: [ 0] [  322/  468] time: 81.6178, train_loss: 0.07745088, train_accuracy: 0.9688, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  323/  468] time: 81.8011, train_loss: 0.09638286, train_accuracy: 0.9766, test_Accuracy: 0.9533\n",
            "Epoch: [ 0] [  324/  468] time: 81.9947, train_loss: 0.22310919, train_accuracy: 0.9375, test_Accuracy: 0.9527\n",
            "Epoch: [ 0] [  325/  468] time: 82.3272, train_loss: 0.16938439, train_accuracy: 0.9688, test_Accuracy: 0.9516\n",
            "Epoch: [ 0] [  326/  468] time: 82.5202, train_loss: 0.08953502, train_accuracy: 0.9844, test_Accuracy: 0.9516\n",
            "Epoch: [ 0] [  327/  468] time: 82.7079, train_loss: 0.17239457, train_accuracy: 0.9531, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  328/  468] time: 83.0369, train_loss: 0.07803251, train_accuracy: 0.9844, test_Accuracy: 0.9504\n",
            "Epoch: [ 0] [  329/  468] time: 83.3683, train_loss: 0.12377782, train_accuracy: 0.9609, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  330/  468] time: 83.5775, train_loss: 0.10425656, train_accuracy: 0.9688, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  331/  468] time: 83.7754, train_loss: 0.12741640, train_accuracy: 0.9609, test_Accuracy: 0.9502\n",
            "Epoch: [ 0] [  332/  468] time: 83.9757, train_loss: 0.16691945, train_accuracy: 0.9375, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  333/  468] time: 84.1824, train_loss: 0.13839053, train_accuracy: 0.9609, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  334/  468] time: 84.3786, train_loss: 0.11549623, train_accuracy: 0.9609, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  335/  468] time: 84.5830, train_loss: 0.13021123, train_accuracy: 0.9609, test_Accuracy: 0.9544\n",
            "Epoch: [ 0] [  336/  468] time: 84.7769, train_loss: 0.20288709, train_accuracy: 0.9375, test_Accuracy: 0.9544\n",
            "Epoch: [ 0] [  337/  468] time: 84.9892, train_loss: 0.15383223, train_accuracy: 0.9531, test_Accuracy: 0.9543\n",
            "Epoch: [ 0] [  338/  468] time: 85.1886, train_loss: 0.16587073, train_accuracy: 0.9609, test_Accuracy: 0.9538\n",
            "Epoch: [ 0] [  339/  468] time: 85.3828, train_loss: 0.16748181, train_accuracy: 0.9609, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  340/  468] time: 85.5841, train_loss: 0.20926309, train_accuracy: 0.9453, test_Accuracy: 0.9544\n",
            "Epoch: [ 0] [  341/  468] time: 85.7810, train_loss: 0.08570094, train_accuracy: 0.9844, test_Accuracy: 0.9549\n",
            "Epoch: [ 0] [  342/  468] time: 85.9728, train_loss: 0.08579367, train_accuracy: 0.9609, test_Accuracy: 0.9569\n",
            "Epoch: [ 0] [  343/  468] time: 86.3098, train_loss: 0.16956373, train_accuracy: 0.9453, test_Accuracy: 0.9581\n",
            "Epoch: [ 0] [  344/  468] time: 86.5166, train_loss: 0.08144768, train_accuracy: 0.9766, test_Accuracy: 0.9579\n",
            "Epoch: [ 0] [  345/  468] time: 86.8482, train_loss: 0.21006721, train_accuracy: 0.9453, test_Accuracy: 0.9563\n",
            "Epoch: [ 0] [  346/  468] time: 87.1840, train_loss: 0.27488443, train_accuracy: 0.9219, test_Accuracy: 0.9551\n",
            "Epoch: [ 0] [  347/  468] time: 87.3801, train_loss: 0.08733625, train_accuracy: 0.9609, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  348/  468] time: 87.7154, train_loss: 0.13112295, train_accuracy: 0.9688, test_Accuracy: 0.9543\n",
            "Epoch: [ 0] [  349/  468] time: 87.9057, train_loss: 0.09094437, train_accuracy: 0.9844, test_Accuracy: 0.9544\n",
            "Epoch: [ 0] [  350/  468] time: 88.2465, train_loss: 0.18294476, train_accuracy: 0.9453, test_Accuracy: 0.9567\n",
            "Epoch: [ 0] [  351/  468] time: 88.4426, train_loss: 0.08770378, train_accuracy: 0.9688, test_Accuracy: 0.9582\n",
            "Epoch: [ 0] [  352/  468] time: 88.6423, train_loss: 0.16750395, train_accuracy: 0.9531, test_Accuracy: 0.9582\n",
            "Epoch: [ 0] [  353/  468] time: 88.8405, train_loss: 0.06892468, train_accuracy: 0.9922, test_Accuracy: 0.9573\n",
            "Epoch: [ 0] [  354/  468] time: 89.0474, train_loss: 0.16287866, train_accuracy: 0.9453, test_Accuracy: 0.9561\n",
            "Epoch: [ 0] [  355/  468] time: 89.2465, train_loss: 0.11062098, train_accuracy: 0.9609, test_Accuracy: 0.9551\n",
            "Epoch: [ 0] [  356/  468] time: 89.4493, train_loss: 0.17502746, train_accuracy: 0.9609, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  357/  468] time: 89.6440, train_loss: 0.10696469, train_accuracy: 0.9688, test_Accuracy: 0.9556\n",
            "Epoch: [ 0] [  358/  468] time: 89.8373, train_loss: 0.16029999, train_accuracy: 0.9453, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  359/  468] time: 90.0329, train_loss: 0.21394302, train_accuracy: 0.9062, test_Accuracy: 0.9578\n",
            "Epoch: [ 0] [  360/  468] time: 90.2439, train_loss: 0.07031882, train_accuracy: 0.9766, test_Accuracy: 0.9578\n",
            "Epoch: [ 0] [  361/  468] time: 90.4420, train_loss: 0.09684670, train_accuracy: 0.9766, test_Accuracy: 0.9582\n",
            "Epoch: [ 0] [  362/  468] time: 90.6444, train_loss: 0.17992592, train_accuracy: 0.9297, test_Accuracy: 0.9571\n",
            "Epoch: [ 0] [  363/  468] time: 90.9772, train_loss: 0.16433528, train_accuracy: 0.9609, test_Accuracy: 0.9563\n",
            "Epoch: [ 0] [  364/  468] time: 91.3076, train_loss: 0.09629865, train_accuracy: 0.9688, test_Accuracy: 0.9532\n",
            "Epoch: [ 0] [  365/  468] time: 91.6579, train_loss: 0.07315336, train_accuracy: 0.9844, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  366/  468] time: 92.0710, train_loss: 0.20245039, train_accuracy: 0.9531, test_Accuracy: 0.9533\n",
            "Epoch: [ 0] [  367/  468] time: 92.7490, train_loss: 0.10221750, train_accuracy: 0.9844, test_Accuracy: 0.9535\n",
            "Epoch: [ 0] [  368/  468] time: 93.0433, train_loss: 0.11505873, train_accuracy: 0.9844, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  369/  468] time: 93.3912, train_loss: 0.08920974, train_accuracy: 0.9844, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  370/  468] time: 93.5817, train_loss: 0.19486953, train_accuracy: 0.9688, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  371/  468] time: 93.7743, train_loss: 0.10052045, train_accuracy: 0.9688, test_Accuracy: 0.9584\n",
            "Epoch: [ 0] [  372/  468] time: 93.9631, train_loss: 0.08026705, train_accuracy: 0.9766, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  373/  468] time: 94.1628, train_loss: 0.06632559, train_accuracy: 0.9922, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  374/  468] time: 94.4967, train_loss: 0.12833740, train_accuracy: 0.9766, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  375/  468] time: 94.8305, train_loss: 0.08149434, train_accuracy: 0.9766, test_Accuracy: 0.9564\n",
            "Epoch: [ 0] [  376/  468] time: 95.1711, train_loss: 0.11488111, train_accuracy: 0.9766, test_Accuracy: 0.9572\n",
            "Epoch: [ 0] [  377/  468] time: 95.3662, train_loss: 0.11292741, train_accuracy: 0.9766, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  378/  468] time: 95.7113, train_loss: 0.17045125, train_accuracy: 0.9609, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  379/  468] time: 95.9096, train_loss: 0.13184783, train_accuracy: 0.9688, test_Accuracy: 0.9596\n",
            "Epoch: [ 0] [  380/  468] time: 96.2452, train_loss: 0.08021022, train_accuracy: 0.9844, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  381/  468] time: 96.4551, train_loss: 0.12030915, train_accuracy: 0.9766, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  382/  468] time: 96.7896, train_loss: 0.05011810, train_accuracy: 0.9844, test_Accuracy: 0.9600\n",
            "Epoch: [ 0] [  383/  468] time: 96.9861, train_loss: 0.15683334, train_accuracy: 0.9688, test_Accuracy: 0.9596\n",
            "Epoch: [ 0] [  384/  468] time: 97.1846, train_loss: 0.13521153, train_accuracy: 0.9609, test_Accuracy: 0.9607\n",
            "Epoch: [ 0] [  385/  468] time: 97.4057, train_loss: 0.08541680, train_accuracy: 0.9844, test_Accuracy: 0.9603\n",
            "Epoch: [ 0] [  386/  468] time: 97.7400, train_loss: 0.20404094, train_accuracy: 0.9453, test_Accuracy: 0.9607\n",
            "Epoch: [ 0] [  387/  468] time: 97.9372, train_loss: 0.20425290, train_accuracy: 0.9453, test_Accuracy: 0.9619\n",
            "Epoch: [ 0] [  388/  468] time: 98.1437, train_loss: 0.09703921, train_accuracy: 0.9766, test_Accuracy: 0.9629\n",
            "Epoch: [ 0] [  389/  468] time: 98.3231, train_loss: 0.18570216, train_accuracy: 0.9531, test_Accuracy: 0.9639\n",
            "Epoch: [ 0] [  390/  468] time: 98.5317, train_loss: 0.14018977, train_accuracy: 0.9531, test_Accuracy: 0.9626\n",
            "Epoch: [ 0] [  391/  468] time: 98.8626, train_loss: 0.13753362, train_accuracy: 0.9453, test_Accuracy: 0.9626\n",
            "Epoch: [ 0] [  392/  468] time: 99.0637, train_loss: 0.11662087, train_accuracy: 0.9766, test_Accuracy: 0.9628\n",
            "Epoch: [ 0] [  393/  468] time: 99.2665, train_loss: 0.14134432, train_accuracy: 0.9766, test_Accuracy: 0.9636\n",
            "Epoch: [ 0] [  394/  468] time: 99.5145, train_loss: 0.07277193, train_accuracy: 0.9766, test_Accuracy: 0.9625\n",
            "Epoch: [ 0] [  395/  468] time: 99.8486, train_loss: 0.12600544, train_accuracy: 0.9688, test_Accuracy: 0.9611\n",
            "Epoch: [ 0] [  396/  468] time: 100.2067, train_loss: 0.12268262, train_accuracy: 0.9688, test_Accuracy: 0.9601\n",
            "Epoch: [ 0] [  397/  468] time: 100.5644, train_loss: 0.14885294, train_accuracy: 0.9531, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  398/  468] time: 100.9269, train_loss: 0.13285661, train_accuracy: 0.9375, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  399/  468] time: 101.2779, train_loss: 0.11386711, train_accuracy: 0.9688, test_Accuracy: 0.9603\n",
            "Epoch: [ 0] [  400/  468] time: 102.0391, train_loss: 0.11821534, train_accuracy: 0.9609, test_Accuracy: 0.9620\n",
            "Epoch: [ 0] [  401/  468] time: 102.2898, train_loss: 0.15471584, train_accuracy: 0.9609, test_Accuracy: 0.9622\n",
            "Epoch: [ 0] [  402/  468] time: 103.0271, train_loss: 0.07124992, train_accuracy: 0.9844, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  403/  468] time: 103.2326, train_loss: 0.09713560, train_accuracy: 0.9766, test_Accuracy: 0.9610\n",
            "Epoch: [ 0] [  404/  468] time: 103.7937, train_loss: 0.13567632, train_accuracy: 0.9453, test_Accuracy: 0.9599\n",
            "Epoch: [ 0] [  405/  468] time: 104.1284, train_loss: 0.22641692, train_accuracy: 0.9297, test_Accuracy: 0.9595\n",
            "Epoch: [ 0] [  406/  468] time: 104.3228, train_loss: 0.14679782, train_accuracy: 0.9688, test_Accuracy: 0.9586\n",
            "Epoch: [ 0] [  407/  468] time: 104.6582, train_loss: 0.10855272, train_accuracy: 0.9766, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  408/  468] time: 104.8551, train_loss: 0.12053572, train_accuracy: 0.9766, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  409/  468] time: 105.0510, train_loss: 0.07526009, train_accuracy: 0.9609, test_Accuracy: 0.9584\n",
            "Epoch: [ 0] [  410/  468] time: 105.3823, train_loss: 0.12126847, train_accuracy: 0.9531, test_Accuracy: 0.9586\n",
            "Epoch: [ 0] [  411/  468] time: 105.5797, train_loss: 0.10847312, train_accuracy: 0.9609, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  412/  468] time: 105.7727, train_loss: 0.11511581, train_accuracy: 0.9609, test_Accuracy: 0.9592\n",
            "Epoch: [ 0] [  413/  468] time: 105.9647, train_loss: 0.06626978, train_accuracy: 0.9688, test_Accuracy: 0.9590\n",
            "Epoch: [ 0] [  414/  468] time: 106.1807, train_loss: 0.18954787, train_accuracy: 0.9219, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  415/  468] time: 106.3655, train_loss: 0.25925583, train_accuracy: 0.9219, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  416/  468] time: 106.5620, train_loss: 0.12720685, train_accuracy: 0.9766, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  417/  468] time: 106.7649, train_loss: 0.20188747, train_accuracy: 0.9375, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  418/  468] time: 106.9946, train_loss: 0.09907945, train_accuracy: 0.9609, test_Accuracy: 0.9607\n",
            "Epoch: [ 0] [  419/  468] time: 107.3603, train_loss: 0.10345651, train_accuracy: 0.9688, test_Accuracy: 0.9623\n",
            "Epoch: [ 0] [  420/  468] time: 107.7058, train_loss: 0.10499157, train_accuracy: 0.9609, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  421/  468] time: 108.0594, train_loss: 0.20080286, train_accuracy: 0.9609, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  422/  468] time: 108.7285, train_loss: 0.16623938, train_accuracy: 0.9531, test_Accuracy: 0.9607\n",
            "Epoch: [ 0] [  423/  468] time: 109.4029, train_loss: 0.09785365, train_accuracy: 0.9766, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  424/  468] time: 109.7352, train_loss: 0.14384386, train_accuracy: 0.9531, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  425/  468] time: 109.9720, train_loss: 0.07347881, train_accuracy: 0.9844, test_Accuracy: 0.9620\n",
            "Epoch: [ 0] [  426/  468] time: 110.3148, train_loss: 0.16803603, train_accuracy: 0.9375, test_Accuracy: 0.9631\n",
            "Epoch: [ 0] [  427/  468] time: 110.5472, train_loss: 0.11453809, train_accuracy: 0.9766, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  428/  468] time: 110.8876, train_loss: 0.08915490, train_accuracy: 0.9766, test_Accuracy: 0.9601\n",
            "Epoch: [ 0] [  429/  468] time: 111.2343, train_loss: 0.11945593, train_accuracy: 0.9766, test_Accuracy: 0.9603\n",
            "Epoch: [ 0] [  430/  468] time: 111.5660, train_loss: 0.08393213, train_accuracy: 0.9766, test_Accuracy: 0.9611\n",
            "Epoch: [ 0] [  431/  468] time: 111.9250, train_loss: 0.18266433, train_accuracy: 0.9531, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  432/  468] time: 112.2957, train_loss: 0.14778596, train_accuracy: 0.9688, test_Accuracy: 0.9628\n",
            "Epoch: [ 0] [  433/  468] time: 112.6561, train_loss: 0.10687518, train_accuracy: 0.9766, test_Accuracy: 0.9632\n",
            "Epoch: [ 0] [  434/  468] time: 112.9051, train_loss: 0.31921947, train_accuracy: 0.9219, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  435/  468] time: 113.1224, train_loss: 0.17729315, train_accuracy: 0.9453, test_Accuracy: 0.9610\n",
            "Epoch: [ 0] [  436/  468] time: 113.4797, train_loss: 0.15358774, train_accuracy: 0.9453, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  437/  468] time: 113.8310, train_loss: 0.14971069, train_accuracy: 0.9453, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  438/  468] time: 114.1262, train_loss: 0.04689591, train_accuracy: 0.9844, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  439/  468] time: 114.3634, train_loss: 0.14547983, train_accuracy: 0.9609, test_Accuracy: 0.9598\n",
            "Epoch: [ 0] [  440/  468] time: 115.0557, train_loss: 0.08210434, train_accuracy: 0.9844, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  441/  468] time: 115.4095, train_loss: 0.11351410, train_accuracy: 0.9609, test_Accuracy: 0.9570\n",
            "Epoch: [ 0] [  442/  468] time: 115.7488, train_loss: 0.16500327, train_accuracy: 0.9531, test_Accuracy: 0.9563\n",
            "Epoch: [ 0] [  443/  468] time: 115.9625, train_loss: 0.14967591, train_accuracy: 0.9531, test_Accuracy: 0.9569\n",
            "Epoch: [ 0] [  444/  468] time: 116.2649, train_loss: 0.12319484, train_accuracy: 0.9531, test_Accuracy: 0.9578\n",
            "Epoch: [ 0] [  445/  468] time: 116.4868, train_loss: 0.06204610, train_accuracy: 0.9844, test_Accuracy: 0.9564\n",
            "Epoch: [ 0] [  446/  468] time: 116.7334, train_loss: 0.13283384, train_accuracy: 0.9531, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  447/  468] time: 116.9475, train_loss: 0.11448755, train_accuracy: 0.9531, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  448/  468] time: 117.3026, train_loss: 0.24028586, train_accuracy: 0.9375, test_Accuracy: 0.9605\n",
            "Epoch: [ 0] [  449/  468] time: 117.9729, train_loss: 0.14828864, train_accuracy: 0.9531, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  450/  468] time: 118.1948, train_loss: 0.19994357, train_accuracy: 0.9531, test_Accuracy: 0.9584\n",
            "Epoch: [ 0] [  451/  468] time: 118.5006, train_loss: 0.20337778, train_accuracy: 0.9453, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  452/  468] time: 118.8301, train_loss: 0.08079767, train_accuracy: 0.9766, test_Accuracy: 0.9563\n",
            "Epoch: [ 0] [  453/  468] time: 119.0351, train_loss: 0.10231087, train_accuracy: 0.9531, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  454/  468] time: 119.3807, train_loss: 0.14518639, train_accuracy: 0.9609, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  455/  468] time: 120.0702, train_loss: 0.17134742, train_accuracy: 0.9453, test_Accuracy: 0.9561\n",
            "Epoch: [ 0] [  456/  468] time: 120.7471, train_loss: 0.10573095, train_accuracy: 0.9688, test_Accuracy: 0.9594\n",
            "Epoch: [ 0] [  457/  468] time: 120.9892, train_loss: 0.05334747, train_accuracy: 0.9922, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  458/  468] time: 121.1900, train_loss: 0.19721159, train_accuracy: 0.9375, test_Accuracy: 0.9637\n",
            "Epoch: [ 0] [  459/  468] time: 121.3858, train_loss: 0.17394787, train_accuracy: 0.9688, test_Accuracy: 0.9651\n",
            "Epoch: [ 0] [  460/  468] time: 121.5743, train_loss: 0.13615327, train_accuracy: 0.9766, test_Accuracy: 0.9643\n",
            "Epoch: [ 0] [  461/  468] time: 121.7756, train_loss: 0.08222219, train_accuracy: 0.9844, test_Accuracy: 0.9630\n",
            "Epoch: [ 0] [  462/  468] time: 121.9729, train_loss: 0.06309248, train_accuracy: 0.9844, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  463/  468] time: 122.1778, train_loss: 0.15334475, train_accuracy: 0.9609, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  464/  468] time: 122.3655, train_loss: 0.12923983, train_accuracy: 0.9609, test_Accuracy: 0.9612\n",
            "Epoch: [ 0] [  465/  468] time: 122.5734, train_loss: 0.10610124, train_accuracy: 0.9609, test_Accuracy: 0.9608\n",
            "Epoch: [ 0] [  466/  468] time: 122.8155, train_loss: 0.14048445, train_accuracy: 0.9766, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  467/  468] time: 123.0152, train_loss: 0.12115686, train_accuracy: 0.9531, test_Accuracy: 0.9616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout\n",
        "- training data set의 샘플이 분포되어 있음\n",
        "![image.png](data:image/png;base64,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)\n",
        "  - Under-fittin: Traning Data의 sample들의 정확도가 낮고, Test Data set의 정확도도 낮음\n",
        "  - Over-fitting: Traning Data의 sample들의 정확도가 높은 것, Test Data set의 정확도는 낮음\n",
        "- Network가 있을 때, 각각의 뉴런들 중 몇 개를 끄고 학습하는 것, 즉, 일부분만 활용하는 것\n",
        "  - 무슨 노드를 끄는지는 랜덤\n",
        "  - Test 때는 모든 뉴런들을 이용\n",
        "- Regularization이라고 할 수 있음"
      ],
      "metadata": {
        "id": "YkfmnYsPSCrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create network"
      ],
      "metadata": {
        "id": "n-MLqtVaUPLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten() :\n",
        "    return tf.keras.layers.Flatten()\n",
        "\n",
        "def dense(label_dim, weight_init) :\n",
        "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
        "\n",
        "def relu() :\n",
        "    return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
        "\n",
        "def dropout(rate) :\n",
        "    return tf.keras.layers.Dropout(rate)"
      ],
      "metadata": {
        "id": "7ItzrlCTT3m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance function"
      ],
      "metadata": {
        "id": "LfPdaFdaUwej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, \n",
        "                                                                   from_logits=True))\n",
        "    return loss\n",
        "\n",
        "def accuracy_fn(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
        "    return accuracy\n",
        "\n",
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ],
      "metadata": {
        "id": "M6sTCugVUyTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model - function"
      ],
      "metadata": {
        "id": "BNojS59KUUn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class create_model_class(tf.keras.Model):\n",
        "    def __init__(self, label_dim):\n",
        "        super(create_model_class, self).__init__()\n",
        "        weight_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(flatten())\n",
        "\n",
        "        for i in range(4):\n",
        "            self.model.add(dense(512, weight_init))\n",
        "            self.model.add(relu())\n",
        "            self.model.add(dropout(rate=0.5))\n",
        "\n",
        "        self.model.add(dense(label_dim, weight_init))\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "CYVtaHGDT59k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create network - function"
      ],
      "metadata": {
        "id": "VwTLQ-eCUaOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_function(label_dim) :\n",
        "    weight_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(flatten())\n",
        "\n",
        "    for i in range(4) :\n",
        "        model.add(dense(512, weight_init))\n",
        "        model.add(relu())\n",
        "        model.add(dropout(rate=0.5))\n",
        "\n",
        "    model.add(dense(label_dim, weight_init))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "oFgn3a-fT8L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model & optimizer & writer"
      ],
      "metadata": {
        "id": "HhrpP62rU_IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Model \"\"\"\n",
        "network = create_model_function(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "\"\"\" Writer \"\"\"\n",
        "checkpoint_dir = 'checkpoints'\n",
        "logs_dir = 'logs'\n",
        "\n",
        "model_dir = 'nn_dropout'\n",
        "\n",
        "checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "check_folder(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n",
        "logs_dir = os.path.join(logs_dir, model_dir)"
      ],
      "metadata": {
        "id": "vOXgf3loUJ1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restore checkpoint & start train or test phase"
      ],
      "metadata": {
        "id": "L5zRBRKSVBAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if train_flag :\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(dnn=network)\n",
        "\n",
        "    # create writer for tensorboard\n",
        "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
        "    start_time = time()\n",
        "\n",
        "    # restore check-point if it exits\n",
        "    could_load, checkpoint_counter = load(network, checkpoint_dir)    \n",
        "\n",
        "    if could_load:\n",
        "        start_epoch = (int)(checkpoint_counter / training_iterations)        \n",
        "        counter = checkpoint_counter        \n",
        "        print(\" [*] Load SUCCESS\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        start_iteration = 0\n",
        "        counter = 0\n",
        "        print(\" [!] Load failed...\")\n",
        "    \n",
        "    # train phase\n",
        "    with summary_writer.as_default():  # for tensorboard\n",
        "        for epoch in range(start_epoch, training_epochs):\n",
        "            for idx, (train_input, train_label) in enumerate(train_dataset):            \n",
        "                grads = grad(network, train_input, train_label)\n",
        "                optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
        "\n",
        "                train_loss = loss_fn(network, train_input, train_label)\n",
        "                train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "                \n",
        "                for test_input, test_label in test_dataset:                \n",
        "                    test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n",
        "                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n",
        "                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n",
        "\n",
        "                print(\n",
        "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
        "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
        "                       test_accuracy))\n",
        "                counter += 1                \n",
        "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
        "        \n",
        "# test phase      \n",
        "else :\n",
        "    _, _ = load(network, checkpoint_dir)\n",
        "    for test_input, test_label in test_dataset:    \n",
        "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CFlm0ZpUMCR",
        "outputId": "31b7cb82-9741-488f-a473-269edcceddb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Reading checkpoints...\n",
            " [*] Failed to find a checkpoint\n",
            " [!] Load failed...\n",
            "Epoch: [ 0] [    0/  468] time: 0.8293, train_loss: 2.32374096, train_accuracy: 0.2734, test_Accuracy: 0.1889\n",
            "Epoch: [ 0] [    1/  468] time: 1.5295, train_loss: 2.28977537, train_accuracy: 0.1875, test_Accuracy: 0.1310\n",
            "Epoch: [ 0] [    2/  468] time: 2.2412, train_loss: 2.25335622, train_accuracy: 0.1641, test_Accuracy: 0.1086\n",
            "Epoch: [ 0] [    3/  468] time: 2.9394, train_loss: 2.22751999, train_accuracy: 0.1016, test_Accuracy: 0.1382\n",
            "Epoch: [ 0] [    4/  468] time: 3.6477, train_loss: 2.25236654, train_accuracy: 0.1797, test_Accuracy: 0.1820\n",
            "Epoch: [ 0] [    5/  468] time: 4.1752, train_loss: 2.23017287, train_accuracy: 0.3281, test_Accuracy: 0.3211\n",
            "Epoch: [ 0] [    6/  468] time: 4.8742, train_loss: 2.18742990, train_accuracy: 0.4297, test_Accuracy: 0.4438\n",
            "Epoch: [ 0] [    7/  468] time: 5.5828, train_loss: 2.19688082, train_accuracy: 0.4531, test_Accuracy: 0.4486\n",
            "Epoch: [ 0] [    8/  468] time: 6.2895, train_loss: 2.26672363, train_accuracy: 0.4453, test_Accuracy: 0.4269\n",
            "Epoch: [ 0] [    9/  468] time: 6.9925, train_loss: 2.10687065, train_accuracy: 0.5234, test_Accuracy: 0.4116\n",
            "Epoch: [ 0] [   10/  468] time: 7.5209, train_loss: 2.13810110, train_accuracy: 0.3750, test_Accuracy: 0.4123\n",
            "Epoch: [ 0] [   11/  468] time: 8.0554, train_loss: 2.07141161, train_accuracy: 0.4297, test_Accuracy: 0.4183\n",
            "Epoch: [ 0] [   12/  468] time: 8.7561, train_loss: 2.05650425, train_accuracy: 0.4688, test_Accuracy: 0.4500\n",
            "Epoch: [ 0] [   13/  468] time: 9.4630, train_loss: 2.01040816, train_accuracy: 0.5000, test_Accuracy: 0.4988\n",
            "Epoch: [ 0] [   14/  468] time: 10.1621, train_loss: 1.83650815, train_accuracy: 0.5938, test_Accuracy: 0.5392\n",
            "Epoch: [ 0] [   15/  468] time: 10.6869, train_loss: 2.02680731, train_accuracy: 0.5938, test_Accuracy: 0.5697\n",
            "Epoch: [ 0] [   16/  468] time: 11.2263, train_loss: 1.94935822, train_accuracy: 0.6328, test_Accuracy: 0.5861\n",
            "Epoch: [ 0] [   17/  468] time: 11.7555, train_loss: 1.80860877, train_accuracy: 0.6562, test_Accuracy: 0.5989\n",
            "Epoch: [ 0] [   18/  468] time: 12.4602, train_loss: 1.78072345, train_accuracy: 0.6328, test_Accuracy: 0.6028\n",
            "Epoch: [ 0] [   19/  468] time: 13.1584, train_loss: 1.78365767, train_accuracy: 0.6250, test_Accuracy: 0.6156\n",
            "Epoch: [ 0] [   20/  468] time: 13.8550, train_loss: 1.68482089, train_accuracy: 0.6953, test_Accuracy: 0.6247\n",
            "Epoch: [ 0] [   21/  468] time: 14.5686, train_loss: 1.70048046, train_accuracy: 0.5859, test_Accuracy: 0.6426\n",
            "Epoch: [ 0] [   22/  468] time: 15.2685, train_loss: 1.61748171, train_accuracy: 0.6328, test_Accuracy: 0.6566\n",
            "Epoch: [ 0] [   23/  468] time: 15.9739, train_loss: 1.63722205, train_accuracy: 0.6875, test_Accuracy: 0.6807\n",
            "Epoch: [ 0] [   24/  468] time: 16.5015, train_loss: 1.33745492, train_accuracy: 0.7344, test_Accuracy: 0.6935\n",
            "Epoch: [ 0] [   25/  468] time: 17.2023, train_loss: 1.42630243, train_accuracy: 0.7344, test_Accuracy: 0.7026\n",
            "Epoch: [ 0] [   26/  468] time: 18.5968, train_loss: 1.33599377, train_accuracy: 0.6875, test_Accuracy: 0.7126\n",
            "Epoch: [ 0] [   27/  468] time: 19.3840, train_loss: 1.39516497, train_accuracy: 0.7344, test_Accuracy: 0.7231\n",
            "Epoch: [ 0] [   28/  468] time: 20.0908, train_loss: 1.50576901, train_accuracy: 0.6875, test_Accuracy: 0.7454\n",
            "Epoch: [ 0] [   29/  468] time: 20.7947, train_loss: 1.24336171, train_accuracy: 0.7656, test_Accuracy: 0.7575\n",
            "Epoch: [ 0] [   30/  468] time: 21.4926, train_loss: 1.29976487, train_accuracy: 0.7578, test_Accuracy: 0.7673\n",
            "Epoch: [ 0] [   31/  468] time: 22.1939, train_loss: 1.22398472, train_accuracy: 0.7656, test_Accuracy: 0.7856\n",
            "Epoch: [ 0] [   32/  468] time: 22.8953, train_loss: 1.23251343, train_accuracy: 0.7578, test_Accuracy: 0.7843\n",
            "Epoch: [ 0] [   33/  468] time: 23.5956, train_loss: 1.22171736, train_accuracy: 0.7422, test_Accuracy: 0.7807\n",
            "Epoch: [ 0] [   34/  468] time: 24.2993, train_loss: 1.03026581, train_accuracy: 0.7969, test_Accuracy: 0.7748\n",
            "Epoch: [ 0] [   35/  468] time: 25.0014, train_loss: 1.20414424, train_accuracy: 0.7656, test_Accuracy: 0.7589\n",
            "Epoch: [ 0] [   36/  468] time: 25.6986, train_loss: 0.96452439, train_accuracy: 0.7891, test_Accuracy: 0.7511\n",
            "Epoch: [ 0] [   37/  468] time: 26.4044, train_loss: 0.94470310, train_accuracy: 0.7422, test_Accuracy: 0.7541\n",
            "Epoch: [ 0] [   38/  468] time: 27.1155, train_loss: 0.94231623, train_accuracy: 0.7109, test_Accuracy: 0.7593\n",
            "Epoch: [ 0] [   39/  468] time: 27.8162, train_loss: 1.14371538, train_accuracy: 0.7188, test_Accuracy: 0.7737\n",
            "Epoch: [ 0] [   40/  468] time: 28.5204, train_loss: 0.91926628, train_accuracy: 0.7656, test_Accuracy: 0.7950\n",
            "Epoch: [ 0] [   41/  468] time: 29.2210, train_loss: 1.02368259, train_accuracy: 0.7578, test_Accuracy: 0.8125\n",
            "Epoch: [ 0] [   42/  468] time: 29.9433, train_loss: 1.01443768, train_accuracy: 0.8438, test_Accuracy: 0.8137\n",
            "Epoch: [ 0] [   43/  468] time: 30.6750, train_loss: 0.79844272, train_accuracy: 0.8047, test_Accuracy: 0.8085\n",
            "Epoch: [ 0] [   44/  468] time: 32.0157, train_loss: 0.99718618, train_accuracy: 0.7969, test_Accuracy: 0.8065\n",
            "Epoch: [ 0] [   45/  468] time: 33.4262, train_loss: 1.02055418, train_accuracy: 0.8125, test_Accuracy: 0.8045\n",
            "Epoch: [ 0] [   46/  468] time: 33.9538, train_loss: 0.79272127, train_accuracy: 0.8047, test_Accuracy: 0.8038\n",
            "Epoch: [ 0] [   47/  468] time: 34.6758, train_loss: 0.77662587, train_accuracy: 0.8125, test_Accuracy: 0.8162\n",
            "Epoch: [ 0] [   48/  468] time: 35.4223, train_loss: 0.69522560, train_accuracy: 0.8828, test_Accuracy: 0.8267\n",
            "Epoch: [ 0] [   49/  468] time: 36.3492, train_loss: 0.66796708, train_accuracy: 0.8672, test_Accuracy: 0.8288\n",
            "Epoch: [ 0] [   50/  468] time: 37.1138, train_loss: 1.07493865, train_accuracy: 0.7188, test_Accuracy: 0.8358\n",
            "Epoch: [ 0] [   51/  468] time: 38.5760, train_loss: 0.74656409, train_accuracy: 0.8359, test_Accuracy: 0.8387\n",
            "Epoch: [ 0] [   52/  468] time: 39.3373, train_loss: 0.98862755, train_accuracy: 0.7891, test_Accuracy: 0.8386\n",
            "Epoch: [ 0] [   53/  468] time: 40.7527, train_loss: 0.66340327, train_accuracy: 0.8438, test_Accuracy: 0.8432\n",
            "Epoch: [ 0] [   54/  468] time: 41.4516, train_loss: 0.74069929, train_accuracy: 0.8281, test_Accuracy: 0.8428\n",
            "Epoch: [ 0] [   55/  468] time: 42.7938, train_loss: 0.83842969, train_accuracy: 0.8750, test_Accuracy: 0.8457\n",
            "Epoch: [ 0] [   56/  468] time: 43.3263, train_loss: 0.72054189, train_accuracy: 0.8594, test_Accuracy: 0.8505\n",
            "Epoch: [ 0] [   57/  468] time: 44.6785, train_loss: 0.88002676, train_accuracy: 0.8672, test_Accuracy: 0.8574\n",
            "Epoch: [ 0] [   58/  468] time: 46.0972, train_loss: 0.65484744, train_accuracy: 0.8281, test_Accuracy: 0.8678\n",
            "Epoch: [ 0] [   59/  468] time: 46.7972, train_loss: 0.73482770, train_accuracy: 0.8906, test_Accuracy: 0.8733\n",
            "Epoch: [ 0] [   60/  468] time: 47.3350, train_loss: 0.74953032, train_accuracy: 0.9141, test_Accuracy: 0.8765\n",
            "Epoch: [ 0] [   61/  468] time: 48.0407, train_loss: 0.79186589, train_accuracy: 0.8672, test_Accuracy: 0.8756\n",
            "Epoch: [ 0] [   62/  468] time: 48.7421, train_loss: 0.56857818, train_accuracy: 0.9219, test_Accuracy: 0.8754\n",
            "Epoch: [ 0] [   63/  468] time: 49.2753, train_loss: 0.67662561, train_accuracy: 0.8750, test_Accuracy: 0.8777\n",
            "Epoch: [ 0] [   64/  468] time: 49.9742, train_loss: 0.64992505, train_accuracy: 0.9062, test_Accuracy: 0.8773\n",
            "Epoch: [ 0] [   65/  468] time: 50.6741, train_loss: 0.60383403, train_accuracy: 0.8984, test_Accuracy: 0.8767\n",
            "Epoch: [ 0] [   66/  468] time: 51.3737, train_loss: 0.57062167, train_accuracy: 0.8750, test_Accuracy: 0.8796\n",
            "Epoch: [ 0] [   67/  468] time: 52.0739, train_loss: 0.61225820, train_accuracy: 0.9062, test_Accuracy: 0.8823\n",
            "Epoch: [ 0] [   68/  468] time: 52.7762, train_loss: 0.57210219, train_accuracy: 0.8516, test_Accuracy: 0.8852\n",
            "Epoch: [ 0] [   69/  468] time: 53.4861, train_loss: 0.63791156, train_accuracy: 0.8984, test_Accuracy: 0.8862\n",
            "Epoch: [ 0] [   70/  468] time: 54.1884, train_loss: 0.57383394, train_accuracy: 0.8984, test_Accuracy: 0.8882\n",
            "Epoch: [ 0] [   71/  468] time: 54.7264, train_loss: 0.74592733, train_accuracy: 0.8516, test_Accuracy: 0.8907\n",
            "Epoch: [ 0] [   72/  468] time: 55.4244, train_loss: 0.54911375, train_accuracy: 0.8594, test_Accuracy: 0.8916\n",
            "Epoch: [ 0] [   73/  468] time: 56.1255, train_loss: 0.56229323, train_accuracy: 0.8906, test_Accuracy: 0.8920\n",
            "Epoch: [ 0] [   74/  468] time: 56.8260, train_loss: 0.62754714, train_accuracy: 0.8438, test_Accuracy: 0.8922\n",
            "Epoch: [ 0] [   75/  468] time: 57.3377, train_loss: 0.56673050, train_accuracy: 0.8906, test_Accuracy: 0.8937\n",
            "Epoch: [ 0] [   76/  468] time: 57.8782, train_loss: 0.83723718, train_accuracy: 0.8047, test_Accuracy: 0.8916\n",
            "Epoch: [ 0] [   77/  468] time: 58.5978, train_loss: 0.65858728, train_accuracy: 0.8438, test_Accuracy: 0.8917\n",
            "Epoch: [ 0] [   78/  468] time: 60.0039, train_loss: 0.53551710, train_accuracy: 0.9297, test_Accuracy: 0.8925\n",
            "Epoch: [ 0] [   79/  468] time: 60.7775, train_loss: 0.66654146, train_accuracy: 0.8750, test_Accuracy: 0.8946\n",
            "Epoch: [ 0] [   80/  468] time: 61.4763, train_loss: 0.49092954, train_accuracy: 0.9062, test_Accuracy: 0.8957\n",
            "Epoch: [ 0] [   81/  468] time: 62.1761, train_loss: 0.57905698, train_accuracy: 0.8828, test_Accuracy: 0.8976\n",
            "Epoch: [ 0] [   82/  468] time: 62.8830, train_loss: 0.66495329, train_accuracy: 0.8438, test_Accuracy: 0.8977\n",
            "Epoch: [ 0] [   83/  468] time: 63.4183, train_loss: 0.55787164, train_accuracy: 0.9141, test_Accuracy: 0.9002\n",
            "Epoch: [ 0] [   84/  468] time: 63.9453, train_loss: 0.54112697, train_accuracy: 0.9375, test_Accuracy: 0.9004\n",
            "Epoch: [ 0] [   85/  468] time: 64.6462, train_loss: 0.48105127, train_accuracy: 0.9297, test_Accuracy: 0.9031\n",
            "Epoch: [ 0] [   86/  468] time: 65.3460, train_loss: 0.50788003, train_accuracy: 0.9297, test_Accuracy: 0.9051\n",
            "Epoch: [ 0] [   87/  468] time: 65.8963, train_loss: 0.56380528, train_accuracy: 0.8828, test_Accuracy: 0.9041\n",
            "Epoch: [ 0] [   88/  468] time: 66.5952, train_loss: 0.43681848, train_accuracy: 0.9531, test_Accuracy: 0.9023\n",
            "Epoch: [ 0] [   89/  468] time: 67.5292, train_loss: 0.63175142, train_accuracy: 0.8750, test_Accuracy: 0.8999\n",
            "Epoch: [ 0] [   90/  468] time: 68.3093, train_loss: 0.52948588, train_accuracy: 0.8516, test_Accuracy: 0.9004\n",
            "Epoch: [ 0] [   91/  468] time: 69.0136, train_loss: 0.50457233, train_accuracy: 0.8984, test_Accuracy: 0.9015\n",
            "Epoch: [ 0] [   92/  468] time: 70.4114, train_loss: 0.55574089, train_accuracy: 0.8672, test_Accuracy: 0.9013\n",
            "Epoch: [ 0] [   93/  468] time: 71.1167, train_loss: 0.50256038, train_accuracy: 0.9297, test_Accuracy: 0.9022\n",
            "Epoch: [ 0] [   94/  468] time: 71.8205, train_loss: 0.48268646, train_accuracy: 0.8906, test_Accuracy: 0.9041\n",
            "Epoch: [ 0] [   95/  468] time: 73.1890, train_loss: 0.49143741, train_accuracy: 0.8984, test_Accuracy: 0.9039\n",
            "Epoch: [ 0] [   96/  468] time: 73.9391, train_loss: 0.41725338, train_accuracy: 0.8750, test_Accuracy: 0.9006\n",
            "Epoch: [ 0] [   97/  468] time: 74.7085, train_loss: 0.51124001, train_accuracy: 0.8828, test_Accuracy: 0.8968\n",
            "Epoch: [ 0] [   98/  468] time: 75.4328, train_loss: 0.48158360, train_accuracy: 0.9375, test_Accuracy: 0.8940\n",
            "Epoch: [ 0] [   99/  468] time: 76.8541, train_loss: 0.61208892, train_accuracy: 0.8984, test_Accuracy: 0.8932\n",
            "Epoch: [ 0] [  100/  468] time: 78.2732, train_loss: 0.52284509, train_accuracy: 0.9062, test_Accuracy: 0.8976\n",
            "Epoch: [ 0] [  101/  468] time: 78.9781, train_loss: 0.55998504, train_accuracy: 0.8750, test_Accuracy: 0.9043\n",
            "Epoch: [ 0] [  102/  468] time: 79.6872, train_loss: 0.74383909, train_accuracy: 0.8672, test_Accuracy: 0.9078\n",
            "Epoch: [ 0] [  103/  468] time: 80.3871, train_loss: 0.52334642, train_accuracy: 0.9297, test_Accuracy: 0.9111\n",
            "Epoch: [ 0] [  104/  468] time: 81.0871, train_loss: 0.41539353, train_accuracy: 0.9609, test_Accuracy: 0.9105\n",
            "Epoch: [ 0] [  105/  468] time: 81.7899, train_loss: 0.46723440, train_accuracy: 0.9688, test_Accuracy: 0.9121\n",
            "Epoch: [ 0] [  106/  468] time: 82.4860, train_loss: 0.42512837, train_accuracy: 0.9062, test_Accuracy: 0.9138\n",
            "Epoch: [ 0] [  107/  468] time: 83.1871, train_loss: 0.48610133, train_accuracy: 0.8984, test_Accuracy: 0.9138\n",
            "Epoch: [ 0] [  108/  468] time: 83.8856, train_loss: 0.62163723, train_accuracy: 0.8828, test_Accuracy: 0.9134\n",
            "Epoch: [ 0] [  109/  468] time: 84.5865, train_loss: 0.47276685, train_accuracy: 0.9219, test_Accuracy: 0.9148\n",
            "Epoch: [ 0] [  110/  468] time: 85.2858, train_loss: 0.54809177, train_accuracy: 0.9375, test_Accuracy: 0.9156\n",
            "Epoch: [ 0] [  111/  468] time: 85.9860, train_loss: 0.58542418, train_accuracy: 0.8672, test_Accuracy: 0.9156\n",
            "Epoch: [ 0] [  112/  468] time: 86.6878, train_loss: 0.42835310, train_accuracy: 0.9219, test_Accuracy: 0.9154\n",
            "Epoch: [ 0] [  113/  468] time: 87.4024, train_loss: 0.39101583, train_accuracy: 0.9297, test_Accuracy: 0.9152\n",
            "Epoch: [ 0] [  114/  468] time: 87.9445, train_loss: 0.55866969, train_accuracy: 0.8750, test_Accuracy: 0.9146\n",
            "Epoch: [ 0] [  115/  468] time: 88.6457, train_loss: 0.46568069, train_accuracy: 0.9219, test_Accuracy: 0.9141\n",
            "Epoch: [ 0] [  116/  468] time: 89.3466, train_loss: 0.26257494, train_accuracy: 0.9375, test_Accuracy: 0.9125\n",
            "Epoch: [ 0] [  117/  468] time: 89.8909, train_loss: 0.39571109, train_accuracy: 0.9297, test_Accuracy: 0.9127\n",
            "Epoch: [ 0] [  118/  468] time: 90.5982, train_loss: 0.59199488, train_accuracy: 0.9062, test_Accuracy: 0.9133\n",
            "Epoch: [ 0] [  119/  468] time: 91.3048, train_loss: 0.48517546, train_accuracy: 0.9062, test_Accuracy: 0.9144\n",
            "Epoch: [ 0] [  120/  468] time: 92.0062, train_loss: 0.49110383, train_accuracy: 0.9219, test_Accuracy: 0.9159\n",
            "Epoch: [ 0] [  121/  468] time: 92.7078, train_loss: 0.47704345, train_accuracy: 0.9141, test_Accuracy: 0.9173\n",
            "Epoch: [ 0] [  122/  468] time: 93.2531, train_loss: 0.40748709, train_accuracy: 0.9062, test_Accuracy: 0.9177\n",
            "Epoch: [ 0] [  123/  468] time: 93.9558, train_loss: 0.41760430, train_accuracy: 0.9062, test_Accuracy: 0.9187\n",
            "Epoch: [ 0] [  124/  468] time: 94.6660, train_loss: 0.46000499, train_accuracy: 0.9219, test_Accuracy: 0.9187\n",
            "Epoch: [ 0] [  125/  468] time: 95.3691, train_loss: 0.27279446, train_accuracy: 0.9453, test_Accuracy: 0.9195\n",
            "Epoch: [ 0] [  126/  468] time: 96.0722, train_loss: 0.33791602, train_accuracy: 0.9453, test_Accuracy: 0.9198\n",
            "Epoch: [ 0] [  127/  468] time: 96.8344, train_loss: 0.45187831, train_accuracy: 0.9062, test_Accuracy: 0.9216\n",
            "Epoch: [ 0] [  128/  468] time: 97.5084, train_loss: 0.54096562, train_accuracy: 0.9141, test_Accuracy: 0.9230\n",
            "Epoch: [ 0] [  129/  468] time: 98.1894, train_loss: 0.34108010, train_accuracy: 0.8984, test_Accuracy: 0.9233\n",
            "Epoch: [ 0] [  130/  468] time: 98.9327, train_loss: 0.41310567, train_accuracy: 0.9141, test_Accuracy: 0.9212\n",
            "Epoch: [ 0] [  131/  468] time: 100.3085, train_loss: 0.47351325, train_accuracy: 0.9062, test_Accuracy: 0.9171\n",
            "Epoch: [ 0] [  132/  468] time: 101.2162, train_loss: 0.40558630, train_accuracy: 0.9062, test_Accuracy: 0.9164\n",
            "Epoch: [ 0] [  133/  468] time: 102.1256, train_loss: 0.31794053, train_accuracy: 0.9297, test_Accuracy: 0.9144\n",
            "Epoch: [ 0] [  134/  468] time: 102.8943, train_loss: 0.48214611, train_accuracy: 0.9297, test_Accuracy: 0.9150\n",
            "Epoch: [ 0] [  135/  468] time: 103.5947, train_loss: 0.58551425, train_accuracy: 0.8828, test_Accuracy: 0.9172\n",
            "Epoch: [ 0] [  136/  468] time: 104.2940, train_loss: 0.45533240, train_accuracy: 0.9375, test_Accuracy: 0.9185\n",
            "Epoch: [ 0] [  137/  468] time: 104.9930, train_loss: 0.42015052, train_accuracy: 0.9141, test_Accuracy: 0.9198\n",
            "Epoch: [ 0] [  138/  468] time: 105.6915, train_loss: 0.44135323, train_accuracy: 0.9141, test_Accuracy: 0.9200\n",
            "Epoch: [ 0] [  139/  468] time: 106.4059, train_loss: 0.46937340, train_accuracy: 0.8672, test_Accuracy: 0.9177\n",
            "Epoch: [ 0] [  140/  468] time: 107.1059, train_loss: 0.35677451, train_accuracy: 0.9141, test_Accuracy: 0.9185\n",
            "Epoch: [ 0] [  141/  468] time: 107.8115, train_loss: 0.39436686, train_accuracy: 0.9219, test_Accuracy: 0.9210\n",
            "Epoch: [ 0] [  142/  468] time: 108.5356, train_loss: 0.42164400, train_accuracy: 0.9141, test_Accuracy: 0.9239\n",
            "Epoch: [ 0] [  143/  468] time: 109.2342, train_loss: 0.49590826, train_accuracy: 0.9453, test_Accuracy: 0.9258\n",
            "Epoch: [ 0] [  144/  468] time: 110.5780, train_loss: 0.47398019, train_accuracy: 0.9297, test_Accuracy: 0.9260\n",
            "Epoch: [ 0] [  145/  468] time: 111.2373, train_loss: 0.35637757, train_accuracy: 0.9141, test_Accuracy: 0.9253\n",
            "Epoch: [ 0] [  146/  468] time: 111.9894, train_loss: 0.45276633, train_accuracy: 0.9297, test_Accuracy: 0.9244\n",
            "Epoch: [ 0] [  147/  468] time: 112.7205, train_loss: 0.32304847, train_accuracy: 0.9219, test_Accuracy: 0.9230\n",
            "Epoch: [ 0] [  148/  468] time: 113.3817, train_loss: 0.35459536, train_accuracy: 0.9297, test_Accuracy: 0.9220\n",
            "Epoch: [ 0] [  149/  468] time: 114.0397, train_loss: 0.39014614, train_accuracy: 0.9062, test_Accuracy: 0.9232\n",
            "Epoch: [ 0] [  150/  468] time: 114.7727, train_loss: 0.34567997, train_accuracy: 0.9219, test_Accuracy: 0.9259\n",
            "Epoch: [ 0] [  151/  468] time: 115.3863, train_loss: 0.43339527, train_accuracy: 0.8906, test_Accuracy: 0.9261\n",
            "Epoch: [ 0] [  152/  468] time: 116.0961, train_loss: 0.38684219, train_accuracy: 0.9375, test_Accuracy: 0.9268\n",
            "Epoch: [ 0] [  153/  468] time: 117.5302, train_loss: 0.32517242, train_accuracy: 0.9297, test_Accuracy: 0.9258\n",
            "Epoch: [ 0] [  154/  468] time: 120.2963, train_loss: 0.46142387, train_accuracy: 0.9141, test_Accuracy: 0.9252\n",
            "Epoch: [ 0] [  155/  468] time: 121.0459, train_loss: 0.36109722, train_accuracy: 0.9453, test_Accuracy: 0.9243\n",
            "Epoch: [ 0] [  156/  468] time: 121.9071, train_loss: 0.29235715, train_accuracy: 0.9375, test_Accuracy: 0.9263\n",
            "Epoch: [ 0] [  157/  468] time: 122.4405, train_loss: 0.26455984, train_accuracy: 0.9688, test_Accuracy: 0.9276\n",
            "Epoch: [ 0] [  158/  468] time: 123.1433, train_loss: 0.30438995, train_accuracy: 0.9453, test_Accuracy: 0.9286\n",
            "Epoch: [ 0] [  159/  468] time: 123.8467, train_loss: 0.37164426, train_accuracy: 0.9141, test_Accuracy: 0.9292\n",
            "Epoch: [ 0] [  160/  468] time: 124.5501, train_loss: 0.42212921, train_accuracy: 0.9375, test_Accuracy: 0.9289\n",
            "Epoch: [ 0] [  161/  468] time: 125.2534, train_loss: 0.28746107, train_accuracy: 0.9531, test_Accuracy: 0.9291\n",
            "Epoch: [ 0] [  162/  468] time: 125.9535, train_loss: 0.47217357, train_accuracy: 0.8984, test_Accuracy: 0.9283\n",
            "Epoch: [ 0] [  163/  468] time: 126.6545, train_loss: 0.24553487, train_accuracy: 0.9844, test_Accuracy: 0.9287\n",
            "Epoch: [ 0] [  164/  468] time: 127.3599, train_loss: 0.42025724, train_accuracy: 0.9297, test_Accuracy: 0.9296\n",
            "Epoch: [ 0] [  165/  468] time: 128.0644, train_loss: 0.40954846, train_accuracy: 0.9219, test_Accuracy: 0.9304\n",
            "Epoch: [ 0] [  166/  468] time: 128.7631, train_loss: 0.29420727, train_accuracy: 0.9609, test_Accuracy: 0.9297\n",
            "Epoch: [ 0] [  167/  468] time: 129.4882, train_loss: 0.27544785, train_accuracy: 0.9297, test_Accuracy: 0.9307\n",
            "Epoch: [ 0] [  168/  468] time: 130.1913, train_loss: 0.30788016, train_accuracy: 0.9297, test_Accuracy: 0.9296\n",
            "Epoch: [ 0] [  169/  468] time: 130.8907, train_loss: 0.28197688, train_accuracy: 0.9609, test_Accuracy: 0.9280\n",
            "Epoch: [ 0] [  170/  468] time: 131.5914, train_loss: 0.65862280, train_accuracy: 0.8750, test_Accuracy: 0.9269\n",
            "Epoch: [ 0] [  171/  468] time: 132.2193, train_loss: 0.30450952, train_accuracy: 0.9141, test_Accuracy: 0.9276\n",
            "Epoch: [ 0] [  172/  468] time: 133.0644, train_loss: 0.41367751, train_accuracy: 0.8984, test_Accuracy: 0.9286\n",
            "Epoch: [ 0] [  173/  468] time: 134.5147, train_loss: 0.38902181, train_accuracy: 0.9297, test_Accuracy: 0.9288\n",
            "Epoch: [ 0] [  174/  468] time: 135.2153, train_loss: 0.25906724, train_accuracy: 0.9766, test_Accuracy: 0.9283\n",
            "Epoch: [ 0] [  175/  468] time: 135.9729, train_loss: 0.29029441, train_accuracy: 0.9375, test_Accuracy: 0.9290\n",
            "Epoch: [ 0] [  176/  468] time: 137.4047, train_loss: 0.32742247, train_accuracy: 0.9219, test_Accuracy: 0.9302\n",
            "Epoch: [ 0] [  177/  468] time: 138.1076, train_loss: 0.32432380, train_accuracy: 0.9375, test_Accuracy: 0.9321\n",
            "Epoch: [ 0] [  178/  468] time: 138.8199, train_loss: 0.31778470, train_accuracy: 0.9453, test_Accuracy: 0.9328\n",
            "Epoch: [ 0] [  179/  468] time: 139.5263, train_loss: 0.27614766, train_accuracy: 0.9531, test_Accuracy: 0.9327\n",
            "Epoch: [ 0] [  180/  468] time: 140.2317, train_loss: 0.30420822, train_accuracy: 0.9062, test_Accuracy: 0.9323\n",
            "Epoch: [ 0] [  181/  468] time: 141.0093, train_loss: 0.28694117, train_accuracy: 0.9297, test_Accuracy: 0.9317\n",
            "Epoch: [ 0] [  182/  468] time: 141.7488, train_loss: 0.31028968, train_accuracy: 0.9297, test_Accuracy: 0.9325\n",
            "Epoch: [ 0] [  183/  468] time: 142.5042, train_loss: 0.32581422, train_accuracy: 0.9766, test_Accuracy: 0.9331\n",
            "Epoch: [ 0] [  184/  468] time: 143.2548, train_loss: 0.40983772, train_accuracy: 0.9531, test_Accuracy: 0.9340\n",
            "Epoch: [ 0] [  185/  468] time: 144.6081, train_loss: 0.28104424, train_accuracy: 0.9609, test_Accuracy: 0.9332\n",
            "Epoch: [ 0] [  186/  468] time: 145.3189, train_loss: 0.28158063, train_accuracy: 0.9531, test_Accuracy: 0.9336\n",
            "Epoch: [ 0] [  187/  468] time: 146.0342, train_loss: 0.48210302, train_accuracy: 0.9219, test_Accuracy: 0.9339\n",
            "Epoch: [ 0] [  188/  468] time: 146.7384, train_loss: 0.32730103, train_accuracy: 0.9766, test_Accuracy: 0.9347\n",
            "Epoch: [ 0] [  189/  468] time: 147.2694, train_loss: 0.36268729, train_accuracy: 0.9297, test_Accuracy: 0.9344\n",
            "Epoch: [ 0] [  190/  468] time: 147.9718, train_loss: 0.36487049, train_accuracy: 0.9531, test_Accuracy: 0.9349\n",
            "Epoch: [ 0] [  191/  468] time: 148.5043, train_loss: 0.40515578, train_accuracy: 0.9141, test_Accuracy: 0.9362\n",
            "Epoch: [ 0] [  192/  468] time: 149.2106, train_loss: 0.38349223, train_accuracy: 0.8984, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  193/  468] time: 149.9119, train_loss: 0.35778511, train_accuracy: 0.9297, test_Accuracy: 0.9365\n",
            "Epoch: [ 0] [  194/  468] time: 150.4595, train_loss: 0.31586844, train_accuracy: 0.9609, test_Accuracy: 0.9378\n",
            "Epoch: [ 0] [  195/  468] time: 151.1693, train_loss: 0.38578349, train_accuracy: 0.9062, test_Accuracy: 0.9370\n",
            "Epoch: [ 0] [  196/  468] time: 151.8683, train_loss: 0.44308460, train_accuracy: 0.9219, test_Accuracy: 0.9364\n",
            "Epoch: [ 0] [  197/  468] time: 152.4045, train_loss: 0.47649032, train_accuracy: 0.9453, test_Accuracy: 0.9360\n",
            "Epoch: [ 0] [  198/  468] time: 153.1067, train_loss: 0.44003284, train_accuracy: 0.9375, test_Accuracy: 0.9359\n",
            "Epoch: [ 0] [  199/  468] time: 153.8120, train_loss: 0.34558237, train_accuracy: 0.9531, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [  200/  468] time: 154.5122, train_loss: 0.38001627, train_accuracy: 0.9219, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  201/  468] time: 155.2253, train_loss: 0.15232582, train_accuracy: 0.9766, test_Accuracy: 0.9383\n",
            "Epoch: [ 0] [  202/  468] time: 156.5934, train_loss: 0.29022029, train_accuracy: 0.9609, test_Accuracy: 0.9381\n",
            "Epoch: [ 0] [  203/  468] time: 157.9591, train_loss: 0.27872062, train_accuracy: 0.9766, test_Accuracy: 0.9375\n",
            "Epoch: [ 0] [  204/  468] time: 158.6848, train_loss: 0.25183111, train_accuracy: 0.9453, test_Accuracy: 0.9354\n",
            "Epoch: [ 0] [  205/  468] time: 159.4281, train_loss: 0.32905498, train_accuracy: 0.9297, test_Accuracy: 0.9349\n",
            "Epoch: [ 0] [  206/  468] time: 160.1288, train_loss: 0.51562482, train_accuracy: 0.9141, test_Accuracy: 0.9352\n",
            "Epoch: [ 0] [  207/  468] time: 161.5516, train_loss: 0.44448560, train_accuracy: 0.9141, test_Accuracy: 0.9360\n",
            "Epoch: [ 0] [  208/  468] time: 162.2522, train_loss: 0.33069047, train_accuracy: 0.9375, test_Accuracy: 0.9366\n",
            "Epoch: [ 0] [  209/  468] time: 163.6592, train_loss: 0.27603140, train_accuracy: 0.9375, test_Accuracy: 0.9346\n",
            "Epoch: [ 0] [  210/  468] time: 165.0017, train_loss: 0.28862327, train_accuracy: 0.9453, test_Accuracy: 0.9334\n",
            "Epoch: [ 0] [  211/  468] time: 166.3900, train_loss: 0.22553304, train_accuracy: 0.9375, test_Accuracy: 0.9329\n",
            "Epoch: [ 0] [  212/  468] time: 167.1803, train_loss: 0.49548844, train_accuracy: 0.8984, test_Accuracy: 0.9337\n",
            "Epoch: [ 0] [  213/  468] time: 167.8844, train_loss: 0.39635977, train_accuracy: 0.8984, test_Accuracy: 0.9349\n",
            "Epoch: [ 0] [  214/  468] time: 168.4200, train_loss: 0.33765608, train_accuracy: 0.9375, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  215/  468] time: 169.1300, train_loss: 0.35369635, train_accuracy: 0.9375, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  216/  468] time: 169.8308, train_loss: 0.32452789, train_accuracy: 0.9141, test_Accuracy: 0.9375\n",
            "Epoch: [ 0] [  217/  468] time: 170.5340, train_loss: 0.31054562, train_accuracy: 0.9453, test_Accuracy: 0.9369\n",
            "Epoch: [ 0] [  218/  468] time: 171.2065, train_loss: 0.38924637, train_accuracy: 0.8984, test_Accuracy: 0.9375\n",
            "Epoch: [ 0] [  219/  468] time: 171.9132, train_loss: 0.28954616, train_accuracy: 0.9375, test_Accuracy: 0.9365\n",
            "Epoch: [ 0] [  220/  468] time: 173.3121, train_loss: 0.35859302, train_accuracy: 0.8984, test_Accuracy: 0.9366\n",
            "Epoch: [ 0] [  221/  468] time: 174.0192, train_loss: 0.41935110, train_accuracy: 0.9453, test_Accuracy: 0.9365\n",
            "Epoch: [ 0] [  222/  468] time: 175.4419, train_loss: 0.27212065, train_accuracy: 0.9609, test_Accuracy: 0.9376\n",
            "Epoch: [ 0] [  223/  468] time: 176.8637, train_loss: 0.43933553, train_accuracy: 0.9219, test_Accuracy: 0.9376\n",
            "Epoch: [ 0] [  224/  468] time: 178.2698, train_loss: 0.47209617, train_accuracy: 0.9531, test_Accuracy: 0.9362\n",
            "Epoch: [ 0] [  225/  468] time: 178.9937, train_loss: 0.35153383, train_accuracy: 0.9219, test_Accuracy: 0.9349\n",
            "Epoch: [ 0] [  226/  468] time: 179.7061, train_loss: 0.35058555, train_accuracy: 0.9453, test_Accuracy: 0.9344\n",
            "Epoch: [ 0] [  227/  468] time: 180.4199, train_loss: 0.27809393, train_accuracy: 0.9453, test_Accuracy: 0.9341\n",
            "Epoch: [ 0] [  228/  468] time: 180.9529, train_loss: 0.23238410, train_accuracy: 0.9531, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  229/  468] time: 181.6543, train_loss: 0.26525062, train_accuracy: 0.9531, test_Accuracy: 0.9371\n",
            "Epoch: [ 0] [  230/  468] time: 183.0551, train_loss: 0.33082283, train_accuracy: 0.9375, test_Accuracy: 0.9377\n",
            "Epoch: [ 0] [  231/  468] time: 184.4642, train_loss: 0.29093218, train_accuracy: 0.9531, test_Accuracy: 0.9385\n",
            "Epoch: [ 0] [  232/  468] time: 185.1661, train_loss: 0.34436893, train_accuracy: 0.9297, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  233/  468] time: 186.5580, train_loss: 0.31923437, train_accuracy: 0.9375, test_Accuracy: 0.9390\n",
            "Epoch: [ 0] [  234/  468] time: 187.2551, train_loss: 0.22448534, train_accuracy: 0.9609, test_Accuracy: 0.9389\n",
            "Epoch: [ 0] [  235/  468] time: 187.9380, train_loss: 0.32064530, train_accuracy: 0.9609, test_Accuracy: 0.9402\n",
            "Epoch: [ 0] [  236/  468] time: 189.3399, train_loss: 0.27326620, train_accuracy: 0.9688, test_Accuracy: 0.9419\n",
            "Epoch: [ 0] [  237/  468] time: 190.1008, train_loss: 0.46741918, train_accuracy: 0.8984, test_Accuracy: 0.9422\n",
            "Epoch: [ 0] [  238/  468] time: 190.8071, train_loss: 0.24924716, train_accuracy: 0.9766, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  239/  468] time: 191.5059, train_loss: 0.38208231, train_accuracy: 0.9219, test_Accuracy: 0.9396\n",
            "Epoch: [ 0] [  240/  468] time: 192.2079, train_loss: 0.23860589, train_accuracy: 0.9375, test_Accuracy: 0.9390\n",
            "Epoch: [ 0] [  241/  468] time: 192.9054, train_loss: 0.17773736, train_accuracy: 0.9609, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  242/  468] time: 193.6091, train_loss: 0.43133068, train_accuracy: 0.8984, test_Accuracy: 0.9373\n",
            "Epoch: [ 0] [  243/  468] time: 194.1464, train_loss: 0.29502839, train_accuracy: 0.9609, test_Accuracy: 0.9363\n",
            "Epoch: [ 0] [  244/  468] time: 194.8526, train_loss: 0.40526375, train_accuracy: 0.9219, test_Accuracy: 0.9369\n",
            "Epoch: [ 0] [  245/  468] time: 195.5569, train_loss: 0.27244461, train_accuracy: 0.9688, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  246/  468] time: 196.2556, train_loss: 0.35888553, train_accuracy: 0.9531, test_Accuracy: 0.9416\n",
            "Epoch: [ 0] [  247/  468] time: 196.9644, train_loss: 0.33817750, train_accuracy: 0.9453, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  248/  468] time: 197.6710, train_loss: 0.22869283, train_accuracy: 0.9453, test_Accuracy: 0.9430\n",
            "Epoch: [ 0] [  249/  468] time: 198.3879, train_loss: 0.23260912, train_accuracy: 0.9375, test_Accuracy: 0.9428\n",
            "Epoch: [ 0] [  250/  468] time: 199.0946, train_loss: 0.20031580, train_accuracy: 0.9609, test_Accuracy: 0.9424\n",
            "Epoch: [ 0] [  251/  468] time: 199.8003, train_loss: 0.22000971, train_accuracy: 0.9766, test_Accuracy: 0.9401\n",
            "Epoch: [ 0] [  252/  468] time: 200.5076, train_loss: 0.30465311, train_accuracy: 0.9688, test_Accuracy: 0.9393\n",
            "Epoch: [ 0] [  253/  468] time: 201.0522, train_loss: 0.35057256, train_accuracy: 0.9531, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  254/  468] time: 201.7554, train_loss: 0.38595259, train_accuracy: 0.9062, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  255/  468] time: 202.3443, train_loss: 0.25583038, train_accuracy: 0.9375, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  256/  468] time: 203.0460, train_loss: 0.13291085, train_accuracy: 0.9688, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  257/  468] time: 203.7471, train_loss: 0.22392547, train_accuracy: 0.9531, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  258/  468] time: 204.4472, train_loss: 0.30011672, train_accuracy: 0.9453, test_Accuracy: 0.9415\n",
            "Epoch: [ 0] [  259/  468] time: 205.1558, train_loss: 0.28873804, train_accuracy: 0.9688, test_Accuracy: 0.9412\n",
            "Epoch: [ 0] [  260/  468] time: 205.8560, train_loss: 0.28503159, train_accuracy: 0.9531, test_Accuracy: 0.9408\n",
            "Epoch: [ 0] [  261/  468] time: 206.5572, train_loss: 0.20121610, train_accuracy: 0.9609, test_Accuracy: 0.9412\n",
            "Epoch: [ 0] [  262/  468] time: 207.2562, train_loss: 0.28671339, train_accuracy: 0.9844, test_Accuracy: 0.9409\n",
            "Epoch: [ 0] [  263/  468] time: 207.9601, train_loss: 0.34496844, train_accuracy: 0.9609, test_Accuracy: 0.9402\n",
            "Epoch: [ 0] [  264/  468] time: 208.6792, train_loss: 0.17702153, train_accuracy: 0.9688, test_Accuracy: 0.9394\n",
            "Epoch: [ 0] [  265/  468] time: 209.3786, train_loss: 0.33652663, train_accuracy: 0.9609, test_Accuracy: 0.9401\n",
            "Epoch: [ 0] [  266/  468] time: 210.0823, train_loss: 0.34691185, train_accuracy: 0.9453, test_Accuracy: 0.9414\n",
            "Epoch: [ 0] [  267/  468] time: 210.7832, train_loss: 0.21125410, train_accuracy: 0.9453, test_Accuracy: 0.9436\n",
            "Epoch: [ 0] [  268/  468] time: 211.4825, train_loss: 0.28335407, train_accuracy: 0.9531, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  269/  468] time: 212.1850, train_loss: 0.17696023, train_accuracy: 0.9844, test_Accuracy: 0.9448\n",
            "Epoch: [ 0] [  270/  468] time: 212.8902, train_loss: 0.18924209, train_accuracy: 0.9766, test_Accuracy: 0.9445\n",
            "Epoch: [ 0] [  271/  468] time: 213.5936, train_loss: 0.21630047, train_accuracy: 0.9531, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  272/  468] time: 214.3028, train_loss: 0.32559812, train_accuracy: 0.9609, test_Accuracy: 0.9445\n",
            "Epoch: [ 0] [  273/  468] time: 215.0085, train_loss: 0.22784020, train_accuracy: 0.9688, test_Accuracy: 0.9446\n",
            "Epoch: [ 0] [  274/  468] time: 215.7122, train_loss: 0.30875158, train_accuracy: 0.9531, test_Accuracy: 0.9454\n",
            "Epoch: [ 0] [  275/  468] time: 216.2769, train_loss: 0.35089406, train_accuracy: 0.9531, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  276/  468] time: 216.9779, train_loss: 0.26115495, train_accuracy: 0.9297, test_Accuracy: 0.9451\n",
            "Epoch: [ 0] [  277/  468] time: 217.6848, train_loss: 0.34926236, train_accuracy: 0.9531, test_Accuracy: 0.9461\n",
            "Epoch: [ 0] [  278/  468] time: 218.2068, train_loss: 0.45808750, train_accuracy: 0.9375, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  279/  468] time: 218.7463, train_loss: 0.34020281, train_accuracy: 0.9453, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  280/  468] time: 219.4428, train_loss: 0.25119823, train_accuracy: 0.9453, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  281/  468] time: 220.1420, train_loss: 0.33018401, train_accuracy: 0.9375, test_Accuracy: 0.9438\n",
            "Epoch: [ 0] [  282/  468] time: 220.8394, train_loss: 0.26921761, train_accuracy: 0.9453, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  283/  468] time: 221.5438, train_loss: 0.25046742, train_accuracy: 0.9609, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  284/  468] time: 222.2443, train_loss: 0.26459029, train_accuracy: 0.9688, test_Accuracy: 0.9461\n",
            "Epoch: [ 0] [  285/  468] time: 222.9453, train_loss: 0.39106494, train_accuracy: 0.9453, test_Accuracy: 0.9472\n",
            "Epoch: [ 0] [  286/  468] time: 223.6463, train_loss: 0.30217427, train_accuracy: 0.8984, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  287/  468] time: 224.3549, train_loss: 0.22183582, train_accuracy: 0.9219, test_Accuracy: 0.9467\n",
            "Epoch: [ 0] [  288/  468] time: 225.0711, train_loss: 0.21748069, train_accuracy: 0.9453, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  289/  468] time: 225.7781, train_loss: 0.28660858, train_accuracy: 0.9609, test_Accuracy: 0.9464\n",
            "Epoch: [ 0] [  290/  468] time: 226.4762, train_loss: 0.36200523, train_accuracy: 0.9297, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  291/  468] time: 227.1798, train_loss: 0.22615975, train_accuracy: 0.9688, test_Accuracy: 0.9465\n",
            "Epoch: [ 0] [  292/  468] time: 227.8795, train_loss: 0.31969300, train_accuracy: 0.9375, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  293/  468] time: 228.5807, train_loss: 0.34691873, train_accuracy: 0.9609, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  294/  468] time: 229.2800, train_loss: 0.30770040, train_accuracy: 0.9453, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  295/  468] time: 229.9810, train_loss: 0.34433272, train_accuracy: 0.9453, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  296/  468] time: 230.6841, train_loss: 0.27367437, train_accuracy: 0.9453, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  297/  468] time: 231.3862, train_loss: 0.34839967, train_accuracy: 0.9375, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  298/  468] time: 231.9792, train_loss: 0.25504550, train_accuracy: 0.9688, test_Accuracy: 0.9475\n",
            "Epoch: [ 0] [  299/  468] time: 233.4543, train_loss: 0.24719009, train_accuracy: 0.9375, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  300/  468] time: 234.6932, train_loss: 0.29825237, train_accuracy: 0.9219, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  301/  468] time: 235.4952, train_loss: 0.47206336, train_accuracy: 0.8984, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  302/  468] time: 236.8925, train_loss: 0.26908636, train_accuracy: 0.9609, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  303/  468] time: 237.5980, train_loss: 0.19649476, train_accuracy: 0.9453, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  304/  468] time: 238.3092, train_loss: 0.36241508, train_accuracy: 0.9297, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  305/  468] time: 239.0087, train_loss: 0.18082449, train_accuracy: 0.9688, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  306/  468] time: 239.7147, train_loss: 0.37433019, train_accuracy: 0.9219, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  307/  468] time: 240.4157, train_loss: 0.22425321, train_accuracy: 0.9531, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  308/  468] time: 241.7657, train_loss: 0.23613298, train_accuracy: 0.9766, test_Accuracy: 0.9461\n",
            "Epoch: [ 0] [  309/  468] time: 243.1760, train_loss: 0.46559054, train_accuracy: 0.9453, test_Accuracy: 0.9449\n",
            "Epoch: [ 0] [  310/  468] time: 243.8790, train_loss: 0.47045863, train_accuracy: 0.9062, test_Accuracy: 0.9448\n",
            "Epoch: [ 0] [  311/  468] time: 244.5782, train_loss: 0.53992051, train_accuracy: 0.8984, test_Accuracy: 0.9446\n",
            "Epoch: [ 0] [  312/  468] time: 245.2850, train_loss: 0.28585634, train_accuracy: 0.9453, test_Accuracy: 0.9438\n",
            "Epoch: [ 0] [  313/  468] time: 245.9896, train_loss: 0.22461209, train_accuracy: 0.9609, test_Accuracy: 0.9428\n",
            "Epoch: [ 0] [  314/  468] time: 246.5322, train_loss: 0.28689539, train_accuracy: 0.9609, test_Accuracy: 0.9425\n",
            "Epoch: [ 0] [  315/  468] time: 247.2331, train_loss: 0.22181037, train_accuracy: 0.9453, test_Accuracy: 0.9428\n",
            "Epoch: [ 0] [  316/  468] time: 247.9334, train_loss: 0.43144932, train_accuracy: 0.9219, test_Accuracy: 0.9442\n",
            "Epoch: [ 0] [  317/  468] time: 248.6370, train_loss: 0.45047450, train_accuracy: 0.9219, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  318/  468] time: 249.3367, train_loss: 0.30529284, train_accuracy: 0.9609, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  319/  468] time: 250.1147, train_loss: 0.27362567, train_accuracy: 0.9453, test_Accuracy: 0.9467\n",
            "Epoch: [ 0] [  320/  468] time: 251.5055, train_loss: 0.22949620, train_accuracy: 0.9453, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  321/  468] time: 252.9248, train_loss: 0.33303869, train_accuracy: 0.9219, test_Accuracy: 0.9455\n",
            "Epoch: [ 0] [  322/  468] time: 253.6397, train_loss: 0.33499980, train_accuracy: 0.9688, test_Accuracy: 0.9437\n",
            "Epoch: [ 0] [  323/  468] time: 254.4850, train_loss: 0.31990814, train_accuracy: 0.9375, test_Accuracy: 0.9423\n",
            "Epoch: [ 0] [  324/  468] time: 255.2593, train_loss: 0.24657124, train_accuracy: 0.9297, test_Accuracy: 0.9427\n",
            "Epoch: [ 0] [  325/  468] time: 255.9758, train_loss: 0.35665527, train_accuracy: 0.9375, test_Accuracy: 0.9424\n",
            "Epoch: [ 0] [  326/  468] time: 256.6765, train_loss: 0.24223207, train_accuracy: 0.9531, test_Accuracy: 0.9434\n",
            "Epoch: [ 0] [  327/  468] time: 257.3780, train_loss: 0.33268249, train_accuracy: 0.9688, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  328/  468] time: 258.0814, train_loss: 0.31289798, train_accuracy: 0.9297, test_Accuracy: 0.9440\n",
            "Epoch: [ 0] [  329/  468] time: 258.7859, train_loss: 0.33618331, train_accuracy: 0.9531, test_Accuracy: 0.9446\n",
            "Epoch: [ 0] [  330/  468] time: 259.4862, train_loss: 0.31703413, train_accuracy: 0.9453, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  331/  468] time: 260.0142, train_loss: 0.36661959, train_accuracy: 0.9609, test_Accuracy: 0.9461\n",
            "Epoch: [ 0] [  332/  468] time: 260.5591, train_loss: 0.30596170, train_accuracy: 0.9609, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  333/  468] time: 261.2597, train_loss: 0.20833108, train_accuracy: 0.9531, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  334/  468] time: 261.9629, train_loss: 0.28104925, train_accuracy: 0.9453, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  335/  468] time: 262.6626, train_loss: 0.22935921, train_accuracy: 0.9609, test_Accuracy: 0.9459\n",
            "Epoch: [ 0] [  336/  468] time: 263.3617, train_loss: 0.36034948, train_accuracy: 0.9219, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  337/  468] time: 264.0688, train_loss: 0.58030462, train_accuracy: 0.9141, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  338/  468] time: 264.6148, train_loss: 0.23466735, train_accuracy: 0.9688, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  339/  468] time: 265.3202, train_loss: 0.31669176, train_accuracy: 0.9531, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  340/  468] time: 266.0305, train_loss: 0.48259667, train_accuracy: 0.9297, test_Accuracy: 0.9490\n",
            "Epoch: [ 0] [  341/  468] time: 266.7319, train_loss: 0.25539792, train_accuracy: 0.9609, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  342/  468] time: 267.4368, train_loss: 0.24561448, train_accuracy: 0.9453, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  343/  468] time: 267.9751, train_loss: 0.15227303, train_accuracy: 0.9609, test_Accuracy: 0.9490\n",
            "Epoch: [ 0] [  344/  468] time: 268.6823, train_loss: 0.20320411, train_accuracy: 0.9688, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  345/  468] time: 269.3854, train_loss: 0.14819548, train_accuracy: 0.9766, test_Accuracy: 0.9488\n",
            "Epoch: [ 0] [  346/  468] time: 270.0903, train_loss: 0.08800314, train_accuracy: 0.9922, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  347/  468] time: 270.7978, train_loss: 0.27448717, train_accuracy: 0.9453, test_Accuracy: 0.9496\n",
            "Epoch: [ 0] [  348/  468] time: 271.4965, train_loss: 0.45731014, train_accuracy: 0.9375, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  349/  468] time: 272.0230, train_loss: 0.24191421, train_accuracy: 0.9688, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  350/  468] time: 272.5423, train_loss: 0.21674228, train_accuracy: 0.9609, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  351/  468] time: 273.0843, train_loss: 0.24284795, train_accuracy: 0.9609, test_Accuracy: 0.9481\n",
            "Epoch: [ 0] [  352/  468] time: 273.7871, train_loss: 0.29523081, train_accuracy: 0.9297, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  353/  468] time: 274.4872, train_loss: 0.19525267, train_accuracy: 0.9531, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  354/  468] time: 275.1853, train_loss: 0.36719054, train_accuracy: 0.9219, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  355/  468] time: 275.8854, train_loss: 0.20577088, train_accuracy: 0.9766, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  356/  468] time: 276.5845, train_loss: 0.29857236, train_accuracy: 0.9609, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  357/  468] time: 277.2901, train_loss: 0.38153058, train_accuracy: 0.8984, test_Accuracy: 0.9500\n",
            "Epoch: [ 0] [  358/  468] time: 277.9907, train_loss: 0.43352073, train_accuracy: 0.9219, test_Accuracy: 0.9500\n",
            "Epoch: [ 0] [  359/  468] time: 278.6904, train_loss: 0.21759607, train_accuracy: 0.9766, test_Accuracy: 0.9491\n",
            "Epoch: [ 0] [  360/  468] time: 279.3930, train_loss: 0.21843305, train_accuracy: 0.9609, test_Accuracy: 0.9471\n",
            "Epoch: [ 0] [  361/  468] time: 280.0948, train_loss: 0.49098146, train_accuracy: 0.8984, test_Accuracy: 0.9445\n",
            "Epoch: [ 0] [  362/  468] time: 280.7993, train_loss: 0.22556877, train_accuracy: 0.9922, test_Accuracy: 0.9433\n",
            "Epoch: [ 0] [  363/  468] time: 281.5001, train_loss: 0.20192578, train_accuracy: 0.9531, test_Accuracy: 0.9423\n",
            "Epoch: [ 0] [  364/  468] time: 282.0323, train_loss: 0.27875277, train_accuracy: 0.9531, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  365/  468] time: 282.7358, train_loss: 0.32901049, train_accuracy: 0.9375, test_Accuracy: 0.9434\n",
            "Epoch: [ 0] [  366/  468] time: 283.4348, train_loss: 0.24447894, train_accuracy: 0.9531, test_Accuracy: 0.9444\n",
            "Epoch: [ 0] [  367/  468] time: 284.1337, train_loss: 0.21373428, train_accuracy: 0.9688, test_Accuracy: 0.9457\n",
            "Epoch: [ 0] [  368/  468] time: 284.8411, train_loss: 0.29656941, train_accuracy: 0.9531, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  369/  468] time: 285.5402, train_loss: 0.17848498, train_accuracy: 0.9453, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  370/  468] time: 286.2362, train_loss: 0.39869475, train_accuracy: 0.9297, test_Accuracy: 0.9472\n",
            "Epoch: [ 0] [  371/  468] time: 286.9380, train_loss: 0.34338188, train_accuracy: 0.9375, test_Accuracy: 0.9487\n",
            "Epoch: [ 0] [  372/  468] time: 287.6398, train_loss: 0.25758097, train_accuracy: 0.9219, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  373/  468] time: 288.3421, train_loss: 0.20436350, train_accuracy: 0.9609, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  374/  468] time: 289.0502, train_loss: 0.17464590, train_accuracy: 0.9531, test_Accuracy: 0.9490\n",
            "Epoch: [ 0] [  375/  468] time: 289.7647, train_loss: 0.23768784, train_accuracy: 0.9531, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  376/  468] time: 290.4612, train_loss: 0.31767958, train_accuracy: 0.9141, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  377/  468] time: 291.1698, train_loss: 0.23347566, train_accuracy: 0.9688, test_Accuracy: 0.9467\n",
            "Epoch: [ 0] [  378/  468] time: 292.5603, train_loss: 0.27930564, train_accuracy: 0.9297, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  379/  468] time: 293.9573, train_loss: 0.43039048, train_accuracy: 0.9219, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  380/  468] time: 294.6587, train_loss: 0.23162270, train_accuracy: 0.9609, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  381/  468] time: 295.3662, train_loss: 0.22988300, train_accuracy: 0.9688, test_Accuracy: 0.9473\n",
            "Epoch: [ 0] [  382/  468] time: 296.0697, train_loss: 0.24917036, train_accuracy: 0.9766, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  383/  468] time: 297.4962, train_loss: 0.27822384, train_accuracy: 0.9531, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  384/  468] time: 298.2018, train_loss: 0.22538713, train_accuracy: 0.9531, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  385/  468] time: 299.6069, train_loss: 0.33485636, train_accuracy: 0.9453, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  386/  468] time: 300.3208, train_loss: 0.26584029, train_accuracy: 0.9688, test_Accuracy: 0.9493\n",
            "Epoch: [ 0] [  387/  468] time: 301.1697, train_loss: 0.44571194, train_accuracy: 0.9375, test_Accuracy: 0.9507\n",
            "Epoch: [ 0] [  388/  468] time: 301.9931, train_loss: 0.20527861, train_accuracy: 0.9375, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  389/  468] time: 303.4045, train_loss: 0.32660949, train_accuracy: 0.9219, test_Accuracy: 0.9509\n",
            "Epoch: [ 0] [  390/  468] time: 304.1077, train_loss: 0.30290452, train_accuracy: 0.9453, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  391/  468] time: 304.8116, train_loss: 0.23213431, train_accuracy: 0.8984, test_Accuracy: 0.9511\n",
            "Epoch: [ 0] [  392/  468] time: 305.5101, train_loss: 0.26967746, train_accuracy: 0.9297, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  393/  468] time: 306.2270, train_loss: 0.17256561, train_accuracy: 0.9609, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  394/  468] time: 307.5736, train_loss: 0.17611615, train_accuracy: 0.9766, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  395/  468] time: 308.9842, train_loss: 0.20328917, train_accuracy: 0.9531, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  396/  468] time: 309.6896, train_loss: 0.27099538, train_accuracy: 0.9531, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  397/  468] time: 310.3931, train_loss: 0.28059059, train_accuracy: 0.9531, test_Accuracy: 0.9451\n",
            "Epoch: [ 0] [  398/  468] time: 311.0968, train_loss: 0.25703862, train_accuracy: 0.9766, test_Accuracy: 0.9464\n",
            "Epoch: [ 0] [  399/  468] time: 311.6243, train_loss: 0.42218202, train_accuracy: 0.9219, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  400/  468] time: 312.3332, train_loss: 0.38649821, train_accuracy: 0.9297, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  401/  468] time: 313.0381, train_loss: 0.24012873, train_accuracy: 0.9531, test_Accuracy: 0.9530\n",
            "Epoch: [ 0] [  402/  468] time: 313.7412, train_loss: 0.24810374, train_accuracy: 0.9609, test_Accuracy: 0.9543\n",
            "Epoch: [ 0] [  403/  468] time: 314.4553, train_loss: 0.24090040, train_accuracy: 0.9375, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  404/  468] time: 315.8732, train_loss: 0.37118894, train_accuracy: 0.9297, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  405/  468] time: 316.4079, train_loss: 0.50870645, train_accuracy: 0.9141, test_Accuracy: 0.9503\n",
            "Epoch: [ 0] [  406/  468] time: 317.1097, train_loss: 0.28199071, train_accuracy: 0.9219, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  407/  468] time: 317.8155, train_loss: 0.28412938, train_accuracy: 0.9453, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  408/  468] time: 318.5261, train_loss: 0.42361864, train_accuracy: 0.9375, test_Accuracy: 0.9459\n",
            "Epoch: [ 0] [  409/  468] time: 319.2328, train_loss: 0.24892233, train_accuracy: 0.9609, test_Accuracy: 0.9472\n",
            "Epoch: [ 0] [  410/  468] time: 319.9339, train_loss: 0.23002070, train_accuracy: 0.9531, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  411/  468] time: 320.6462, train_loss: 0.24543297, train_accuracy: 0.9453, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  412/  468] time: 321.9956, train_loss: 0.30882022, train_accuracy: 0.9531, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  413/  468] time: 322.7019, train_loss: 0.36538801, train_accuracy: 0.9453, test_Accuracy: 0.9508\n",
            "Epoch: [ 0] [  414/  468] time: 323.2375, train_loss: 0.14533681, train_accuracy: 0.9844, test_Accuracy: 0.9514\n",
            "Epoch: [ 0] [  415/  468] time: 323.9408, train_loss: 0.31805190, train_accuracy: 0.9375, test_Accuracy: 0.9516\n",
            "Epoch: [ 0] [  416/  468] time: 324.6532, train_loss: 0.23578283, train_accuracy: 0.9688, test_Accuracy: 0.9519\n",
            "Epoch: [ 0] [  417/  468] time: 325.3575, train_loss: 0.17044428, train_accuracy: 0.9766, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  418/  468] time: 326.0600, train_loss: 0.13118511, train_accuracy: 0.9688, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  419/  468] time: 326.7720, train_loss: 0.16863576, train_accuracy: 0.9609, test_Accuracy: 0.9488\n",
            "Epoch: [ 0] [  420/  468] time: 327.4720, train_loss: 0.17181426, train_accuracy: 0.9531, test_Accuracy: 0.9491\n",
            "Epoch: [ 0] [  421/  468] time: 328.1775, train_loss: 0.21486092, train_accuracy: 0.9688, test_Accuracy: 0.9493\n",
            "Epoch: [ 0] [  422/  468] time: 328.8871, train_loss: 0.23732872, train_accuracy: 0.9688, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  423/  468] time: 329.5880, train_loss: 0.34924048, train_accuracy: 0.9141, test_Accuracy: 0.9496\n",
            "Epoch: [ 0] [  424/  468] time: 330.2898, train_loss: 0.26025549, train_accuracy: 0.9766, test_Accuracy: 0.9494\n",
            "Epoch: [ 0] [  425/  468] time: 330.9922, train_loss: 0.29900751, train_accuracy: 0.9453, test_Accuracy: 0.9497\n",
            "Epoch: [ 0] [  426/  468] time: 331.6913, train_loss: 0.39319879, train_accuracy: 0.8984, test_Accuracy: 0.9506\n",
            "Epoch: [ 0] [  427/  468] time: 332.3926, train_loss: 0.16035712, train_accuracy: 0.9609, test_Accuracy: 0.9518\n",
            "Epoch: [ 0] [  428/  468] time: 333.0972, train_loss: 0.40402836, train_accuracy: 0.9219, test_Accuracy: 0.9500\n",
            "Epoch: [ 0] [  429/  468] time: 333.8032, train_loss: 0.27746841, train_accuracy: 0.9375, test_Accuracy: 0.9486\n",
            "Epoch: [ 0] [  430/  468] time: 334.5069, train_loss: 0.39184129, train_accuracy: 0.9141, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  431/  468] time: 335.2184, train_loss: 0.25502884, train_accuracy: 0.9375, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  432/  468] time: 335.9323, train_loss: 0.24758822, train_accuracy: 0.9531, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  433/  468] time: 336.6410, train_loss: 0.13596526, train_accuracy: 0.9766, test_Accuracy: 0.9482\n",
            "Epoch: [ 0] [  434/  468] time: 337.9905, train_loss: 0.28488892, train_accuracy: 0.9609, test_Accuracy: 0.9493\n",
            "Epoch: [ 0] [  435/  468] time: 338.6908, train_loss: 0.22888747, train_accuracy: 0.9609, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  436/  468] time: 340.0647, train_loss: 0.32120204, train_accuracy: 0.9453, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  437/  468] time: 341.4705, train_loss: 0.20034820, train_accuracy: 0.9609, test_Accuracy: 0.9529\n",
            "Epoch: [ 0] [  438/  468] time: 342.1738, train_loss: 0.24392419, train_accuracy: 0.9609, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  439/  468] time: 342.8759, train_loss: 0.23197037, train_accuracy: 0.9453, test_Accuracy: 0.9515\n",
            "Epoch: [ 0] [  440/  468] time: 343.4037, train_loss: 0.28702673, train_accuracy: 0.9375, test_Accuracy: 0.9529\n",
            "Epoch: [ 0] [  441/  468] time: 344.1190, train_loss: 0.25346306, train_accuracy: 0.9375, test_Accuracy: 0.9536\n",
            "Epoch: [ 0] [  442/  468] time: 344.8261, train_loss: 0.22557051, train_accuracy: 0.9375, test_Accuracy: 0.9538\n",
            "Epoch: [ 0] [  443/  468] time: 345.5310, train_loss: 0.16252954, train_accuracy: 0.9766, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  444/  468] time: 346.2366, train_loss: 0.26540872, train_accuracy: 0.9219, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  445/  468] time: 346.9434, train_loss: 0.27961665, train_accuracy: 0.9297, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  446/  468] time: 347.6546, train_loss: 0.16142163, train_accuracy: 0.9766, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  447/  468] time: 348.3640, train_loss: 0.16772568, train_accuracy: 0.9844, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  448/  468] time: 349.8052, train_loss: 0.31461042, train_accuracy: 0.9375, test_Accuracy: 0.9556\n",
            "Epoch: [ 0] [  449/  468] time: 351.2256, train_loss: 0.21305534, train_accuracy: 0.9375, test_Accuracy: 0.9551\n",
            "Epoch: [ 0] [  450/  468] time: 351.9623, train_loss: 0.16676307, train_accuracy: 0.9766, test_Accuracy: 0.9557\n",
            "Epoch: [ 0] [  451/  468] time: 352.6716, train_loss: 0.24554220, train_accuracy: 0.9531, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  452/  468] time: 353.3743, train_loss: 0.17808229, train_accuracy: 0.9453, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  453/  468] time: 354.0780, train_loss: 0.39674997, train_accuracy: 0.9219, test_Accuracy: 0.9538\n",
            "Epoch: [ 0] [  454/  468] time: 354.7794, train_loss: 0.29247534, train_accuracy: 0.9531, test_Accuracy: 0.9545\n",
            "Epoch: [ 0] [  455/  468] time: 355.3203, train_loss: 0.24002454, train_accuracy: 0.9375, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  456/  468] time: 356.0186, train_loss: 0.26441899, train_accuracy: 0.9531, test_Accuracy: 0.9534\n",
            "Epoch: [ 0] [  457/  468] time: 356.7220, train_loss: 0.23563477, train_accuracy: 0.9531, test_Accuracy: 0.9534\n",
            "Epoch: [ 0] [  458/  468] time: 357.2544, train_loss: 0.12604724, train_accuracy: 0.9844, test_Accuracy: 0.9527\n",
            "Epoch: [ 0] [  459/  468] time: 357.9676, train_loss: 0.24082103, train_accuracy: 0.9531, test_Accuracy: 0.9515\n",
            "Epoch: [ 0] [  460/  468] time: 358.6750, train_loss: 0.25918895, train_accuracy: 0.9609, test_Accuracy: 0.9515\n",
            "Epoch: [ 0] [  461/  468] time: 359.3787, train_loss: 0.19497046, train_accuracy: 0.9766, test_Accuracy: 0.9518\n",
            "Epoch: [ 0] [  462/  468] time: 360.0843, train_loss: 0.32171744, train_accuracy: 0.9219, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  463/  468] time: 360.7922, train_loss: 0.36894259, train_accuracy: 0.9297, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  464/  468] time: 361.4949, train_loss: 0.15646607, train_accuracy: 0.9609, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  465/  468] time: 362.0388, train_loss: 0.13743781, train_accuracy: 0.9844, test_Accuracy: 0.9560\n",
            "Epoch: [ 0] [  466/  468] time: 362.7433, train_loss: 0.25602680, train_accuracy: 0.9609, test_Accuracy: 0.9573\n",
            "Epoch: [ 0] [  467/  468] time: 363.4481, train_loss: 0.30584377, train_accuracy: 0.9609, test_Accuracy: 0.9587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Normalization\n",
        "- network가 있을 때, input으로 들어온 데이터의 분포는 뉴런을 지날수록 변형됨 -> 학습이 덜 됨, Internal Covariate Shift\n",
        "- $$ \\bar x = \\frac{x-\\mu_B}{\\sqrt {\\sigma_B^2} + \\epsilon } $$\n",
        "- $$ \\hat x = y\\bar x + \\beta $$"
      ],
      "metadata": {
        "id": "YxwrqHh9VIyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint function"
      ],
      "metadata": {
        "id": "Q5EllYJBYg3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(model, checkpoint_dir):\n",
        "    print(\" [*] Reading checkpoints...\")\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "    if ckpt :\n",
        "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "        checkpoint = tf.train.Checkpoint(dnn=model)\n",
        "        checkpoint.restore(save_path=os.path.join(checkpoint_dir, ckpt_name))\n",
        "        counter = int(ckpt_name.split('-')[1])\n",
        "        print(\" [*] Success to read {}\".format(ckpt_name))\n",
        "        return True, counter\n",
        "    else:\n",
        "        print(\" [*] Failed to find a checkpoint\")\n",
        "        return False, 0\n",
        "\n",
        "def check_folder(dir):\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "    return dir"
      ],
      "metadata": {
        "id": "2nJ2mciaYitL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create network"
      ],
      "metadata": {
        "id": "m-ZsQRHqW-UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten() :\n",
        "    return tf.keras.layers.Flatten()\n",
        "\n",
        "def dense(label_dim, weight_init) :\n",
        "    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n",
        "\n",
        "def relu() :\n",
        "    return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
        "\n",
        "def batch_norm() :\n",
        "    return tf.keras.layers.BatchNormalization()"
      ],
      "metadata": {
        "id": "lQsX2Y37XKpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model - class"
      ],
      "metadata": {
        "id": "V82qUXgvXXN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class create_model_class(tf.keras.Model):\n",
        "    def __init__(self, label_dim):\n",
        "        super(create_model_class, self).__init__()\n",
        "        weight_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(flatten())\n",
        "        \n",
        "        # 순서는 layer - norm - activation or norm - activation - layer\n",
        "        for i in range(4):\n",
        "            self.model.add(dense(512, weight_init))\n",
        "            self.model.add(batch_norm())\n",
        "            self.model.add(relu())\n",
        "\n",
        "        self.model.add(dense(label_dim, weight_init))\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "VDt074sYXTxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model - function"
      ],
      "metadata": {
        "id": "lIro0s_IXZNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_function(label_dim) :\n",
        "    weight_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(flatten())\n",
        "\n",
        "    for i in range(4) :\n",
        "        model.add(dense(512, weight_init))\n",
        "        model.add(batch_norm())\n",
        "        model.add(relu())\n",
        "\n",
        "    model.add(dense(label_dim, weight_init))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4ratFdI8Xa9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define model & optimizer & writer"
      ],
      "metadata": {
        "id": "sISXRaWSYJb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Model \"\"\"\n",
        "network = create_model_function(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "\"\"\" Writer \"\"\"\n",
        "checkpoint_dir = 'checkpoints'\n",
        "logs_dir = 'logs'\n",
        "\n",
        "model_dir = 'nn_dropout'\n",
        "\n",
        "checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "check_folder(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n",
        "logs_dir = os.path.join(logs_dir, model_dir)"
      ],
      "metadata": {
        "id": "wBDFnJrDYJb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restore checkpoint & start train or test phase"
      ],
      "metadata": {
        "id": "cov7SAguXd80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if train_flag :\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(dnn=network)\n",
        "\n",
        "    # create writer for tensorboard\n",
        "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
        "    start_time = time()\n",
        "\n",
        "    # restore check-point if it exits\n",
        "    could_load, checkpoint_counter = load(network, checkpoint_dir)    \n",
        "\n",
        "    if could_load:\n",
        "        start_epoch = (int)(checkpoint_counter / training_iterations)        \n",
        "        counter = checkpoint_counter        \n",
        "        print(\" [*] Load SUCCESS\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        start_iteration = 0\n",
        "        counter = 0\n",
        "        print(\" [!] Load failed...\")\n",
        "    \n",
        "    # train phase\n",
        "    with summary_writer.as_default():  # for tensorboard\n",
        "        for epoch in range(start_epoch, training_epochs):\n",
        "            for idx, (train_input, train_label) in enumerate(train_dataset):            \n",
        "                grads = grad(network, train_input, train_label)\n",
        "                optimizer.apply_gradients(grads_and_vars=zip(grads, network.trainable_variables))\n",
        "\n",
        "                train_loss = loss_fn(network, train_input, train_label)\n",
        "                train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "                \n",
        "                for test_input, test_label in test_dataset:                \n",
        "                    test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n",
        "                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n",
        "                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n",
        "\n",
        "                print(\n",
        "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
        "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
        "                       test_accuracy))\n",
        "                counter += 1                \n",
        "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
        "        \n",
        "# test phase      \n",
        "else :\n",
        "    _, _ = load(network, checkpoint_dir)\n",
        "    for test_input, test_label in test_dataset:    \n",
        "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GrK0ptzXxLH",
        "outputId": "8c8f7fda-5307-4fa1-fba2-bf1075713778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Reading checkpoints...\n",
            " [*] Success to read nn_dropout-468-1\n",
            " [*] Load SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConvNet의 Conv 레이어 만들기\n",
        "## history\n",
        "- 고양이 실험에서 시작\n",
        "- 고양이는 각각 뉴런이 이미지의 어떤 형태의 부분에서만 반응함\n",
        "\n",
        "## 방법\n",
        "- 이미지를 잘라서 Conv에 넣음\n",
        "- Relu 함수 층을 넣음\n",
        "- 여러번 할 수 있음\n",
        "- 중간에 한 번씩 Polling을 함\n",
        "- 마지막으로 FC를 붙임\n",
        "\n",
        "## Start with an image (width * hight * depth)\n",
        "- filter를 이용하여 이미지를 부분적으로 처리\n",
        "- depth는 원본과 filter가 같아야 함\n",
        "- filter는 값 하나를 만들어 냄\n",
        "  - $$ Wx + b = ReLU(Wx+b)$$\n",
        "- filter를 이동시키면서 전체 이미지를 처리\n",
        "- 몇 개의 number가 나올까?\n",
        "  - output size: (N-F) / stride + 1\n",
        "- 움직이는 간격을 stride라고 부름\n",
        "\n",
        "## padding\n",
        "- 테두리에 가상의 입력을 만들어 주는 것\n",
        "- 그림이 작아지는 것을 방지하기 위해\n",
        "- 모서리임을 알려주기 위해\n",
        "- 입력의 이미지와 출력의 이미지가 같아지기 위해 사용\n",
        "\n",
        "## Convolution layer\n",
        "- Convolution layer를 사용하면 깊이가 깊어짐\n"
      ],
      "metadata": {
        "id": "8Cl1uWJ4FojI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConvNet Max pooling과 Full Network\n",
        "## Pooling\n",
        "- sampling이라고 봄\n",
        "- convolution layer에서 한 레이어만 뽑아내서 resize함\n",
        "- 각각의 한 레이어씩 반복\n",
        "\n",
        "## Max Pooling\n",
        "- poll filter가 2X3고 stride가 2이면\n",
        "  - 4개의 필터가 생김\n",
        "  - 2X2의 output\n",
        "  - 한 필터에 있는 값 중에서 가장 큰 값을 고르는 것\n",
        "- 전체의 값들 중에 하나만 뽑아서 sampling이라고도 부름\n",
        "\n",
        "## Fully Connected Layer\n"
      ],
      "metadata": {
        "id": "X-Ejvu_tJ1QE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conv net의 활용 예\n",
        "## LeNet-5\n",
        "- input이 주어지고 각각의 convolution에 5*5, stride 1을 사용\n",
        "\n",
        "## AlexNet\n",
        "- Image net 경진대회에서 1등\n",
        "- color image를 입력받음\n",
        "- 첫번째 레이어에서 96개의 필터 사용, stride 4\n",
        "- 두번째 레이어에서 3*3 필터, stride 2\n",
        "- 계속해서 이어짐\n",
        "- Nomalization layer: 값들을 Nomalition 하는 것, 최근 들어서는 잘 사용되지 않음\n",
        "- ReLU를 처음 사용\n",
        "\n",
        "## GoogLeNet\n",
        "- 2014의 1등\n",
        "- Inception module: 입력이 들어가고 1X1 convolution, 3X3 pooling을 함\n",
        "- Inception module을 deep하게 연결\n",
        "\n",
        "## ResNet\n",
        "- 152개 layer 사용\n",
        "- layer가 깊어지면 학습이 어려움\n",
        "  - 중간의 값을 jump 시키는 Residual net을 사용\n",
        "  - 실제 학습할때는 깊지 않은 것처럼 학습할 수 있음\n",
        "\n"
      ],
      "metadata": {
        "id": "2QYFxatrLI4G"
      }
    }
  ]
}