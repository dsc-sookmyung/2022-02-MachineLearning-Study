{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqNyBAAj8KmO"
      },
      "source": [
        "# 11-0-1 CNN basics convolution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es9jFNvGfAYS",
        "outputId": "a48906a4-41f6-4e38-a734-ee595263612d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "zifh_a4HfG7h",
        "outputId": "3b4b3466-6ffc-46d0-e23a-df42c4d3b152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image.shape (1, 3, 3, 1)\n",
            "weight.shape (2, 2, 1, 1)\n",
            "conv2d.shape (1, 2, 2, 1)\n",
            "[[12. 16.]\n",
            " [24. 28.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAD8CAYAAABZ0jAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPiklEQVR4nO3df6xfdX3H8edrIJCMrRS6lQZdgUhQjFr0Bn9gpE4E5I9CIpkl2ywLpNPJlmhchJCowS1D9weLmU4b7ESzQSebWjeYq1TiEi163YBKHbTUZVJRHMUqAZHie398T5Oz6723t/d++H7v9+b5SG6+55zP+Xzv+6Twyvme8z33napCklr5lVEXIGlpMVQkNWWoSGrKUJHUlKEiqSlDRVJTCwqVJCcm2ZZkd/e6fIb9nk1yT/eztbf9tCR3J9mTZEuSYxZSj6TRW+iZyjXAnVV1BnBntz6dp6pqTfezrrf9Q8CNVfVC4HHgygXWI2nEspAvvyV5AFhbVY8kWQXcVVVnTrPfE1V1/JRtAX4EnFxVB5O8BvhAVV0474IkjdzRC5y/sqoe6ZZ/AKycYb/jkkwCB4EbqurzwEnAj6vqYLfPw8ApM/2iJBuBjd3qKxdYt4bs+OOPP/xOWjR+9rOf8cwzz2Q+cw8bKkm+DJw8zdB1/ZWqqiQznfasrqp9SU4HtifZCRw4kkKrahOwqavJZwvGzMTExKhL0BGYnJyc99zDhkpVnT/TWJIfJlnV+/jz6Azvsa973ZvkLuBs4B+BE5Ic3Z2tPB/YN49jkLSILPRC7VZgQ7e8AfjC1B2SLE9ybLe8AjgX2FWDizlfAS6bbb6k8bLQULkBeFOS3cD53TpJJpLc1O3zYmAyyb0MQuSGqtrVjb0XeHeSPQyusXxygfVIGrEF3f0ZFa+pjJ+1a9eOugQdgcnJSX7605/O60Kt36iV1JShIqkpQ0VSU4aKpKYMFUlNGSqSmjJUJDVlqEhqylCR1JShIqkpQ0VSU4aKpKYMFUlNGSqSmjJUJDVlqEhqylCR1JShIqmp57ztaZI1Sb6e5P4k9yV5a2/sU0m+22uJumYh9UgavWG0PX0SeFtVvQS4CPirJCf0xv+01xL1ngXWI2nEFhoqlwA3d8s3A5dO3aGqHqyq3d3y9xn0BvqNBf5eSYvUQkNlrm1PAUhyDnAM8FBv8593H4tuPNQfSNL4GlbbU7oOhp8BNlTVL7rN1zIIo2MYtDR9L3D9DPP7vZQlLVJDaXua5NeBfwGuq6odvfc+dJbzdJK/Bd4zSx32UpbGwDDanh4DfA74dFXdNmVsVfcaBtdjvr3AeiSN2DDanv4O8HrgimluHf9dkp3ATmAF8GcLrEfSiNn2VENh29PxYttTSYuGoSKpKUNFUlOGiqSmDBVJTRkqkpoyVCQ1ZahIaspQkdSUoSKpKUNFUlOGiqSmDBVJTRkqkpoyVCQ1ZahIaspQkdSUoSKpKUNFUlNNQiXJRUkeSLInyS+1Pk1ybJIt3fjdSU7tjV3bbX8gyYUt6pE0OgsOlSRHAR8F3gycBVye5Kwpu10JPF5VLwRuBD7UzT0LWA8c6rP8se79JI2pFmcq5wB7qmpvVf0cuJVBj+W+fs/l24A3dr1+LgFuraqnq+q7wJ7u/SSNqRahcgrwvd76w922afepqoPAAeCkOc4FBm1Pk0wmmWxQs6TnyGHbni4Wtj2VxkOLM5V9wAt668/vtk27T5KjgWXAY3OcK2mMtAiVbwJnJDmt65u8nkGP5b5+z+XLgO01aI24FVjf3R06DTgD+EaDmiSNyII//lTVwSRXA18CjgI2V9X9Sa4HJqtqK/BJ4DNJ9gD7GQQP3X7/AOwCDgLvrKpnF1qTpNGxl7KGwl7K48VeypIWDUNFUlOGiqSmDBVJTRkqkpoyVCQ1ZahIaspQkdSUoSKpKUNFUlOGiqSmDBVJTRkqkpoyVCQ1ZahIaspQkdSUoSKpKUNFUlPDanv67iS7ktyX5M4kq3tjzya5p/uZ+gezJY2ZBf/h617b0zcxaAb2zSRbq2pXb7f/BCaq6skk7wA+DLy1G3uqqtYstA5Ji8NQ2p5W1Veq6sludQeD/j6SlqBhtT3tuxK4o7d+XNfOdEeSS2eaZNtTaTwMte1pkt8DJoDzeptXV9W+JKcD25PsrKqHps617ak0HobV9pQk5wPXAeuq6ulD26tqX/e6F7gLOLtBTZJGZChtT5OcDXyCQaA82tu+PMmx3fIK4FwG3QoljalhtT39S+B44LNJAP6nqtYBLwY+keQXDALuhil3jSSNGdueaihsezpebHsqadEwVCQ1ZahIaspQkdSUoSKpKUNFUlOGiqSmDBVJTRkqkpoyVCQ1ZahIaspQkdSUoSKpKUNFUlOGiqSmDBVJTRkqkpoyVCQ1Nay2p1ck+VGvvelVvbENSXZ3Pxta1CNpdIbV9hRgS1VdPWXuicD7GfQCKuBb3dzHF1qXpNEYStvTWVwIbKuq/V2QbAMualCTpBFp0aFwuranr5pmv7ckeT3wIPCuqvreDHOnbZmaZCOwEWDlypVs2bKlQekalvPOO+/wO2nRmJiYmPfcYV2o/SJwalW9jMHZyM1H+gZVtamqJqpqYtmyZc0LlNTGUNqeVtVjvVanNwGvnOtcSeNlWG1PV/VW1wHf6Za/BFzQtT9dDlzQbZM0pobV9vRPkqwDDgL7gSu6ufuTfJBBMAFcX1X7F1qTpNFpcaGWqroduH3Ktvf1lq8Frp1h7mZgc4s6JI2e36iV1JShIqkpQ0VSU4aKpKYMFUlNGSqSmjJUJDVlqEhqylCR1JShIqkpQ0VSU4aKpKYMFUlNGSqSmjJUJDVlqEhqylCR1JShIqmpYbU9vbHX8vTBJD/ujT3bG9s6da6k8TKUtqdV9a7e/n8MnN17i6eqas1C65C0OIyi7enlwC0Nfq+kRahFqBxJ69LVwGnA9t7m45JMJtmR5NKZfkmSjd1+kwcOHGhQtqTnQpMWHUdgPXBbVT3b27a6qvYlOR3YnmRnVT00dWJVbQI2AZx55pk1nHIlHamhtD3tWc+Ujz5Vta973Qvcxf+/3iJpzAyl7SlAkhcBy4Gv97YtT3Jst7wCOBfYNXWupPExrLanMAibW6uq/9HlxcAnkvyCQcDd0L9rJGn8DKXtabf+gWnmfQ14aYsaJC0OfqNWUlOGiqSmDBVJTRkqkpoyVCQ1ZahIaspQkdSUoSKpKUNFUlOGiqSmDBVJTRkqkpoyVCQ1ZahIaspQkdSUoSKpKUNFUlOGiqSmWrU93Zzk0STfnmE8ST7StUW9L8kremMbkuzufja0qEfS6LQ6U/kUcNEs428Gzuh+NgJ/A5DkROD9wKsYdDp8f5LljWqSNAJNQqWqvgrsn2WXS4BP18AO4IQkq4ALgW1Vtb+qHge2MXs4SVrkhnVNZabWqEfSMtW2p9IYGJsLtVW1qaomqmpi2bJloy5H0gyGFSoztUY9kpapksbAsEJlK/C27i7Qq4EDVfUIg66GF3TtT5cDF3TbJI2pJh0Kk9wCrAVWJHmYwR2d5wFU1ccZdC+8GNgDPAn8QTe2P8kHGfRjBri+qma74CtpkWvV9vTyw4wX8M4ZxjYDm1vUIWn0xuZCraTxYKhIaspQkdSUoSKpKUNFUlOGiqSmDBVJTRkqkpoyVCQ1ZahIaspQkdSUoSKpKUNFUlOGiqSmDBVJTRkqkpoyVCQ1ZahIampYbU9/t2t3ujPJ15K8vDf23932e5JMtqhH0ugMq+3pd4HzquqlwAeBTVPG31BVa6pqolE9kkak1R++/mqSU2cZ/1pvdQeD/j6SlqBRXFO5Erijt17AvyX5VpKNI6hHUkNNzlTmKskbGITK63qbX1dV+5L8JrAtyX91Dd+nzt0IbARYuXLlUOqVdOSGdqaS5GXATcAlVfXYoe1Vta97fRT4HHDOdPPtpSyNh6GESpLfAv4J+P2qerC3/VeT/NqhZQZtT6e9gyRpPAyr7en7gJOAjyUBONjd6VkJfK7bdjTw91X1ry1qkjQaw2p7ehVw1TTb9wIv/+UZksaV36iV1JShIqkpQ0VSU4aKpKYMFUlNGSqSmjJUJDVlqEhqylCR1JShIqkpQ0VSU4aKpKYMFUlNGSqSmjJUJDVlqEhqylCR1JShIqkpQ0VSU8Pqpbw2yYGuX/I9Sd7XG7soyQNJ9iS5pkU9kkZnWL2UAf6965e8pqquB0hyFPBR4M3AWcDlSc5qVJOkEWgSKl1Hwf3zmHoOsKeq9lbVz4FbgUta1CRpNIbZ9vQ1Se4Fvg+8p6ruB04Bvtfb52HgVdNN7rc9BZ5eu3btUmw6tgL431EX8RxZqse2VI/rzPlOHFao/AewuqqeSHIx8HngjCN5g6raBGwCSDLZNSNbUpbqccHSPbalfFzznTuUuz9V9ZOqeqJbvh14XpIVwD7gBb1dn99tkzSmhtVL+eR0vU2TnNP93seAbwJnJDktyTHAemDrMGqS9NwYVi/ly4B3JDkIPAWsr6oCDia5GvgScBSwubvWcjibWtS9CC3V44Kle2we1xQZ/L8tSW34jVpJTRkqkpoai1BJcmKSbUl2d6/LZ9jv2d6jAIv2gu/hHk1IcmySLd343UlOHX6VR24Ox3VFkh/1/o2uGkWdR2oOj6EkyUe6474vySuGXeN8LOTxmllV1aL/AT4MXNMtXwN8aIb9nhh1rXM4lqOAh4DTgWOAe4GzpuzzR8DHu+X1wJZR193ouK4A/nrUtc7j2F4PvAL49gzjFwN3AAFeDdw96pobHdda4J+P9H3H4kyFwVf3b+6WbwYuHWEtCzWXRxP6x3sb8MZDt+QXsSX7yEUd/jGUS4BP18AO4IQkq4ZT3fzN4bjmZVxCZWVVPdIt/wBYOcN+xyWZTLIjyWINnukeTThlpn2q6iBwADhpKNXN31yOC+At3UeE25K8YJrxcTTXYx9Hr0lyb5I7krxkLhOG+ezPrJJ8GTh5mqHr+itVVUlmug++uqr2JTkd2J5kZ1U91LpWzdsXgVuq6ukkf8jgbOy3R1yTZjavx2sWTahU1fkzjSX5YZJVVfVId1r56Azvsa973ZvkLuBsBp/zF5O5PJpwaJ+HkxwNLGPwDeTF7LDHVVX9Y7iJwbWypWBJPm5SVT/pLd+e5GNJVlTVrA9QjsvHn63Ahm55A/CFqTskWZ7k2G55BXAusGtoFc7dXB5N6B/vZcD26q6cLWKHPa4p1xnWAd8ZYn3Ppa3A27q7QK8GDvQ+ro+tWR6vmd2or0DP8Sr1ScCdwG7gy8CJ3fYJ4KZu+bXATgZ3HXYCV4667lmO52LgQQZnUdd1264H1nXLxwGfBfYA3wBOH3XNjY7rL4D7u3+jrwAvGnXNczyuW4BHgGcYXC+5Eng78PZuPAz+2NhD3X97E6OuudFxXd3799oBvHYu7+vX9CU1NS4ffySNCUNFUlOGiqSmDBVJTRkqkpoyVCQ1ZahIaur/AOpcnMTTxau0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image = tf.constant([[[[1],[2],[3]],\n",
        "                   [[4],[5],[6]], \n",
        "                   [[7],[8],[9]]]], dtype=np.float32)\n",
        "\n",
        "print(\"image.shape\", image.shape)\n",
        "weight = np.array([[[[1.]],[[1.]]],\n",
        "                   [[[1.]],[[1.]]]])\n",
        "print(\"weight.shape\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = keras.layers.Conv2D(filters=1, kernel_size=2, padding='VALID', \n",
        "                             kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "print(conv2d.numpy().reshape(2,2))\n",
        "plt.imshow(conv2d.numpy().reshape(2,2), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "YSY_J4PQfQXM",
        "outputId": "16f47465-69ca-4bbe-b10e-1c2b367c2b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image.shape (1, 3, 3, 1)\n",
            "weight.shape (2, 2, 1, 1)\n",
            "conv2d.shape (1, 3, 3, 1)\n",
            "[[12. 16.  9.]\n",
            " [24. 28. 15.]\n",
            " [15. 17.  9.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"image.shape\", image.shape)\n",
        "weight = np.array([[[[1.]],[[1.]]],\n",
        "                   [[[1.]],[[1.]]]])\n",
        "print(\"weight.shape\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = keras.layers.Conv2D(filters=1, kernel_size=2, padding='SAME', \n",
        "                             kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "print(conv2d.numpy().reshape(3,3))\n",
        "plt.imshow(conv2d.numpy().reshape(3,3), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "N-BS3Yj0fjDi",
        "outputId": "8d21d420-427c-489d-fae1-12a879421f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image.shape (1, 3, 3, 1)\n",
            "weight.shape (2, 2, 1, 3)\n",
            "conv2d.shape (1, 3, 3, 3)\n",
            "[[12. 16.  9.]\n",
            " [24. 28. 15.]\n",
            " [15. 17.  9.]]\n",
            "[[120. 160.  90.]\n",
            " [240. 280. 150.]\n",
            " [150. 170.  90.]]\n",
            "[[-12. -16.  -9.]\n",
            " [-24. -28. -15.]\n",
            " [-15. -17.  -9.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"image.shape\", image.shape)\n",
        "\n",
        "weight = np.array([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
        "                   [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
        "print(\"weight.shape\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = keras.layers.Conv2D(filters=3, kernel_size=2, padding='SAME',\n",
        "                             kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    print(feature_map.reshape(3,3))\n",
        "    plt.subplot(1,3,i+1), plt.imshow(feature_map.reshape(3,3), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_SUaYZufwzO"
      },
      "source": [
        "# 11-0-2 CNN basics pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VgvQn_8fz0-",
        "outputId": "550041f0-74f7-43ca-bec3-08fdb21b031f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 1, 1, 1)\n",
            "[[[[4.]]]]\n"
          ]
        }
      ],
      "source": [
        "image = tf.constant([[[[4],[3]],\n",
        "                    [[2],[1]]]], dtype=np.float32)\n",
        "pool = keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='VALID')(image)\n",
        "print(pool.shape)\n",
        "print(pool.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfSj3F2HgAfb",
        "outputId": "e428df7d-a4ab-48bd-aafe-1982dc4d1aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 2, 2, 1)\n",
            "[[[[4.]\n",
            "   [3.]]\n",
            "\n",
            "  [[2.]\n",
            "   [1.]]]]\n"
          ]
        }
      ],
      "source": [
        "image = tf.constant([[[[4],[3]],\n",
        "                    [[2],[1]]]], dtype=np.float32)\n",
        "pool = keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='SAME')(image)\n",
        "print(pool.shape)\n",
        "print(pool.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "zcEqamdVgDYh",
        "outputId": "cb5f5d16-804c-4e05-9559-521641174162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN9klEQVR4nO3df4xV9ZnH8c+zWP6QojBrOhKKSyEGg8ZON4gbl6w1hvojGhw1TSexoZE4/YNJaLIhNewf1WwwZBU2SzTNTKMWNl1qEzUgaQouoOzGhDgiKo5LdQ2mTEaowZEf/mCHefaPezBTnfu9w7nn3nOZ5/1Kbu6957nnnicnfDi/7pmvubsATH5/VXYDAJqDsANBEHYgCMIOBEHYgSAuaubCzIxT/0CDubuNN72uLbuZ3Wpmh8zsPTN7sJ7vAtBYlvc6u5lNkfRHSUslHZH0qqQudx9IzMOWHWiwRmzZF0t6z93fd/czkn4raVkd3weggeoJ+2xJfxrz/kg27S+YWbeZ9ZtZfx3LAlCnhp+gc/c+SX0Su/FAmerZsg9KmjPm/bezaQBaUD1hf1XSlWb2HTObKulHkrYV0xaAouXejXf3ETPrkbRD0hRJT7n724V1BqBQuS+95VoYx+xAwzXkRzUALhyEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBJF7yGZcGKZMmZKsX3rppQ1dfk9PT9XaxRdfnJx3wYIFyfrKlSuT9ccee6xqraurKznv559/nqyvW7cuWX/44YeT9TLUFXYzOyzppKSzkkbcfVERTQEoXhFb9pvc/aMCvgdAA3HMDgRRb9hd0k4ze83Musf7gJl1m1m/mfXXuSwAdah3N36Juw+a2bckvWhm/+Pue8d+wN37JPVJkpl5ncsDkFNdW3Z3H8yej0l6XtLiIpoCULzcYTezaWY2/dxrST+QdLCoxgAUq57d+HZJz5vZue/5D3f/QyFdTTJXXHFFsj516tRk/YYbbkjWlyxZUrU2Y8aM5Lz33HNPsl6mI0eOJOsbN25M1js7O6vWTp48mZz3jTfeSNZffvnlZL0V5Q67u78v6bsF9gKggbj0BgRB2IEgCDsQBGEHgiDsQBDm3rwftU3WX9B1dHQk67t3707WG32baasaHR1N1u+///5k/dSpU7mXPTQ0lKx//PHHyfqhQ4dyL7vR3N3Gm86WHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeC4Dp7Adra2pL1ffv2Jevz5s0rsp1C1ep9eHg4Wb/pppuq1s6cOZOcN+rvD+rFdXYgOMIOBEHYgSAIOxAEYQeCIOxAEIQdCIIhmwtw/PjxZH316tXJ+h133JGsv/7668l6rT+pnHLgwIFkfenSpcn66dOnk/Wrr766am3VqlXJeVEstuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EAT3s7eASy65JFmvNbxwb29v1dqKFSuS8953333J+pYtW5J1tJ7c97Ob2VNmdszMDo6Z1mZmL5rZu9nzzCKbBVC8iezG/1rSrV+Z9qCkXe5+paRd2XsALaxm2N19r6Sv/h50maRN2etNku4quC8ABcv72/h2dz83WNaHktqrfdDMuiV151wOgILUfSOMu3vqxJu790nqkzhBB5Qp76W3o2Y2S5Ky52PFtQSgEfKGfZuk5dnr5ZK2FtMOgEapuRtvZlskfV/SZWZ2RNIvJK2T9DszWyHpA0k/bGSTk92JEyfqmv+TTz7JPe8DDzyQrD/zzDPJeq0x1tE6aobd3buqlG4uuBcADcTPZYEgCDsQBGEHgiDsQBCEHQiCW1wngWnTplWtvfDCC8l5b7zxxmT9tttuS9Z37tyZrKP5GLIZCI6wA0EQdiAIwg4EQdiBIAg7EARhB4LgOvskN3/+/GR9//79yfrw8HCyvmfPnmS9v7+/au2JJ55IztvMf5uTCdfZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIrrMH19nZmaw//fTTyfr06dNzL3vNmjXJ+ubNm5P1oaGhZD0qrrMDwRF2IAjCDgRB2IEgCDsQBGEHgiDsQBBcZ0fSNddck6xv2LAhWb/55vyD/fb29ibra9euTdYHBwdzL/tClvs6u5k9ZWbHzOzgmGkPmdmgmR3IHrcX2SyA4k1kN/7Xkm4dZ/q/untH9vh9sW0BKFrNsLv7XknHm9ALgAaq5wRdj5m9me3mz6z2ITPrNrN+M6v+x8gANFzesP9S0nxJHZKGJK2v9kF373P3Re6+KOeyABQgV9jd/ai7n3X3UUm/krS42LYAFC1X2M1s1pi3nZIOVvssgNZQ8zq7mW2R9H1Jl0k6KukX2fsOSS7psKSfunvNm4u5zj75zJgxI1m/8847q9Zq3StvNu7l4i/t3r07WV+6dGmyPllVu85+0QRm7Bpn8pN1dwSgqfi5LBAEYQeCIOxAEIQdCIKwA0FwiytK88UXXyTrF12Uvlg0MjKSrN9yyy1Vay+99FJy3gsZf0oaCI6wA0EQdiAIwg4EQdiBIAg7EARhB4KoedcbYrv22muT9XvvvTdZv+6666rWal1Hr2VgYCBZ37t3b13fP9mwZQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBILjOPsktWLAgWe/p6UnW77777mT98ssvP++eJurs2bPJ+tBQ+q+Xj46OFtnOBY8tOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwXX2C0Cta9ldXeMNtFtR6zr63Llz87RUiP7+/mR97dq1yfq2bduKbGfSq7llN7M5ZrbHzAbM7G0zW5VNbzOzF83s3ex5ZuPbBZDXRHbjRyT9o7svlPR3klaa2UJJD0ra5e5XStqVvQfQomqG3d2H3H1/9vqkpHckzZa0TNKm7GObJN3VqCYB1O+8jtnNbK6k70naJ6nd3c/9OPlDSe1V5umW1J2/RQBFmPDZeDP7pqRnJf3M3U+MrXlldMhxB2109z53X+Tui+rqFEBdJhR2M/uGKkH/jbs/l00+amazsvosScca0yKAItTcjTczk/SkpHfcfcOY0jZJyyWty563NqTDSaC9fdwjnC8tXLgwWX/88ceT9auuuuq8eyrKvn37kvVHH320am3r1vQ/GW5RLdZEjtn/XtKPJb1lZgeyaWtUCfnvzGyFpA8k/bAxLQIoQs2wu/t/Sxp3cHdJNxfbDoBG4eeyQBCEHQiCsANBEHYgCMIOBMEtrhPU1tZWtdbb25uct6OjI1mfN29erp6K8MorryTr69evT9Z37NiRrH/22Wfn3RMagy07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgQR5jr79ddfn6yvXr06WV+8eHHV2uzZs3P1VJRPP/20am3jxo3JeR955JFk/fTp07l6Quthyw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQYS5zt7Z2VlXvR4DAwPJ+vbt25P1kZGRZD11z/nw8HByXsTBlh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgjB3T3/AbI6kzZLaJbmkPnf/NzN7SNIDkv6cfXSNu/++xnelFwagbu4+7qjLEwn7LEmz3H2/mU2X9Jqku1QZj/2Uuz820SYIO9B41cI+kfHZhyQNZa9Pmtk7ksr90ywAztt5HbOb2VxJ35O0L5vUY2ZvmtlTZjazyjzdZtZvZv11dQqgLjV347/8oNk3Jb0saa27P2dm7ZI+UuU4/p9V2dW/v8Z3sBsPNFjuY3ZJMrNvSNouaYe7bxinPlfSdne/psb3EHagwaqFveZuvJmZpCclvTM26NmJu3M6JR2st0kAjTORs/FLJP2XpLckjWaT10jqktShym78YUk/zU7mpb6LLTvQYHXtxheFsAONl3s3HsDkQNiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQii2UM2fyTpgzHvL8umtaJW7a1V+5LoLa8ie/ubaoWm3s/+tYWb9bv7otIaSGjV3lq1L4ne8mpWb+zGA0EQdiCIssPeV/LyU1q1t1btS6K3vJrSW6nH7ACap+wtO4AmIexAEKWE3cxuNbNDZvaemT1YRg/VmNlhM3vLzA6UPT5dNobeMTM7OGZam5m9aGbvZs/jjrFXUm8Pmdlgtu4OmNntJfU2x8z2mNmAmb1tZquy6aWuu0RfTVlvTT9mN7Mpkv4oaamkI5JeldTl7gNNbaQKMzssaZG7l/4DDDP7B0mnJG0+N7SWmf2LpOPuvi77j3Kmu/+8RXp7SOc5jHeDeqs2zPhPVOK6K3L48zzK2LIvlvSeu7/v7mck/VbSshL6aHnuvlfS8a9MXiZpU/Z6kyr/WJquSm8twd2H3H1/9vqkpHPDjJe67hJ9NUUZYZ8t6U9j3h9Ra4337pJ2mtlrZtZddjPjaB8zzNaHktrLbGYcNYfxbqavDDPeMusuz/Dn9eIE3dctcfe/lXSbpJXZ7mpL8soxWCtdO/2lpPmqjAE4JGl9mc1kw4w/K+ln7n5ibK3MdTdOX01Zb2WEfVDSnDHvv51NawnuPpg9H5P0vCqHHa3k6LkRdLPnYyX38yV3P+ruZ919VNKvVOK6y4YZf1bSb9z9uWxy6etuvL6atd7KCPurkq40s++Y2VRJP5K0rYQ+vsbMpmUnTmRm0yT9QK03FPU2Scuz18slbS2xl7/QKsN4VxtmXCWvu9KHP3f3pj8k3a7KGfn/lfRPZfRQpa95kt7IHm+X3ZukLars1v2fKuc2Vkj6a0m7JL0r6T8ltbVQb/+uytDeb6oSrFkl9bZElV30NyUdyB63l73uEn01Zb3xc1kgCE7QAUEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "\n",
        "img = train_images[0]\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "XYDtL4AegJbe",
        "outputId": "a8a1cbe4-e774-4208-e33f-16f40da90e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 14, 14, 5)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img = img.reshape(-1,28,28,1)\n",
        "img = tf.convert_to_tensor(img)\n",
        "weight_init = keras.initializers.RandomNormal(stddev=0.01)\n",
        "conv2d = keras.layers.Conv2D(filters=5, kernel_size=3, strides=(2, 2), padding='SAME', \n",
        "                             kernel_initializer=weight_init)(img)\n",
        "print(conv2d.shape)\n",
        "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(14,14), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "gGdEZgxIgL5Z",
        "outputId": "ff4e35a5-ed71-48e4-cc4b-72de7e53c3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 7, 7, 5)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pool = keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='SAME')(conv2d)\n",
        "print(pool.shape)\n",
        "\n",
        "feature_maps = np.swapaxes(pool, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(7, 7), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBbqHg4vgo54"
      },
      "source": [
        "# 11-1 MNIST CNN keras sequential eager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1nkPv-g3fL"
      },
      "source": [
        "## NN Implementation Flow in TensorFlow\n",
        "1. Set hyper parameters\n",
        "2. Make a data pipelining\n",
        "3. Build a neural network model\n",
        "4. Define a loss function\n",
        "5. Calculate a gradient\n",
        "6. Select an optimizer\n",
        "7. Define a metric for model's performance\n",
        "8. (optional) Make a checkpoint for saving\n",
        "9. Train and Validate a neural network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N_v8ad-gzFh",
        "outputId": "971dc436-f278-4ca8-a750-cf452c21460f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC3XEmBWhSJS"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "tf.random.set_seed(777)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ_yhuDKhV3l"
      },
      "outputs": [],
      "source": [
        "cur_dir = os.getcwd()\n",
        "ckpt_dir_name = 'checkpoints'\n",
        "model_dir_name = 'minst_cnn_seq'\n",
        "\n",
        "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax-rnpFLhZHo"
      },
      "outputs": [],
      "source": [
        "## MNIST Dataset #########################################################\n",
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "##########################################################################\n",
        "\n",
        "## Fashion MNIST Dataset #################################################\n",
        "#mnist = keras.datasets.fashion_mnist\n",
        "#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "##########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iw28OAZIhbbC"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
        "    \n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "# 차원 하나 추가\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "    \n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)    \n",
        "    \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n",
        "                buffer_size=100000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m61J28irhdOt"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, padding='SAME', \n",
        "                                  input_shape=(28, 28, 1)))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "othOfBm1hfBZ",
        "outputId": "1bc5c018-090f-4573-9545-a929ee8838dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               524544    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 619,786\n",
            "Trainable params: 619,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7fFO5ShhmSu"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
        "        y_pred=logits, y_true=labels, from_logits=True))    \n",
        "    return loss   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyk90LLZhn5o"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yVm_ilnhpyd"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def evaluate(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isH0L0y5hrFK"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urPO5V8mhs1T"
      },
      "outputs": [],
      "source": [
        "checkpoint = tf.train.Checkpoint(cnn=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spVOE_MahuIU"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train(model, images, labels):\n",
        "    grads = grad(model, images, labels)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNy33RCAhu9K"
      },
      "outputs": [],
      "source": [
        "# train my model\n",
        "print('Learning started. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "    avg_loss = 0.\n",
        "    avg_train_acc = 0.\n",
        "    avg_test_acc = 0.\n",
        "    train_step = 0\n",
        "    test_step = 0    \n",
        "    \n",
        "    for images, labels in train_dataset:\n",
        "        train(model, images, labels)\n",
        "        #grads = grad(model, images, labels)                \n",
        "        #optimizer.apply_gradients(zip(grads, model.variables))\n",
        "        loss = loss_fn(model, images, labels)\n",
        "        acc = evaluate(model, images, labels)\n",
        "        avg_loss = avg_loss + loss\n",
        "        avg_train_acc = avg_train_acc + acc\n",
        "        train_step += 1\n",
        "    avg_loss = avg_loss / train_step\n",
        "    avg_train_acc = avg_train_acc / train_step\n",
        "    \n",
        "    for images, labels in test_dataset:        \n",
        "        acc = evaluate(model, images, labels)        \n",
        "        avg_test_acc = avg_test_acc + acc\n",
        "        test_step += 1    \n",
        "    avg_test_acc = avg_test_acc / test_step    \n",
        "\n",
        "    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
        "          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
        "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
        "    \n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "print('Learning Finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgz01XZhjUrB"
      },
      "source": [
        "# 11-2 MNIST CNN keras functional eager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBmtVr1Jja5t"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 3\n",
        "batch_size = 100\n",
        "\n",
        "tf.random.set_seed(777)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW6YQpA5jhH6"
      },
      "outputs": [],
      "source": [
        "cur_dir = os.getcwd()\n",
        "ckpt_dir_name = 'checkpoints'\n",
        "model_dir_name = 'minst_cnn_func'\n",
        "\n",
        "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hxb8-zeBjin0"
      },
      "outputs": [],
      "source": [
        "## MNIST Dataset #########################################################\n",
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "##########################################################################\n",
        "\n",
        "## Fashion MNIST Dataset #################################################\n",
        "#mnist = keras.datasets.fashion_mnist\n",
        "#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "##########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTYpXoeVjk3H"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
        "    \n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "    \n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)    \n",
        "    \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n",
        "                buffer_size=100000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkSCI3PXjmmB"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    inputs = keras.Input(shape=(28, 28, 1))\n",
        "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(inputs)\n",
        "    pool1 = keras.layers.MaxPool2D(padding='SAME')(conv1)\n",
        "    conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(pool1)\n",
        "    pool2 = keras.layers.MaxPool2D(padding='SAME')(conv2)\n",
        "    conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(pool2)\n",
        "    pool3 = keras.layers.MaxPool2D(padding='SAME')(conv3)\n",
        "    pool3_flat = keras.layers.Flatten()(pool3)\n",
        "    dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu)(pool3_flat)\n",
        "    drop4 = keras.layers.Dropout(rate=0.4)(dense4)\n",
        "    logits = keras.layers.Dense(units=10)(drop4)\n",
        "    return keras.Model(inputs=inputs, outputs=logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl0UICnnjo3p",
        "outputId": "87259df8-f680-4e4a-ebe5-cd04669ef0b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               524544    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 619,786\n",
            "Trainable params: 619,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-TODfx_jq5C"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
        "        y_pred=logits, y_true=labels, from_logits=True))    \n",
        "    return loss   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q91_tCRdjr8D"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P3F4127jt-V"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def evaluate(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MlpTO-0jwp5"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2OsVEzFjx--"
      },
      "outputs": [],
      "source": [
        "checkpoint = tf.train.Checkpoint(cnn=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s4AecFqjz93"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train(model, images, labels):\n",
        "    grads = grad(model, images, labels)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5gcI63Aj1UI",
        "outputId": "896e281f-c5c7-4987-8dcb-de439d0cc57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning started. It takes sometime.\n",
            "Epoch: 1 loss = 0.16170827 train accuracy =  0.9596 test accuracy =  0.9865\n",
            "Epoch: 2 loss = 0.03895051 train accuracy =  0.9905 test accuracy =  0.9905\n",
            "Epoch: 3 loss = 0.02492788 train accuracy =  0.9938 test accuracy =  0.9910\n",
            "Learning Finished!\n"
          ]
        }
      ],
      "source": [
        "# train my model\n",
        "print('Learning started. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "    avg_loss = 0.\n",
        "    avg_train_acc = 0.\n",
        "    avg_test_acc = 0.\n",
        "    train_step = 0\n",
        "    test_step = 0\n",
        "    \n",
        "    for images, labels in train_dataset:\n",
        "        train(model, images, labels)\n",
        "        #grads = grad(model, images, labels)                \n",
        "        #optimizer.apply_gradients(zip(grads, model.variables))\n",
        "        loss = loss_fn(model, images, labels)\n",
        "        acc = evaluate(model, images, labels)\n",
        "        avg_loss = avg_loss + loss\n",
        "        avg_train_acc = avg_train_acc + acc\n",
        "        train_step += 1\n",
        "    avg_loss = avg_loss / train_step\n",
        "    avg_train_acc = avg_train_acc / train_step\n",
        "    \n",
        "    for images, labels in test_dataset:        \n",
        "        acc = evaluate(model, images, labels)        \n",
        "        avg_test_acc = avg_test_acc + acc\n",
        "        test_step += 1    \n",
        "    avg_test_acc = avg_test_acc / test_step    \n",
        "\n",
        "    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
        "          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
        "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
        "    \n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "print('Learning Finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbxo478Wk9Hw"
      },
      "source": [
        "# MNIST CNN keras subclassing eager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YyoHO9YlFUO"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 3\n",
        "batch_size = 100\n",
        "\n",
        "tf.random.set_seed(777)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EU_H4AclJaB"
      },
      "outputs": [],
      "source": [
        "cur_dir = os.getcwd()\n",
        "ckpt_dir_name = 'checkpoints'\n",
        "model_dir_name = 'minst_cnn_subclass'\n",
        "\n",
        "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyi9-iL8lLfE"
      },
      "outputs": [],
      "source": [
        "## MNIST Dataset #########################################################\n",
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "##########################################################################\n",
        "\n",
        "## Fashion MNIST Dataset #################################################\n",
        "#mnist = keras.datasets.fashion_mnist\n",
        "#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "##########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcBObHCBlM5f"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
        "    \n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "    \n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)    \n",
        "    \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n",
        "                buffer_size=100000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ-zAhXTlO4Z"
      },
      "outputs": [],
      "source": [
        "class MNISTModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool1 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool2 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool3 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.pool3_flat = keras.layers.Flatten()\n",
        "        self.dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
        "        self.drop4 = keras.layers.Dropout(rate=0.4)\n",
        "        self.dense5 = keras.layers.Dense(units=10)\n",
        "    def call(self, inputs, training=False):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.pool1(net)\n",
        "        net = self.conv2(net)\n",
        "        net = self.pool2(net)\n",
        "        net = self.conv3(net)\n",
        "        net = self.pool3(net)\n",
        "        net = self.pool3_flat(net)\n",
        "        net = self.dense4(net)\n",
        "        net = self.drop4(net)\n",
        "        net = self.dense5(net)\n",
        "        return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpkU7FkglQkb",
        "outputId": "1f354ea1-f994-4361-e7a2-4ede0d70c219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"mnist_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_13 (Conv2D)          multiple                  320       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          multiple                  18496     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          multiple                  73856     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             multiple                  524544    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         multiple                  0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             multiple                  2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 619,786\n",
            "Trainable params: 619,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = MNISTModel()\n",
        "temp_inputs = keras.Input(shape=(28, 28, 1))\n",
        "model(temp_inputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK2l01XClTIq"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
        "        y_pred=logits, y_true=labels, from_logits=True))     \n",
        "    return loss   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC-XjX5mlUcH"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asK5DwEblVtZ"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def evaluate(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSdifmCxlXIo"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUYotbsLlYvy"
      },
      "outputs": [],
      "source": [
        "checkpoint = tf.train.Checkpoint(cnn=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r09wpEutlaIE"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train(model, images, labels):\n",
        "    grads = grad(model, images, labels)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "43iRaTnblcHG",
        "outputId": "7d8fed19-b2d4-4390-b44d-711d97ce87aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning started. It takes sometime.\n",
            "Epoch: 1 loss = 0.16170827 train accuracy =  0.9596 test accuracy =  0.9865\n",
            "Epoch: 2 loss = 0.03895051 train accuracy =  0.9905 test accuracy =  0.9905\n",
            "Epoch: 3 loss = 0.02492788 train accuracy =  0.9938 test accuracy =  0.9910\n",
            "Learning Finished!\n"
          ]
        }
      ],
      "source": [
        "# train my model\n",
        "print('Learning started. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "    avg_loss = 0.\n",
        "    avg_train_acc = 0.\n",
        "    avg_test_acc = 0.\n",
        "    train_step = 0\n",
        "    test_step = 0\n",
        "    \n",
        "    for images, labels in train_dataset:\n",
        "        train(model, images, labels)\n",
        "        #grads = grad(model, images, labels)                \n",
        "        #optimizer.apply_gradients(zip(grads, model.variables))\n",
        "        loss = loss_fn(model, images, labels)\n",
        "        acc = evaluate(model, images, labels)\n",
        "        avg_loss = avg_loss + loss\n",
        "        avg_train_acc = avg_train_acc + acc\n",
        "        train_step += 1\n",
        "    avg_loss = avg_loss / train_step\n",
        "    avg_train_acc = avg_train_acc / train_step\n",
        "    \n",
        "    for images, labels in test_dataset:        \n",
        "        acc = evaluate(model, images, labels)        \n",
        "        avg_test_acc = avg_test_acc + acc\n",
        "        test_step += 1    \n",
        "    avg_test_acc = avg_test_acc / test_step    \n",
        "\n",
        "    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
        "          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
        "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
        "    \n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "print('Learning Finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fstAhEkVmgS_"
      },
      "source": [
        "# MNIST CNN keras ensemble eager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "312yaW0rmqzt"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 3\n",
        "batch_size = 100\n",
        "\n",
        "tf.random.set_seed(777)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sb9btpcTmvU_"
      },
      "outputs": [],
      "source": [
        "cur_dir = os.getcwd()\n",
        "ckpt_dir_name = 'checkpoints'\n",
        "model_dir_name = 'minst_cnn_emsemble'\n",
        "\n",
        "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ovp_N0bWmwHm"
      },
      "outputs": [],
      "source": [
        "## MNIST Dataset #########################################################\n",
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "##########################################################################\n",
        "\n",
        "## Fashion MNIST Dataset #################################################\n",
        "#mnist = keras.datasets.fashion_mnist\n",
        "#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "##########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lhD_hAxcmyQH"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
        "    \n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "    \n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)    \n",
        "    \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n",
        "                buffer_size=100000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zL3z6tBimy9p"
      },
      "outputs": [],
      "source": [
        "class MNISTModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool1 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool2 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool3 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.pool3_flat = keras.layers.Flatten()\n",
        "        self.dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
        "        self.drop4 = keras.layers.Dropout(rate=0.4)\n",
        "        self.dense5 = keras.layers.Dense(units=10)\n",
        "    def call(self, inputs, training=False):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.pool1(net)\n",
        "        net = self.conv2(net)\n",
        "        net = self.pool2(net)\n",
        "        net = self.conv3(net)\n",
        "        net = self.pool3(net)\n",
        "        net = self.pool3_flat(net)\n",
        "        net = self.dense4(net)\n",
        "        net = self.drop4(net)\n",
        "        net = self.dense5(net)\n",
        "        return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qMBE4LOsm1Vf"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "num_models = 3\n",
        "for m in range(num_models):\n",
        "    models.append(MNISTModel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NI8wn6Jxm2aL"
      },
      "outputs": [],
      "source": [
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
        "        y_pred=logits, y_true=labels, from_logits=True))\n",
        "    return loss   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RgwlzmmAm3aE"
      },
      "outputs": [],
      "source": [
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Rto1AkI0m4l7"
      },
      "outputs": [],
      "source": [
        "def evaluate(models, images, labels):\n",
        "    predictions = np.zeros_like(labels)\n",
        "    for model in models:\n",
        "        logits = model(images, training=False)\n",
        "        predictions += logits\n",
        "    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7wx_az1Em53V"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DQD6KKgBm7D8"
      },
      "outputs": [],
      "source": [
        "checkpoints = []\n",
        "for m in range(num_models):\n",
        "    checkpoints.append(tf.train.Checkpoint(cnn=models[m]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTOpIbnVm8de",
        "outputId": "b47d7e7d-ba09-4f6d-e2b9-304e1025c741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning started. It takes sometime.\n",
            "Epoch: 1 loss = 0.16205220 train accuracy =  0.9653 test accuracy =  0.9899\n",
            "Epoch: 2 loss = 0.04025410 train accuracy =  0.9928 test accuracy =  0.9931\n",
            "Epoch: 3 loss = 0.02749454 train accuracy =  0.9956 test accuracy =  0.9928\n",
            "Learning Finished!\n"
          ]
        }
      ],
      "source": [
        "# train my model\n",
        "print('Learning started. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "    avg_loss = 0.\n",
        "    avg_train_acc = 0.\n",
        "    avg_test_acc = 0.\n",
        "    train_step = 0\n",
        "    test_step = 0    \n",
        "    \n",
        "    for images, labels in train_dataset:\n",
        "        for model in models:\n",
        "            #train(model, images, labels)\n",
        "            grads = grad(model, images, labels)                \n",
        "            optimizer.apply_gradients(zip(grads, model.variables))\n",
        "            loss = loss_fn(model, images, labels)\n",
        "            avg_loss += loss / num_models\n",
        "        acc = evaluate(models, images, labels)\n",
        "        avg_train_acc += acc\n",
        "        train_step += 1\n",
        "    avg_loss = avg_loss / train_step\n",
        "    avg_train_acc = avg_train_acc / train_step\n",
        "    \n",
        "    for images, labels in test_dataset:        \n",
        "        acc = evaluate(models, images, labels)        \n",
        "        avg_test_acc += acc\n",
        "        test_step += 1    \n",
        "    avg_test_acc = avg_test_acc / test_step    \n",
        "\n",
        "    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n",
        "          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
        "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
        "    \n",
        "    \n",
        "    for idx, checkpoint in enumerate(checkpoints):\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix+'-{}'.format(idx))\n",
        "\n",
        "print('Learning Finished!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}