{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2738c0d",
   "metadata": {},
   "source": [
    "## ML lec01-기본적인 machine learning의 용어와 개념 설명\n",
    "1. ml 이란? 프로그램 자체가 데이터를 학습해서 능력을 갖는 프로그램\n",
    " - supervised learning : 정해져 있는 데이터, 레이블 돼있는 데이터(training set)을 가지고 학습\n",
    " - unsupervised learning : 데이터를 보고 스스로 학습함\n",
    " \n",
    "2. supervised learning: image labeling, email spam filter, predicting exam score\n",
    "  - regression\n",
    "  - binary classification\n",
    "  - multi-label classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3ab90",
   "metadata": {},
   "source": [
    "## TensorFlow Lec-02 Simple Linear Regression\n",
    "1.\tRegression : 데이터들은 전체의 평균으로 되돌아가려는 특징이 있다는 통계적 원리\n",
    "2.\tLinear regression : 선형회귀, 데이터를 가장 잘 대변하는 직선의 방정식을 찾는 것, y=ax +b에서 a값과 b값을 찾는 것\n",
    "3.\tHypothesis : 가설, H(x) = Wx + b\n",
    "4.\tCost, cost function : H(x)-y 를 최소화하는 방법, 비용함수 = 오차 제곱의 평균 \n",
    "5.\tGoal: minimize cost \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e026587",
   "metadata": {},
   "source": [
    "## TensorFlow Lab-02 Simple Linear Regression LAB\n",
    "Error= 예측과 실제 값의 차이, cost 값은 error 제곱의 평균값\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e0530",
   "metadata": {},
   "source": [
    "## Gradient descent 경사하강법\n",
    "- minimize cost (W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3005b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alaco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2360e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "x_data=[1,2,3,4,5]\n",
    "y_data=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22a1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#W,b initialize\n",
    "W= tf.Variable(2.9)\n",
    "b= tf.Variable(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9efe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e2f5b1",
   "metadata": {},
   "source": [
    "### Parameter(W,b) update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f968d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1|    2.4520|     0.376| 45.660004\n",
      "    1|    1.1036|  0.003398|  0.206336\n",
      "    1|    1.0128|  -0.02091|  0.001026\n",
      "    1|    1.0065|  -0.02184|  0.000093\n",
      "    1|    1.0059|  -0.02123|  0.000083\n",
      "    1|    1.0057|  -0.02053|  0.000077\n",
      "    1|    1.0055|  -0.01984|  0.000072\n",
      "    1|    1.0053|  -0.01918|  0.000067\n",
      "    1|    1.0051|  -0.01854|  0.000063\n",
      "    1|    1.0050|  -0.01793|  0.000059\n",
      "    1|    1.0048|  -0.01733|  0.000055\n"
     ]
    }
   ],
   "source": [
    "for i in range(100+1):\n",
    "    #gradient descent\n",
    "    with tf.GradientTape() as tape:  #변수들의 정보 변화를 tape에 기록\n",
    "        hypothesis= W*x_data +b\n",
    "        cost= tf.reduce_mean(tf.square(hypothesis-y_data))\n",
    "    W_grad, b_grad= tape.gradient(cost,[W,b])\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    if i%10 ==0:\n",
    "        print(\"{:5}|{:10.4f}|{:10.4}|{:10.6f}\".format(1,W.numpy(), b.numpy(),cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b434a94",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7206187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.00667, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4946702, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(W*5+b)\n",
    "print(W*2.5+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f10be3",
   "metadata": {},
   "source": [
    " ## Gradient descent algorithm\n",
    " - minimize cost function\n",
    " - gradient desecent is used many minimization problems\n",
    " - for a given cost function, cost(W,b), it will find W, b to minimize cost\n",
    " \n",
    "\n",
    "### How it works?\n",
    "- start with initial guesses\n",
    "- cost가 최소화 되는 방향으로 업데이트\n",
    "- 최소점에 도달했다고 판단할때까지 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a3da5",
   "metadata": {},
   "source": [
    "### Cost function in pure Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de49b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7dba93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "X= np.array([1,2,3])\n",
    "Y= np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3664b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(W,x,y):\n",
    "    c=0\n",
    "    for i in range(len(x)):\n",
    "        c+=(W*X[i]-Y[i])**2\n",
    "    return c/len(X) #편차 제곱의 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f236afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000|  74.66667\n",
      "-2.429|  54.85714\n",
      "-1.857|  38.09524\n",
      "-1.286|  24.38095\n",
      "-0.714|  13.71429\n",
      "-0.143|   6.09524\n",
      " 0.429|   1.52381\n",
      " 1.000|   0.00000\n",
      " 1.571|   1.52381\n",
      " 2.143|   6.09524\n",
      " 2.714|  13.71429\n",
      " 3.286|  24.38095\n",
      " 3.857|  38.09524\n",
      " 4.429|  54.85714\n",
      " 5.000|  74.66667\n"
     ]
    }
   ],
   "source": [
    "for feed_W in np.linspace(-3,5,num=15):\n",
    "    curr_cost= cost_func(feed_W,X,Y)\n",
    "    print(\"{:6.3f}|{:10.5f}\".format(feed_W,curr_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c1df8",
   "metadata": {},
   "source": [
    "### Cost function in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a41187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "X= np.array([1,2,3])\n",
    "Y= np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4ae32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fun(W,X,Y):\n",
    "    hypothesis= X*W\n",
    "    return tf.reduce_mean(tf.square(hypothesis-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82c6b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Values= np.linspace(-3,5,num=15)\n",
    "cost_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d45c6306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000|  74.66667\n",
      "-2.429|  54.85714\n",
      "-1.857|  38.09524\n",
      "-1.286|  24.38095\n",
      "-0.714|  13.71429\n",
      "-0.143|   6.09524\n",
      " 0.429|   1.52381\n",
      " 1.000|   0.00000\n",
      " 1.571|   1.52381\n",
      " 2.143|   6.09524\n",
      " 2.714|  13.71429\n",
      " 3.286|  24.38095\n",
      " 3.857|  38.09524\n",
      " 4.429|  54.85714\n",
      " 5.000|  74.66667\n"
     ]
    }
   ],
   "source": [
    "for feed_W in W_Values:\n",
    "    curr_cost= cost_func(feed_W,X,Y)\n",
    "    cost_values.append(curr_cost)\n",
    "    print(\"{:6.3f}|{:10.5f}\".format(feed_W,curr_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139903c",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "100e5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a43ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "x_data=[1.,2.,3.,4.]\n",
    "y_data=[1.,3.,5.,7.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c13d48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W= tf.Variable([6.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1948dfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |   141.0000 |   5.675000\n",
      "   10 |    29.7836 |   3.504818\n",
      "   20 |     6.3950 |   2.509610\n",
      "   30 |     1.4765 |   2.053226\n",
      "   40 |     0.4421 |   1.843936\n",
      "   50 |     0.2246 |   1.747959\n",
      "   60 |     0.1788 |   1.703946\n",
      "   70 |     0.1692 |   1.683762\n",
      "   80 |     0.1672 |   1.674506\n",
      "   90 |     0.1668 |   1.670262\n",
      "  100 |     0.1667 |   1.668315\n",
      "  110 |     0.1667 |   1.667423\n",
      "  120 |     0.1667 |   1.667013\n",
      "  130 |     0.1667 |   1.666826\n",
      "  140 |     0.1667 |   1.666739\n",
      "  150 |     0.1667 |   1.666700\n",
      "  160 |     0.1667 |   1.666682\n",
      "  170 |     0.1667 |   1.666674\n",
      "  180 |     0.1667 |   1.666670\n",
      "  190 |     0.1667 |   1.666668\n",
      "  200 |     0.1667 |   1.666667\n",
      "  210 |     0.1667 |   1.666667\n",
      "  220 |     0.1667 |   1.666667\n",
      "  230 |     0.1667 |   1.666667\n",
      "  240 |     0.1667 |   1.666667\n",
      "  250 |     0.1667 |   1.666667\n",
      "  260 |     0.1667 |   1.666667\n",
      "  270 |     0.1667 |   1.666667\n",
      "  280 |     0.1667 |   1.666667\n",
      "  290 |     0.1667 |   1.666667\n"
     ]
    }
   ],
   "source": [
    "for step in range(300):\n",
    "    hypothesis=W*x_data\n",
    "    cost=tf.reduce_mean(tf.square(hypothesis-y_data))\n",
    "    \n",
    "    alpha= 0.01 #learning rate\n",
    "    gradient= tf.reduce_mean(tf.multiply(tf.multiply(W, x_data)-y_data,x_data))\n",
    "    descent= W- tf.multiply(alpha, gradient)\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(\"{:5} | {:10.4f} | {:10.6f}\".format(step, cost.numpy(), W.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e1a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7688d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81122554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
