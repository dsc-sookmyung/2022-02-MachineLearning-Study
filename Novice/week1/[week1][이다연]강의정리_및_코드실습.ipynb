{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8df5969",
   "metadata": {},
   "source": [
    "# <1주차 MLstudy 강의정리 및 코드실습>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a9ba3",
   "metadata": {},
   "source": [
    "##### 머신러닝이란 인공지능의 한 분야이다. (사람이 학습하듯이 컴퓨터에도 데이터들을 줘서 학습하게 함으로써 새로운 지식을 얻어내게 하는 것)\n",
    "\n",
    "즉, 어떠한 자료나 현상을 바탕으로 프로그램이 학습해서 일을 함\n",
    "\n",
    "프로그램 학습에는 2가지 방법이 있다.\n",
    "\n",
    "1)정해진 Data (supervised learning)\n",
    "\n",
    "2)Data 스스로 학습 (unsupervised learning)\n",
    "\n",
    "1. supervised learnig은 입력된 문제에 대한 답을 예측하는 데 사용된다. ex) 상품 추천, 질병 진단 등\n",
    "\n",
    "학습 훈련 데이터(training data)가 필요하다. 예로, 개와 고양이 사진을 구분하는 것을 들 수 있다. 이때 입력은 사진이고, 출력은 개 또는 고양이인지의 여부가 된다. 또 다른 예시로 사과 사진들을 주고 컴퓨터가 이것이 사과라는 것을 알게 해준다.\n",
    "\n",
    ">Types of supervised learning\n",
    "- regrssion\n",
    "- binary classification\n",
    "- multi-lable classification\n",
    "    \n",
    "2. unsupervised learning은 컴퓨터가 입력값만 있는 훈련 데이터를 이용하여 입력들의 규칙성을 찾는 학습 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e145a68",
   "metadata": {},
   "source": [
    "# ✔Build hypothesis and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "29c189c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miniconda3 MLstudy 가상환경에서 tensorflow 모듈 불러오기 성공!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print ('miniconda3 MLstudy 가상환경에서 tensorflow 모듈 불러오기 성공!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4043538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 데이터 값 입력\n",
    "x_data = [1, 2, 3, 4, 5]\n",
    "y_data = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a779a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w와 b의 초기값 지정\n",
    "W = tf.Variable(2.9)\n",
    "b = tf.Variable(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2eff62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d1d0cd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|    2.4520|     0.376| 45.660004\n",
      "   10|    1.1036|  0.003398|  0.206336\n",
      "   20|    1.0128|  -0.02091|  0.001026\n",
      "   30|    1.0065|  -0.02184|  0.000093\n",
      "   40|    1.0059|  -0.02123|  0.000083\n",
      "   50|    1.0057|  -0.02053|  0.000077\n",
      "   60|    1.0055|  -0.01984|  0.000072\n",
      "   70|    1.0053|  -0.01918|  0.000067\n",
      "   80|    1.0051|  -0.01854|  0.000063\n",
      "   90|    1.0050|  -0.01793|  0.000059\n",
      "  100|    1.0048|  -0.01733|  0.000055\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent를 tensorflow로 구현하고 반복문을 사용하여 10번에 한번씩 print 함\n",
    "\n",
    "for i in range(100+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W * x_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(\"{:5}|{:10.4f}|{:10.4}|{:10.6f}\".format(i, W.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b1d4243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.00667, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4946702, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 위의 알고리즘을 통해 5 or 2 가 입력되었을 때 출력이 입력된 값과 거의 비슷하게 나온 것을 보여줌\n",
    "\n",
    "print(W * 5 + b)\n",
    "print(W * 2.5 + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e1c19c",
   "metadata": {},
   "source": [
    "# ✔How to minimize cost?\n",
    "어떻게 실제 데이터와 비슷하게 (cost를 최소화) 만들어 낼 수 있을까? 바로 Gradient descent 알고리즘을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d69d6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 말고 tensorflow로 구현한 코드\n",
    "\n",
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a5a7beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func(W, X, Y):\n",
    "    hypothesis = X * W\n",
    "    return tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5db95280",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_values = np.linspace(-3, 5, num=15)\n",
    "cost_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b8f3b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000|  74.66667\n",
      "-2.429|  54.85714\n",
      "-1.857|  38.09524\n",
      "-1.286|  24.38095\n",
      "-0.714|  13.71429\n",
      "-0.143|   6.09524\n",
      " 0.429|   1.52381\n",
      " 1.000|   0.00000\n",
      " 1.571|   1.52381\n",
      " 2.143|   6.09524\n",
      " 2.714|  13.71429\n",
      " 3.286|  24.38095\n",
      " 3.857|  38.09524\n",
      " 4.429|  54.85714\n",
      " 5.000|  74.66667\n"
     ]
    }
   ],
   "source": [
    "for feed_W in W_values:\n",
    "    curr_cost = cost_func(feed_W, X, Y)\n",
    "    cost_values.append(curr_cost)\n",
    "\n",
    "    print(\"{:6.3f}|{:10.5f}\".format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1aca107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "\n",
    "x_data = [1., 2., 3., 4.]\n",
    "y_data = [1., 3., 5., 7.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6caf936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W값을 -2로 입력하여도 1로 수렴해나간다.\n",
    "\n",
    "W = tf.Variable([-2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a9dea55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |    42.0000 |  -1.860000\n",
      "   10 |    16.1490 |  -0.773429\n",
      "   20 |     6.2093 |  -0.099668\n",
      "   30 |     2.3875 |   0.318118\n",
      "   40 |     0.9180 |   0.577178\n",
      "   50 |     0.3530 |   0.737817\n",
      "   60 |     0.1357 |   0.837425\n",
      "   70 |     0.0522 |   0.899191\n",
      "   80 |     0.0201 |   0.937490\n",
      "   90 |     0.0077 |   0.961239\n",
      "  100 |     0.0030 |   0.975965\n",
      "  110 |     0.0011 |   0.985096\n",
      "  120 |     0.0004 |   0.990759\n",
      "  130 |     0.0002 |   0.994270\n",
      "  140 |     0.0001 |   0.996447\n",
      "  150 |     0.0000 |   0.997797\n",
      "  160 |     0.0000 |   0.998634\n",
      "  170 |     0.0000 |   0.999153\n",
      "  180 |     0.0000 |   0.999475\n",
      "  190 |     0.0000 |   0.999674\n",
      "  200 |     0.0000 |   0.999798\n",
      "  210 |     0.0000 |   0.999875\n",
      "  220 |     0.0000 |   0.999922\n",
      "  230 |     0.0000 |   0.999952\n",
      "  240 |     0.0000 |   0.999970\n",
      "  250 |     0.0000 |   0.999981\n",
      "  260 |     0.0000 |   0.999988\n",
      "  270 |     0.0000 |   0.999993\n",
      "  280 |     0.0000 |   0.999996\n",
      "  290 |     0.0000 |   0.999997\n"
     ]
    }
   ],
   "source": [
    "# 반복을 통해 특정한 값으로 수렴해 가는 것을 볼 수 있음\n",
    "\n",
    "for step in range(300):\n",
    "    hypothesis = W * X\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    \n",
    "    alpha = 0.01\n",
    "    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))\n",
    "    descent = W - tf.multiply(alpha, gradient)\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print('{:5} | {:10.4f} | {:10.6f}'.format(step, cost.numpy(), W.numpy()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLstudy] *",
   "language": "python",
   "name": "conda-env-MLstudy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
